<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2023-02-23T14:51:17Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8472873" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8472873</identifier>
        <datestamp>2021-09-28</datestamp>
        <setSpec>sensors</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" dtd-version="1.3" xml:lang="en" article-type="research-article">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id>
              <journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id>
              <journal-id journal-id-type="publisher-id">sensors</journal-id>
              <journal-title-group>
                <journal-title>Sensors (Basel, Switzerland)</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1424-8220</issn>
              <publisher>
                <publisher-name>MDPI</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8472873</article-id>
              <article-id pub-id-type="pmcid">PMC8472873</article-id>
              <article-id pub-id-type="pmc-uid">8472873</article-id>
              <article-id pub-id-type="pmid">34577512</article-id>
              <article-id pub-id-type="doi">10.3390/s21186305</article-id>
              <article-id pub-id-type="publisher-id">sensors-21-06305</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Article</subject>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Modular Robotic Limbs for Astronaut Activities Assistance</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zhao</surname>
                    <given-names>Sikai</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zhao</surname>
                    <given-names>Jie</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Sui</surname>
                    <given-names>Dongbao</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Wang</surname>
                    <given-names>Tianshuo</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zheng</surname>
                    <given-names>Tianjiao</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zhao</surname>
                    <given-names>Chuanwu</given-names>
                  </name>
                  <xref rid="af2-sensors-21-06305" ref-type="aff">2</xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Zhu</surname>
                    <given-names>Yanhe</given-names>
                  </name>
                  <xref rid="af1-sensors-21-06305" ref-type="aff">1</xref>
                  <xref rid="c1-sensors-21-06305" ref-type="corresp">*</xref>
                </contrib>
              </contrib-group>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Waslander</surname>
                    <given-names>Steven</given-names>
                  </name>
                  <role>Academic Editor</role>
                </contrib>
              </contrib-group>
              <aff id="af1-sensors-21-06305"><label>1</label>State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Harbin 150001, China; <email>16b908056@stu.hit.edu.cn</email> (S.Z.); <email>jzhao@hit.edu.cn</email> (J.Z.); <email>suidongbao@hit.edu.cn</email> (D.S.); <email>1110810113@hit.edu.cn</email> (T.W.); <email>zhengtj@hit.edu.cn</email> (T.Z.)</aff>
              <aff id="af2-sensors-21-06305"><label>2</label>Institute of Systems Engineering, China Academy of Engineering Physics, Mianyang 621900, China; <email>skye908056@gmail.com</email></aff>
              <author-notes>
                <corresp id="c1-sensors-21-06305"><label>*</label>Correspondence: <email>yhzhu@hit.edu.cn</email></corresp>
              </author-notes>
              <pub-date pub-type="epub">
                <day>21</day>
                <month>9</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="collection">
                <month>9</month>
                <year>2021</year>
              </pub-date>
              <volume>21</volume>
              <issue>18</issue>
              <elocation-id>6305</elocation-id>
              <history>
                <date date-type="received">
                  <day>22</day>
                  <month>7</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>18</day>
                  <month>9</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2021 by the authors.</copyright-statement>
                <copyright-year>2021</copyright-year>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
                </license>
              </permissions>
              <abstract>
                <p>In order to meet the assist requirements of extravehicular activity (EVA) for astronauts, such as moving outside the international space station (ISS) or performing on-orbit tasks by a single astronaut, this paper proposes an astronaut robotic limbs system (AstroLimbs) for extravehicular activities assistance. This system has two robotic limbs that can be fixed on the backpack of the astronaut. Each limb is composed of several basic module units with identical structure and function, which makes it modularized and reconfigurable. The robotic limbs can work as extra arms of the astronaut to assist them outside the space station cabin. In this paper, the robotic limbs are designed and developed. The reinforcement learning method is introduced to achieve autonomous motion planning capacity for the robot, which makes the robot intelligent enough to assist the astronaut in unstructured environment. In the meantime, the movement of the robot is also planned to make it move smoothly. The structure scene of the ISS for extravehicular activities is modeled in a simulation environment, which verified the effectiveness of the proposed method.</p>
              </abstract>
              <kwd-group>
                <kwd>astronaut operation</kwd>
                <kwd>extravehicular activities assistance</kwd>
                <kwd>robotic limbs</kwd>
                <kwd>modular robots</kwd>
                <kwd>wearable robots</kwd>
                <kwd>reinforcement learning</kwd>
              </kwd-group>
            </article-meta>
          </front>
          <body>
            <sec sec-type="intro" id="sec1-sensors-21-06305">
              <title>1. Introduction</title>
              <p>In recent years, space exploration has been regarded as an important strategic development direction by the aerospace powers and relevant independent research institutions in the world [<xref rid="B1-sensors-21-06305" ref-type="bibr">1</xref>]. With the rapid development and application of robot technology and artificial intelligence, the improvement of relevant technologies in the space exploration field have also been promoted significantly [<xref rid="B2-sensors-21-06305" ref-type="bibr">2</xref>,<xref rid="B3-sensors-21-06305" ref-type="bibr">3</xref>,<xref rid="B4-sensors-21-06305" ref-type="bibr">4</xref>,<xref rid="B5-sensors-21-06305" ref-type="bibr">5</xref>]. Although some space tasks have been replaced by robots gradually [<xref rid="B6-sensors-21-06305" ref-type="bibr">6</xref>], the complex and smart operation tasks are still hard for robots to take over. Human operating ability and rich experience still play irreplaceable roles in executing high skilled tasks. Therefore, manned space exploration is still an effective means of space exploration and on-orbit service.</p>
              <p>For the EVA on orbit service, astronauts usually need to complete long-time and complex tasks, such as the on-orbit assembly, maintenance and so on. When they move outside the cabin, they usually have to climb and move only under the assistance of safety rope, which is consumes a lot of energy and is apt to cause fatigue and trauma for the astronauts [<xref rid="B7-sensors-21-06305" ref-type="bibr">7</xref>]. In addition, according to the report, there will be rough and sharp protrusions on the holding railings of the space station due to the high-speed impact of space particles [<xref rid="B8-sensors-21-06305" ref-type="bibr">8</xref>], which usually tear the gloves worn by the astronauts during climbing. The above problems will affect astronauts’ safety and greatly limit the working duration of extravehicular activities.</p>
              <p>To alleviate the above-mentioned problems, the space robots for assisting astronauts have been developed. The space manipulator can be used for on-orbit assembly, ISS maintenance, and long-distance motion assistance for astronauts outside the cabin, such as the Space Station Remote Manipulator System (SSRMS) [<xref rid="B9-sensors-21-06305" ref-type="bibr">9</xref>] and the Special Purpose Dexterous Manipulator (SPDM) [<xref rid="B10-sensors-21-06305" ref-type="bibr">10</xref>]. The anthropomorphic astronaut robots are mainly used for demonstration and verification tests of shaking hands with astronauts or delivering tools, such as the Robonaut 2 (R2) [<xref rid="B11-sensors-21-06305" ref-type="bibr">11</xref>,<xref rid="B12-sensors-21-06305" ref-type="bibr">12</xref>], and Skybot f-850 [<xref rid="B13-sensors-21-06305" ref-type="bibr">13</xref>]. Researchers have also proposed the space robots which can adapt themselves to complex and changeable space environment and also have the capability of on-orbit fabrication or assembly [<xref rid="B14-sensors-21-06305" ref-type="bibr">14</xref>,<xref rid="B15-sensors-21-06305" ref-type="bibr">15</xref>]. In the meantime, in order to improve the robots’ adaptability to the changes of its own state and environment, researchers have introduced intelligent algorithms to enable the robots’ self-modeling and self-evolution [<xref rid="B16-sensors-21-06305" ref-type="bibr">16</xref>,<xref rid="B17-sensors-21-06305" ref-type="bibr">17</xref>,<xref rid="B18-sensors-21-06305" ref-type="bibr">18</xref>,<xref rid="B19-sensors-21-06305" ref-type="bibr">19</xref>]. For the astronauts, these space robots only aim at providing assistance on wide-range movement outside the cabin, executing simple tasks in the cabin or carrying out self-assembly work at the conceptual level, but they are constrained in small-range movement or complex operation outside the cabin. Besides, NASA has developed an astronaut assisted exoskeleton robot system (X1) to enhance the physical ability of astronauts when walking out of the cabin in the future [<xref rid="B20-sensors-21-06305" ref-type="bibr">20</xref>]. However, these assisted devices may not only constrain the mobility of astronauts’ body, but also interfere with their spacesuit.</p>
              <p>The wearable robotic limbs can provide a novel aid in the face of such difficulties. They can serve as the extra arms of human and provide help during the operation. Asada et al. developed several wearable robotic limbs for Boeing aircraft manufacturing and the nuclear industry. Combined with the pilot’s limb posture and working process, they can realize moving assistance, working assistance in special position, human body support and so on [<xref rid="B21-sensors-21-06305" ref-type="bibr">21</xref>,<xref rid="B22-sensors-21-06305" ref-type="bibr">22</xref>,<xref rid="B23-sensors-21-06305" ref-type="bibr">23</xref>,<xref rid="B24-sensors-21-06305" ref-type="bibr">24</xref>]. Vatsal et al. [<xref rid="B25-sensors-21-06305" ref-type="bibr">25</xref>] designed a extensible robotic limb worn on the forearm, to grasp objects. Gopinath et al. [<xref rid="B26-sensors-21-06305" ref-type="bibr">26</xref>] carried out preliminary experimental tests to assist drummers to play drums using wearable robotic limbs. The waist wearable robotic limbs proposed by Sasaki et al. has two mechanical arms [<xref rid="B27-sensors-21-06305" ref-type="bibr">27</xref>,<xref rid="B28-sensors-21-06305" ref-type="bibr">28</xref>] and operated by human foot and toes. These wearable robotic limbs just aim at the needs of industrial manufacturing and daily assistance on the ground. They have not been involved in manned space exploration for astronaut operation assistance.</p>
              <p>In this paper, the robotic limbs for astronauts are named AstroLimbs, and can help astronauts perform extravehicular activities. To our knowledge, it is the first time the concept of applying robotic limbs for astronaut assistance in the space exploration field has been proposed. The AstroLimbs are developed to offer climbing assistance for astronauts outside the cabin, by actively carrying astronauts to help them move together. Each limb is composed of six basic module units with identical structure and function. The basic unit has a rotational degree of freedom (DOF) and the modules are interchangeable. Based on the reinforcement learning method, the robot can move autonomously to the final target from any starting position. The simulation environment referring to the structure of the space station is constructed. The basic movements of the AstroLimbs are planned, including the joint angular velocity and acceleration, the variation of the robot’s posture and the appropriate distance between robot and its current work plane. Via these plans, the robot can move smoothly and stably. The rationality of the learning method and the moving performance are verified in the simulation environment. Thanks to this learned ability, the robot can free both hands of the astronauts to carry out extravehicular activities. In addition, it will also reduce the damage risk to the spacesuit and extend EVA duration.</p>
              <p>The paper is organized as follows. <xref rid="sec2-sensors-21-06305" ref-type="sec">Section 2</xref> describes the utilization concept and the development of the wearable robotic limbs. <xref rid="sec3-sensors-21-06305" ref-type="sec">Section 3</xref> mainly introduces the method of learning to move autonomously and plans the movement of the robotic limbs. <xref rid="sec4-sensors-21-06305" ref-type="sec">Section 4</xref> mainly presents the verification of the learning method and the related results in the simulation environment. Finally, <xref rid="sec5-sensors-21-06305" ref-type="sec">Section 5</xref> summarizes the work of this paper and looks forward to future work.</p>
            </sec>
            <sec id="sec2-sensors-21-06305">
              <title>2. The AstroLimbs Design</title>
              <sec id="sec2dot1-sensors-21-06305">
                <title>2.1. The AstroLimbs Concept</title>
                <p>At present, human manned space activities mainly rely on the space station, which is equivalent to a space laboratory with modern scientific research equipments and is capable of conducting scientific experiments in microgravity environment. It also provides a platform for astronauts to stay in earth orbit for a long time in space, and makes it convenient for astronauts to carry out space experiments, extravehicular walking and other on-orbit activities. In the meanwhile, astronauts need to carry out the extravehicular assembly, inspection and maintenance of the space station. <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref> shows the real and simulated scenes of the ISS, and the simulation scene of astronauts’ extravehicular activities assisted by wearable robotic limbs. The structural design of the ISS is based on the truss structure, which constitutes the keel frame of the space station, as shown in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>a,b. Other multi-function modules, extravehicular service equipment, large mechanical manipulator service systems and solar panels are all installed on the keel frame, which forms a truss hanging cabin type space station. On one hand, it ensures the overall stiffness of the space station, and is conducive to the normal independent operation of each subsystem. On the other hand, it can provide a foothold for astronauts’ assembly and maintenance activities. As shown in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>c,d, astronauts rely on the truss of the space station to move, climb and work outside the cabin. The red frame marks represents the handles installed on the truss for facilitating climbing and moving.</p>
                <p>Based on the scale relationship between the truss of ISS and the astronauts in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>a,b, the corresponding simulation environment is shown in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>c,d. <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>c shows the scene of astronauts moving, climbing, and working on the truss of ISS with the assistance of the AstroLimbs. In the simulation modeling, the cross section of the truss of ISS is designed as regular hexagon shape, which is an axisymmetric figure. Thus, this research mainly focuses on the three work planes that can be seen in the front view. As shown in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>d, the handles for astronauts moving is designed according to the real counterparts in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>b and can be classified into horizontal one and vertical ones in terms of the installation method. Its mounting position refers to the relative position of the real handle on the truss structure in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>b. Two rows of horizontally installed handles are designed on the front work plane. The other two work planes intersecting with the front work plane have one row of horizontally installed handles, respectively. The truss of ISS is equidistantly divided into several space areas, and the corresponding climbing handles are vertical installed handles and are placed on the partition wall in the middle of each area, as shown in the red circle in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>d. These two types of handles provide connection places for astronauts to move freely in a small range on the truss structure outside the ISS.</p>
              </sec>
              <sec id="sec2dot2-sensors-21-06305">
                <title>2.2. Mechanical Design</title>
                <p><xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>e shows the concept of AstroLimbs for assisting extravehicular activities. The AstroLimbs has two robotic arms, which are fixed near the back waist of the astronaut and connected to the astronaut’s backpack. The AstroLimbs grants the pilot two more arms, which can assist the astronaut to climb on the truss outside the cabin and improve the operation ability of addedexecuting extravehicular activities. Besides, when in the fixed working position, it can serve as a partner for the astronaut to carry out the tasks which are difficult to complete for a single person.</p>
                <p>The AstroLimbs system is designed to be modularized due to the following advantages. The basic module unit will have the same structure and function, which can be quickly assembled and disassembled. It is able to improve the fault tolerance of the AstroLimbs when working in the outer space. If one basic module unit of the AstroLimbs has a problem, it can be replaced by another intact module. The basic module units, the reconfiguration and the wearing display of the AstroLimbs are shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>. Each basic module has an independent rotational DOF, as shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>a,d. <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>a is the 3D render map of the basic module unit. Each basic module unit is composed of two identical sub-modules that connected by a steering engine.</p>
                <p>Each sub-module is made of a deformed triangular prism with the edge ground to be smooth surface, which is distinguished by the yellow and blue entities in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>a. At the same time, each sub module has a rotation plane and a connection plane. The rotation planes of the sub-modules coincide with each other to form the rotational DOF. The common axis of rotation is perpendicular to two rotation planes. Its rotation range is −180–180<inline-formula><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>a shows the rotation of the module at 0<inline-formula><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, 90<inline-formula><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> and 180<inline-formula><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, respectively. The situation will be similar when rotating in the other direction. The prototypes corresponding to the rendering basic modules are shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>d. In the meanwhile, the AstroLimbs contains a complete electrical system to move the arm. Metal contacts for electrical connection are designed for connecting adjacent modules. They are used for power supply and communication between modules, to ensure the fast and reliable connection of the electrical system.</p>
                <p>Combined with the idea of anthropomorphic bionic design, two extra arms are designed in the robot system according to the needs of auxiliary operations. The number of modules in each arm can be arbitrarily configured. The total freedom of the robotic arm is determined by the number of modules connected in series. In order to ensure the basic spatial movement ability, the robotic arm was designed with 6 DOFs. Namely, each arm is equipped with six basic modules as the target model for using in the space exploration, as shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>b. <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>e just shows the wearing display of the AstroLimbs. Evabag shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>b is the EVA backpack for outer spacewalk of astronauts. Two wearable robotic limbs are fixed on both sides of the Evabag and are located near the place between waist and chest of the astronaut. This mounting position is good for the robotic limbs to assist the astronaut to move, operate with other astronauts and reduce the spatial overlap with the human limbs. In <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>b, <italic toggle="yes">A<inline-formula><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic>, <italic toggle="yes">A<inline-formula><mml:math id="mm6" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic> and <italic toggle="yes">A<inline-formula><mml:math id="mm7" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic> represent the status of the AstroLimbs’ right arm at three different positions, respectively. The configuration of rotating DOFs corresponding to the right robotic limb in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>b is shown in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>c, where <inline-formula><mml:math id="mm8" display="block" overflow="scroll"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm9" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>–<inline-formula><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm11" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> represents the six different rotating shafts of active DOFs. The module with rotating shaft <inline-formula><mml:math id="mm12" display="block" overflow="scroll"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is fixed to the Evabag. The module with rotating shaft <inline-formula><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm15" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the operating end of the robotic limb. When the rotation angle of each joint is given, the spatial position and posture of the end point relative to the selected base coordinate can be obtained through the forward kinematics of the robotic limb. The state <italic toggle="yes">A<inline-formula><mml:math id="mm16" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic> can be set as the initial state, when the six joint angles varies, the position and posture of the end actuator will also change accordingly. For example, it can move to a new position as illustrated by state <italic toggle="yes">A<inline-formula><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic> or state <italic toggle="yes">A<inline-formula><mml:math id="mm18" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></italic> in <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>b. <xref rid="sensors-21-06305-f002" ref-type="fig">Figure 2</xref>f shows the reconfiguration of the real robotic limb with multiple DOFs based on the modules connected in series.</p>
              </sec>
            </sec>
            <sec id="sec3-sensors-21-06305">
              <title>3. Method for Autonomous Motion</title>
              <sec id="sec3dot1-sensors-21-06305">
                <title>3.1. Q-Learning Algorithm</title>
                <p>Q-learning algorithm of reinforcement learning is introduced for achieving the autonomous motion ability of the AstroLimbs with target orientation at any point on the truss of the ISS during climbing. Therefore, based on the designed working environment of the truss, the state of the AstroLimbs system is divided, and the basic motion of the AstroLimbs is planned. The reward function in the process of task learning is proposed. The corresponding analysis of the training and evaluation results based on reinforcement learning is conducted.</p>
                <p>Reinforcement learning is an overall process refers to the agent’s trial, evaluation and memory. The agent’s learning maps from environment state to action, which makes the agent gain the maximal reward after executing a certain action. This learning process will make the agent perform best under some preset evaluation rules. Q-learning algorithm is one of the evaluation rules for the agent to choose a specific action in the current state, which is an action-utility function. Q is short for the word of quality, which is the quality feedback to each action and provides memory for the agent. When the number of states and actions in the learning process is limited, Q-learning algorithm is very suitable for model free autonomous motion planning.</p>
                <p>Each time in a specific state, the corresponding evaluation value of the agent after executing the action has the following expression:<disp-formula id="FD1-sensors-21-06305"><label>(1)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <italic toggle="yes">s</italic> is the current state, <italic toggle="yes">a</italic> is the action that can be taken in the current state, and <italic toggle="yes">Val</italic> is the obtained maximal value of the evaluation corresponding to this action under the conditions of the current state <italic toggle="yes">s</italic> and action <italic toggle="yes">a</italic>, based on this value the agent can determine the action to execute in this step.</p>
                <p>The core of Q-learning algorithm is the process of constantly updating the evaluation value <italic toggle="yes">Val</italic> in Equation (<xref rid="FD1-sensors-21-06305" ref-type="disp-formula">1</xref>) according to the continuous trial training:<disp-formula id="FD2-sensors-21-06305"><label>(2)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⇐</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mfenced separators="" open="[" close="]"><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo>·</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>a</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">R</italic> represents the reward value that can be obtained by executing action <italic toggle="yes">a</italic> in the current state <italic toggle="yes">s</italic>, <italic toggle="yes">s</italic>’ is the new state of agent after executing action <italic toggle="yes">a</italic>, <italic toggle="yes">a</italic>’ is the possible action in state <italic toggle="yes">s</italic>’, <inline-formula><mml:math id="mm21" display="block" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> is the learning efficiency (<inline-formula><mml:math id="mm22" display="block" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> = 0.01) and <inline-formula><mml:math id="mm23" display="block" overflow="scroll"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:math></inline-formula> serves as the discount factor (<inline-formula><mml:math id="mm24" display="block" overflow="scroll"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:math></inline-formula> = 0.9).</p>
              </sec>
              <sec id="sec3dot2-sensors-21-06305">
                <title>3.2. Determination of the States</title>
                <p><xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>a shows the schematic diagram of the operation status on the ISS truss where the yellow dot, red dot, green dot and red pentagram refer to the handles that can be grasped by the AstroLimbs during the movement. There is a total of 30 handles and each handle represents the corresponding status in <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>a. Among the handles, the green dot represents the starting point of the training process (Point 1). The red pentagram stands for the target point (Point 30). According to <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>b, as the AstroLimbs has two robotic arms, the same foothold (the foothold on the grid colored with green) may belong to either the end of the left arm or the right arm. At this time, although the foothold position is the same, yet it must be regarded as two different states. Thus, there are total 60 states in the process of moving, and the state value can be judged with the following expression:<disp-formula id="FD3-sensors-21-06305"><label>(3)</label><mml:math id="mm25" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <italic toggle="yes">State</italic> is the state number of the AstroLimbs moving on the truss of the ISS, <italic toggle="yes">k</italic> is the current moving arm of the AstroLimbs, <italic toggle="yes">Flag<inline-formula><mml:math id="mm26" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> is the corresponding identification of the current moving arm, when <italic toggle="yes">k</italic> = left, <italic toggle="yes">Flag<inline-formula><mml:math id="mm27" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> = 1 (<italic toggle="yes">k</italic> = right, <italic toggle="yes">Flag<inline-formula><mml:math id="mm28" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> = 0), (<italic toggle="yes">X<inline-formula><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic>, <italic toggle="yes">Y<inline-formula><mml:math id="mm30" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic>, <italic toggle="yes">Z<inline-formula><mml:math id="mm31" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic>) are the landing point coordinates of the AstroLimbs’ moving end.</p>
              </sec>
              <sec id="sec3dot3-sensors-21-06305">
                <title>3.3. Setting of the Actions</title>
                <p>The moving actions of the AstroLimbs will be affected by its own structure and environmental factors. The main influencing factors are listed as follows: (1) The structural features and size of the AstroLimbs itself; (2) The moving ability of the AstroLimbs; (3) The work plane of the state point (the foothold); (4) The position relationship between the state points. Based on the above constraints, the effective actions of the AstroLimbs are introduced, assuming that the left end of the AstroLimbs is fixed, and only the right end are free. Finally, 14 kinds of effective moving actions are obtained and the relative coordinates of the two ends are processed equivalently.</p>
                <p>The equivalent coordinate is introduced to show the relative position of the robot left and right ends. For the X and Y directions, the meaning of equivalent coordinate values (<italic toggle="yes">x<inline-formula><mml:math id="mm32" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> and <italic toggle="yes">y<inline-formula><mml:math id="mm33" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> ) represent the number of handle intervals (or the number of unit intervals) in the right end relative to the left one in the corresponding coordinate direction. In any direction, the distance between the two nearing points is regarded as one basic unit. At this time, if the right end is two units away from the left one, the corresponding equivalent coordinate will be two. When the right end below the left one, the value will turn to be −2. In addition, due to above mentioned influencing factors for the robot motion, the maximum movement distance of the robotic limb in each direction is two basic units. Therefore, the lower and upper limit of the equivalent coordinate values (<italic toggle="yes">x<inline-formula><mml:math id="mm34" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> and <italic toggle="yes">y<inline-formula><mml:math id="mm35" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic>) are −2 and 2, respectively.</p>
                <p>However, for the Z direction, the equivalent coordinate value <italic toggle="yes">z<inline-formula><mml:math id="mm36" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> is designed to distinguish between various situations when the two ends are in different work planes. It determines the spatial moving action mode of the AstroLimbs and the value is self-designed to be from −2 to 2 (<italic toggle="yes">z<inline-formula><mml:math id="mm37" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic>∈{0, 1, −1, 2, −2}). As shown in <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>, action mode <italic toggle="yes">A</italic> means that the AstroLimbs moves in the same work plane and the value <italic toggle="yes">z<inline-formula><mml:math id="mm38" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> is set at 0. Action mode <italic toggle="yes">B</italic> means that the right end is in the work plane 1 and the left end is in the work plane 2 (<italic toggle="yes">z<inline-formula><mml:math id="mm39" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> = −1). Action mode <italic toggle="yes">C</italic> means that the right end is in the work plane 2, the left end is in the work plane 1 (<italic toggle="yes">z<inline-formula><mml:math id="mm40" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> = 1). Action mode <italic toggle="yes">D</italic> means that the right end is in the work plane 3 and the left end is in the work plane 2 (<italic toggle="yes">z<inline-formula><mml:math id="mm41" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> = −2). The action mode <italic toggle="yes">E</italic> means that the right end is in the work plane 2, the left end is in the work plane 3 (<italic toggle="yes">z<inline-formula><mml:math id="mm42" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> = 2).</p>
                <p>According to <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>, {<italic toggle="yes">x<inline-formula><mml:math id="mm43" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, y<inline-formula><mml:math id="mm44" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, z<inline-formula><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic>} is the equivalent coordinate (Eq-Coordinate) of the right end relative to the left end, as shown in <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>b. <italic toggle="yes">x<inline-formula><mml:math id="mm46" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> represents the interval number of the state points of the right end relative to the left end in the <italic toggle="yes">X</italic>-axis direction, and the value of <italic toggle="yes">x<inline-formula><mml:math id="mm47" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> can be obtained (<italic toggle="yes">x<inline-formula><mml:math id="mm48" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic>∈{1, 2}). In the same way, <italic toggle="yes">y<inline-formula><mml:math id="mm49" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic> represents the interval number of the state points in the <italic toggle="yes">Y</italic>-axis direction and then <italic toggle="yes">y<inline-formula><mml:math id="mm50" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></italic>∈{0, 1, −1} can be obtained, where the sign represents the front and back position relationship between the two ends. Especially, the minus sign represents that the left end is in front of the right side in terms of the <italic toggle="yes">Y</italic>-axis. For example, the equivalent coordinates of the two actions are {2, −1, 0} and {2, 1, 0}, respectively, in <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>b.</p>
                <p>Similarly, when the right end is fixed, and only the left end are free, the equivalent coordinates are the same if the relative position relationship between the two ends remains unchanged. Thus, a total of 28 effective actions for the AstroLimbs can be expressed in the form of 14 equivalent coordinates, as shown in <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>.</p>
              </sec>
              <sec id="sec3dot4-sensors-21-06305">
                <title>3.4. The Construction of Reward Mechanism</title>
                <p>Reward is the expression of the contribution made by the agent to perform a specific action in a specific state when achieving the task goal. The goal of the agent is to maximize the expected cumulative reward. During the training process, there are three basic cases for the AstroLimbs in this paper. The first one is the success case, when the robot gets to the final target. The second one is the common case, in which the robot reaches the designed state points except the target. The last is the failure one, when the robot moves out of the allowable points. When the robot steps to another case, the corresponding reward will also turn to be different. Once the robot reaches the target, it will be given the maximal reward. The construction of reward mechanism for the robot will directly affect training process and result. In order to ensure the AstroLimbs has an equal chance to be trained at each state point except the final target, all the rewards of the state points will be set to be the same and the value is designed to be zero. In addition, if the AstroLimbs moves out of the boundary of the working area or its moved end place does not belong to any state that has been planned, it is regarded as failure of the task. In this case, the agent will be punished and the reward is set to a negative value. Based on those principles, we can establish a reward mechanism, which can be expressed by the following Equation:
<disp-formula id="FD4-sensors-21-06305"><label>(4)</label><mml:math id="mm51" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>∼</mml:mo><mml:mn>29</mml:mn></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>∉</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>∼</mml:mo><mml:mn>30</mml:mn></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <italic toggle="yes">R</italic> is the reward value obtained by the agent after performing a specific action, <italic toggle="yes">R<inline-formula><mml:math id="mm52" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> is the maximal reward value when the robot reaching the target and the value is designed to be 50, <italic toggle="yes">U<inline-formula><mml:math id="mm53" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> is the current state of the robot after executing the action, and {<italic toggle="yes">S<inline-formula><mml:math id="mm54" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic>} is a set of all the effective states in the process of the robot moving which is planned in advance as shown in <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>a.</p>
                <p>For the training process of the AstroLimbs, when stepping into the common state1–state29, the value <italic toggle="yes">R</italic> for the robot will always be 0. It means the robot has neither reward nor punishment. The robot will be greatly encouraged by acquiring the maximum reward, the value of which <italic toggle="yes">R</italic> is 50, when reaching the final target state30. Apart from the allowable states, if the robot gets into an undesirable state, it will be punished by deducting a certain reward value of 50 and the value <italic toggle="yes">R</italic> is −50.</p>
              </sec>
              <sec id="sec3dot5-sensors-21-06305">
                <title>3.5. Movement Planning of the AstroLimbs</title>
                <p>In order to plan the basic movement of the AstroLimbs, it is necessary to simplify the overall modeling of the astronaut-robot system, and set the basic assumptions and constraints based on the operation requirements. Due to the astronauts and the backpack are integrated, the astronaut and the space backpack can be regarded as a whole, which will be represented by Evabag (the blue box) as shown in <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>.</p>
                <p>The AstroLimbs has two robotic limbs with six DOFs, represented by the green ellipse module units. The mechanically connected parts of the two basic module units in the series arm are regarded as a solid whole, represented by the green ellipse in <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>a. The blue circle between the two green ellipses in <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>a represents a rotational DOF. Due to the direction design of the rotational DOFs of the robotic limbs, these rotation shafts are not parallel to each other to guarantee the position and posture of the AstroLimbs’ end effector in the working space. Thus, the AstroLimbs system has 12 DOFs as a whole. The coordinate system <italic toggle="yes">XYZ</italic> serves as the world coordinate system {0} and is also the coordinate system of the ISS truss. The coordinate system {B} is fixed on the Evabag, whose origin <italic toggle="yes">O<inline-formula><mml:math id="mm55" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> coincides with the mass center of the Evabag. The plane <italic toggle="yes">Y<inline-formula><mml:math id="mm56" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic><italic toggle="yes">O<inline-formula><mml:math id="mm57" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic><italic toggle="yes">Z<inline-formula><mml:math id="mm58" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> is set as the sagittal plane of the astronaut, in which the axis <italic toggle="yes">y<inline-formula><mml:math id="mm59" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> points to the head direction of the astronaut and the axis <italic toggle="yes">z<inline-formula><mml:math id="mm60" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> points to the back of the astronaut. Therefore, based on the movement of the astronaut, the <inline-formula><mml:math id="mm61" display="block" overflow="scroll"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm62" display="block" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm63" display="block" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> refer to pitch angle, roll angle and yaw angle of the astronaut movement, respectively.</p>
                <p>Due to the fact that the simplified system has 12 DOFs, there are still six redundant DOFs when the position and direction of the two arms’ ends are determined. In order to better plan the basic moving action of the AstroLimbs and meet the astronauts’ comfortable and working needs on the truss of the ISS, it is necessary to set the basic restrictions on the movement position and posture of the astronaut-robot system during moving. These basic restrictions can be described as following:</p>
                <p>(1) The moving position of the Evabag: The projection point of the mass center <italic toggle="yes">O<inline-formula><mml:math id="mm64" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></italic> of Evabag on the corresponding work plane should be within a certain range near the middle point coordinate position of the double ends of the two robotic limbs. The ideal position is designed as:<disp-formula id="FD5-sensors-21-06305"><label>(5)</label><mml:math id="mm65" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced separators="" open="|" close="|"><mml:msubsup><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:msubsup><mml:mi>O</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <italic toggle="yes">i</italic> represents the corresponding work plane (<italic toggle="yes">i</italic> ∈ {1,2,3}), <italic toggle="yes">O</italic><inline-formula><mml:math id="mm66" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow/><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the projection point of Evabag’s mass center in the work plane <italic toggle="yes">i</italic>, <italic toggle="yes">O</italic><inline-formula><mml:math id="mm67" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow/><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the middle point coordinate position of the AstroLimbs’ two end points, <inline-formula><mml:math id="mm68" display="block" overflow="scroll"><mml:mrow><mml:mi>δ</mml:mi></mml:mrow></mml:math></inline-formula> is the allowable deviation from the center position, which is related to the values of <italic toggle="yes">a</italic>, <italic toggle="yes">b</italic>, <italic toggle="yes">c</italic> and <italic toggle="yes">d</italic> in <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>a.</p>
                <p>(2) Space for the pilot to work: A certain distance from the mass center of Evabag to the work plane should be ensured to leave space for the astronaut to move and work without restriction and interference, as shown in the <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>b. This distance should be neither too large nor small. On the one hand, it might be limited by the length of the robotic limb, but on the other, a close enough distance can increase the safety factor for the astronaut to deal with emergencies. Therefore, the space constraint for the astronaut’s movement can be expressed as:<disp-formula id="FD6-sensors-21-06305"><label>(6)</label><mml:math id="mm69" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mfenced separators="" open="|" close="|"><mml:msub><mml:mi>O</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:msubsup><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <italic toggle="yes">h</italic><inline-formula><mml:math id="mm70" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic toggle="yes">h</italic><inline-formula><mml:math id="mm71" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> stand for the lower and upper limits of the space reserved for the astronaut to work, respectively.</p>
                <p>(3) Stability of the movement: To ensure that the astronauts will not suffer from excessive pitch, roll and yaw in the process of moving, the Evabag’s movement direction can be limited as follows:<disp-formula id="FD7-sensors-21-06305"><label>(7)</label><mml:math id="mm72" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfenced open="|" close="|"><mml:mi>α</mml:mi></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∩</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfenced open="|" close="|"><mml:mi>β</mml:mi></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∩</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfenced open="|" close="|"><mml:mi>γ</mml:mi></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>γ</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <inline-formula><mml:math id="mm73" display="block" overflow="scroll"><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm74" display="block" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm75" display="block" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> refer to the pitch angle, roll angle and yaw angle of the astronaut respectively as shown in <xref rid="sensors-21-06305-f004" ref-type="fig">Figure 4</xref>a, <inline-formula><mml:math id="mm76" display="block" overflow="scroll"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm77" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm78" display="block" overflow="scroll"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm79" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm80" display="block" overflow="scroll"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="mm81" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>γ</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the corresponding restrictions of the angles that mentioned above. These three limitations will determine the attitude of the astronaut in the process of extravehicular activities.</p>
                <p>(4) Movement limitation: in the meanwhile, for each limb of the robot is composed of six basic modules connected in series, whose envelope surface has a cylindrical shape with a height of 0.1 m. So the length of each limb is 0.6 m. According to the setting of the simulation platform and the dimensions of the robot system, the AstroLimbs’ ability of moving cross the landing handles is determined. It also can be expressed by the following Equation:<disp-formula id="FD8-sensors-21-06305"><label>(8)</label><mml:math id="mm82" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfenced separators="" open="|" close="|"><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∩</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfenced separators="" open="|" close="|"><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∩</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfenced separators="" open="|" close="|"><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mfenced><mml:mo>≤</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where, <inline-formula><mml:math id="mm83" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the direction vector from the left arm end point to the right arm end point, <inline-formula><mml:math id="mm84" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm85" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm86" display="block" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>P</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> are the projection of the vector on the <italic toggle="yes">x</italic>, <italic toggle="yes">y</italic> and <italic toggle="yes">z</italic> axes, respectively, <inline-formula><mml:math id="mm87" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm88" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm89" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the basic preset moving span in the three-axis directions, <italic toggle="yes">N</italic><inline-formula><mml:math id="mm90" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">N</italic><inline-formula><mml:math id="mm91" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <italic toggle="yes">N</italic><inline-formula><mml:math id="mm92" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the maximal interval value of the footholds (<italic toggle="yes">N</italic><inline-formula><mml:math id="mm93" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 12, <italic toggle="yes">N</italic><inline-formula><mml:math id="mm94" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 5 and <italic toggle="yes">N</italic><inline-formula><mml:math id="mm95" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = 4.5).</p>
                <p>Based on Vrep simulation platform, combined with the motion constraints of the robotic joints, the basic moving actions for the AstroLimbs can be planned according to the Equations (<xref rid="FD1-sensors-21-06305" ref-type="disp-formula">1</xref>)–(<xref rid="FD8-sensors-21-06305" ref-type="disp-formula">8</xref>). In the meantime, through the inverse kinematics solution, the movement angles of each joint corresponding to the basic moving actions can be obtained. In order to give the AstroLimbs the capability of moving smoothly, the moving position, velocity and acceleration of the joints are planned. Considering that there are two kinds of motion modes in the process of moving on the truss, one is the continuous motion between each step, and the other will stop at a certain foothold for some time and then perform the next step. As the requirement for the former mode is more demanding, trajectory planning for the continuous movement will be considered. In order to ensure the continuity of each step and the stability of the moving action switching, the velocity <italic toggle="yes">V</italic><inline-formula><mml:math id="mm96" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, acceleration <italic toggle="yes">A</italic><inline-formula><mml:math id="mm97" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of the AstroLimbs’ moving end on each landing point are set to zero. The maximal velocity <italic toggle="yes">V</italic><inline-formula><mml:math id="mm98" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (90<inline-formula><mml:math id="mm99" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s) and maximal acceleration <italic toggle="yes">A</italic><inline-formula><mml:math id="mm100" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (20<inline-formula><mml:math id="mm101" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s<inline-formula><mml:math id="mm102" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>) are also limited.</p>
              </sec>
            </sec>
            <sec id="sec4-sensors-21-06305">
              <title>4. Simulation and Results</title>
              <sec id="sec4dot1-sensors-21-06305">
                <title>4.1. Construction of Simulation Environment</title>
                <p>According to the working environment designed in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>c,d, the integrated platform involving the astronaut, the robotic limb and working environment is further simplified based on the Vrep simulation environment. <xref rid="sensors-21-06305-f005" ref-type="fig">Figure 5</xref> shows the front view and side view of the simplified simulation platform. The three visible surfaces of the truss are work plane 1, work plane 2 and work plane 3. The work plane 2 is the front view plane, the work plane 1 and work plane 3 are distributed 120<inline-formula><mml:math id="mm103" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> apart from work plane 2. The astronaut and the AstroLimbs can move, climb and work on the three planes. The dimension parameters are shown in the work plane 2, the span of two neighboring handles is 0.71 m in the <italic toggle="yes">Y</italic>-axis direction, and it is 0.6 m in the <italic toggle="yes">X</italic>-axis direction. The dimension parameters setting is also suitable for the work plane 1 and work plane 3. These distance parameters are estimated according to the proportional relationship between the ISS and astronauts, as shown in <xref rid="sensors-21-06305-f001" ref-type="fig">Figure 1</xref>b. This paper aims to verify the principle of the proposed method with the developed AstroLimbs, which will not be affected seriously by the actual size of the work scene. Relevant practical parameters will be confirmed facing future manned space application.</p>
              </sec>
              <sec id="sec4dot2-sensors-21-06305">
                <title>4.2. Training Results and Evaluation</title>
                <p>For the training process, the robot is reset to be in the position of State1 (i.e., the starting point of the task). Thus, the end of left arm will be set in State1, and the end of right arm is in State2. Then the target point of this task is always fixed in State30. The robot will start from the initial point and move two robotic limbs alternately. Each movement will be recorded as one step. When the robot reaches the target point, it completes this training successfully. The number of training times is designed to be 1000. During the training process, the number of steps required to reach the target point should be recorded. In the meanwhile, the cumulative reward of each training episode will also be focused on. The training results can be seen in <xref rid="sensors-21-06305-f006" ref-type="fig">Figure 6</xref> and <xref rid="sensors-21-06305-f007" ref-type="fig">Figure 7</xref>.</p>
                <p><xref rid="sensors-21-06305-f006" ref-type="fig">Figure 6</xref> shows the steps that AstroLimbs needed to reach the final target. The horizontal ordinate stands for the training times and the vertical ordinate represents the step number required to reach the target point for each training episode. Once the robot moves out of bounds, it will be regarded as the failure of this training task and the robot will be reset to the starting point. In this situation, there is no definite number of steps to finish the moving task. That is to say, there are two possible results for the training. One is abnormal movement in which the AstroLimbs might go out of the boundary and fail to reach the target. The other is reaching the goal successfully. As shown in <xref rid="sensors-21-06305-f008" ref-type="fig">Figure 8</xref>, the blue area on the left represents training failure, and the red area on the right represents training success. During the first 1–395 training episodes, the AstroLimbs failed to get to the target. After 395 failures, the robot can reach the target point successfully on the 396th training and performed well after that.</p>
                <p>At the beginning of the training process, the robot is still an inexperienced agent who knows nothing about the surrounding environment. Thus, it will need a certain amount of trial trainings to accumulate the basic experience, which is more likely to step out of the prescribed bounds and fail to reach the target position. In this stage, the steps to reach the target is defined to be the number of moving steps before the failure. It can be seen from the figure that the value is between 4–180, and the data trend is to increase slowly and then decrease. After a variety of failing trials, the number of steps required in the process of 396–430 training times is gradually decreasing. At this stage, the robot has accumulated a certain amount of experience by the earlier trails. Based on this experience, the robot has acquired the ability to understand the environment to some extent and has the chance to finish the task successfully. Thus, the steps needed to reach the target point will decrease.</p>
                <p>However, it has not yet converged in this stage. After more than 430 times of training, the steps required for the robot decrease to the bottom and keep stable on the value 11. Due to the <inline-formula><mml:math id="mm104" display="block" overflow="scroll"><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula>-greedy strategy, the robot still maintains a certain exploration ability in the later stage of the training process. Although the robot has obtained a route to the target point, it will still choose to explore new action sequence with a certain probability. Hence, there is still a small fluctuation of the convergence step number around the value 11, which has no effect on the step number convergence of the whole training process. It serves as the minimal step number the robot need to get the State30 from State1. The corresponding action sequence enables the robot to move autonomously towards to the finishing point.</p>
                <p><xref rid="sensors-21-06305-f007" ref-type="fig">Figure 7</xref> shows the cumulative reward value obtained by each training episode for the robot. Corresponding to <xref rid="sensors-21-06305-f006" ref-type="fig">Figure 6</xref>, taking the 396th training as the boundary, it can also be divided into the blue area of failure and the red area of success. It can be seen from <xref rid="sensors-21-06305-f007" ref-type="fig">Figure 7</xref> that for the first 430 training episodes, the cumulative reward obtained by the robot gradually increases from −50 to 50 ignoring small fluctuations, where the reward is consistent with the setting value. After 430 times of training, the cumulative reward fluctuates slightly, but still tends to be stable. The robot gradually understands the environmental information and acquires the ability to choose the appropriate action.</p>
                <p>In addition, based on the training results, the autonomous movement ability should be evaluated as well. State30 is the final target point, and the initial positions are set to be from State1 to State30, successively. During this evaluation process, whether the robot can reach the final target point successfully will be recorded. If it can reach the target point, the steps of the robot’s autonomous movement will also be preserved, which can be introduced as the evaluation criterion of the learning result. The results are shown in <xref rid="sensors-21-06305-f008" ref-type="fig">Figure 8</xref>. In the process of autonomous moving ability evaluation, the initial position state of the robot is set as the position of the left arm end. It is similar for the right arm end. Thus, only the former condition will be taken as a representative for further analysis. Besides, only one limited section of the ISS truss structure is intercepted as the training environment, which can be sufficient to verify the proposed learning method. The positions of State8, State16 and State24 are the right boundary of the training environment. When the end of the robot is within the three positions, the robot will move out of the training boundary after taking the next action. Therefore, to carry out the evaluation normally as well, we set the position of the right arm end as its state. The movement results of these three special positions are marked by blue columns in the <xref rid="sensors-21-06305-f008" ref-type="fig">Figure 8</xref>. In addition, when in State30, the robot does not need to perform any action to achieve the goal, the number of steps is recorded to be zero.</p>
                <p>Thus, the final results of the evaluation are shown in <xref rid="sensors-21-06305-f008" ref-type="fig">Figure 8</xref>. It is obvious that the robot succeeds in getting to the final target point from any position point. The corresponding number of steps required is 0–11, and the actual success rate is 100%. According to the evaluating results, as the distance between State1 and final target point is the farthest, it will take up to 11 steps to reach State30 from State1. The State24, State28 and State29 are closer to the final target point, thus only one step is needed. Comparing the state position and the relative step number the robot needed, there are some intrinsic relations between these two parts. According to the state definition in <xref rid="sensors-21-06305-f003" ref-type="fig">Figure 3</xref>, State1–State8 belong to work plane 3, State9–State16 belong to the lower part of work plane 2, State17–State22 belong to the upper part of work plane 2 and State23–State30 belong to work plane 1. From the variation trend of the required steps in the <xref rid="sensors-21-06305-f008" ref-type="fig">Figure 8</xref>, it can be found that for different parts of the work plane, the trend of the required steps from left to right varies similarly. Taking State1–State8 as an example, State1 has the largest number of steps. From State2 to State6 shows a declining trend gradually. Then State7 will increase and State8 turns to be the smallest. This trend of variation is related to the position of the state point in the x-axis direction. The closer to the final target place in the x-axis direction, the fewer steps are needed. Although the foothold in the middle of the work plane of the space station truss is closer to the target point than the state point with smaller number in the same plane, its step number will also increase due to the particularity of its position. The footholds in this kind of position, which have fewer close neighboring counterparts. These state points can be regarded as footholds with obstacle attribute, which will not be easy for the robot to pass, so it needs more steps.</p>
                <p>According to the analysis of the training results and evaluation, through Q-learning algorithm, the robot gradually learns the state determination, optional position identification, environment boundary identification, task target confirmation and autonomous motion planning. Therefore, the target oriented autonomous motion ability on the ISS truss is obtained by the robot.</p>
              </sec>
              <sec id="sec4dot3-sensors-21-06305">
                <title>4.3. Simulation Result</title>
                <p>Based on the mechanical design of the AstroLimbs, the construction of the simplified working structure and the establishment of the autonomous motion training mechanism, the training process for the AstroLimbs is carried out. In the meanwhile, the training process is also described in detail as follows. Due to the fact that the astronaut and backpack are connected together, the backpack (Evabag) will be used to replace the astronaut-backpack integrated system, which will have no effect on the final results and can obtain higher simulation efficiency.</p>
                <p>All the moving actions that AstroLimbs has taken during the training process derives from the planning based on the Equations (<xref rid="FD5-sensors-21-06305" ref-type="disp-formula">5</xref>)–(8). The autonomous movement process of the AstroLimbs from the State1 to the target is shown in the <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>.</p>
                <p>Through 1000 iterations of simulation training, the AstroLimbs system can obtain the ability of autonomous movement under the task goal orientation. The training result is shown in <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>a–l, which is the decomposition diagram of the autonomous movement of AstroLimbs from the initial place after the simulation training. Taking <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>b as an example, it represents that the robot takes the first action from the initial position and its current state (<italic toggle="yes">state</italic><inline-formula><mml:math id="mm105" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow/><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) turns to be State2. Similarly, <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>c–l correspond to the state of the AstroLimbs after taking each action. For example, due to <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>c, the left arm end is the last moved end, which has step into the point of State2. The AstroLimbs moves its double arms by turns and reaches the final target within 11 steps from the starting point. In the meanwhile, by connecting the state points that the robot has passed, we can obtain the route of autonomous movement, as shown in <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>l. This route colored by red is chose by the AstroLimbs itself after the training. According to <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>l, the robot moves along the direction of the connecting line between the starting point and the final target, and the route formed by the selected action sequence is short and reasonable.</p>
                <p>During the moving process, each joint movement of the robot has been recorded in order to evaluate the motion performance. The motion from State20 to State23 of the robot will be explained in detail, as shown in <xref rid="sensors-21-06305-f009" ref-type="fig">Figure 9</xref>e,i. In this process, the right end remains stationary, and the left end moves from work plane 2 to work plane 1. It enables the robot system to complete the conversion of work platform. The corresponding action is 11 according to <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>. It is more difficult for the robot to move to a new work plane than working in the same one. Thus, this moving process is taken as an example to evaluate the motion performance of robot. The variations of each joint’s position, velocity and acceleration are shown in <xref rid="sensors-21-06305-f010" ref-type="fig">Figure 10</xref>, <xref rid="sensors-21-06305-f011" ref-type="fig">Figure 11</xref> and <xref rid="sensors-21-06305-f012" ref-type="fig">Figure 12</xref>, respectively.</p>
                <p>According to the motion planning, in order to make the motion relatively stable, the maximum angular velocity and acceleration of each joint are limited. The maximum angular velocity is limited to 90<inline-formula><mml:math id="mm106" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s, and the maximum angular acceleration is limited to 20<inline-formula><mml:math id="mm107" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s<inline-formula><mml:math id="mm108" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. In the meanwhile, when in the starting or ending point, the angular velocity and acceleration of each joint are set to be zero. Thus, the robot joints will not produce excessive impact. According to the <xref rid="sensors-21-06305-f010" ref-type="fig">Figure 10</xref>, <xref rid="sensors-21-06305-f011" ref-type="fig">Figure 11</xref> and <xref rid="sensors-21-06305-f012" ref-type="fig">Figure 12</xref>, the solid lines stand for Joint1–Joint6, which corresponds to the left limb. Similarly, the dashed lines represent Joint 7–Joint 12 of the right limb. The total moving time for this process is 6.5 s. The rotation range of each joint is −180–180<inline-formula><mml:math id="mm109" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> based on the basic module. As shown in <xref rid="sensors-21-06305-f010" ref-type="fig">Figure 10</xref>, the minimum rotation angle is 2.1<inline-formula><mml:math id="mm110" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> that occurs in Joint9. The maximum rotation angle is 203.6<inline-formula><mml:math id="mm111" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> that belongs to Joint 7. It does not exceed the setting rotation range of the each joint, which can meet the requirements.</p>
                <p>As shown in <xref rid="sensors-21-06305-f011" ref-type="fig">Figure 11</xref>, the minimum angular velocity is 6.3<inline-formula><mml:math id="mm112" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s at Joint9 and the maximum is 63.5<inline-formula><mml:math id="mm113" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s at Joint7, which also is consistent with the situation of joint angles. The curve of angular velocity is isosceles triangle, namely its motion process is divided into two stages with equal time. The velocity in the former stage increases uniformly to the maximum, and then it decreases uniformly to zero in the latter stage. The maximum velocity appears at the midpoint of the whole motion. In this way, it ensures the stability of the former and latter half of the motion and the robot approaches the target point slowly at the same time. According to <xref rid="sensors-21-06305-f012" ref-type="fig">Figure 12</xref>, the maximum angular acceleration of each joint is 20<inline-formula><mml:math id="mm114" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>/s<inline-formula><mml:math id="mm115" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> as limited. Based on the variation demand of angular velocity, trapezoidal acceleration planning is adopted. When reaching the target point, the angular acceleration is reduced to zero to prevent collision with the handle on the work plane. In this paper, for the moving process on the ISS, the main goal is to ensure motion stability without pursuing excessively high velocity.The angular velocity and acceleration values of each joint are not set to be too large. In the future research, the robot motion will be further planned and optimized to fit actual application.</p>
              </sec>
            </sec>
            <sec sec-type="conclusions" id="sec5-sensors-21-06305">
              <title>5. Conclusions</title>
              <p>In this paper, a wearable robotic limbs system for astronaut has been proposed to assist the astronauts moving and working outside the space station cabin. For better service in the manned space field, the basic module units of robot are manufactured based on the modular design concept. Besides, the robot is trained to move autonomously by using reinforcement learning method. After the training, the acquisition skills of the robot are evaluated by setting the initial place randomly. For all the state points, the robot succeeds in moving autonomously from any starting place to the final target point. In the meanwhile, the basic moving actions of the robot are planned considering the motion stability and working comfort of the astronaut. In addition, a simulation platform of the robot and truss of ISS are built in the Vrep environment. The results of the reinforcement learning method and moving performance of the robot are verified in the simulation environment, which indicates the effectiveness of the reinforcement learning method for the robot to obtain the autonomous mobility towards the task target.</p>
              <p>In future, the robot will be trained to adapt to the complex and changeable space environment. Combined with the prototype of the AstroLimbs, its motion assisting ability will be further verified in the low microgravity environment on the ground, which will provide ground test data for future application in outer space.</p>
            </sec>
          </body>
          <back>
            <fn-group>
              <fn>
                <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
              </fn>
            </fn-group>
            <notes>
              <title>Author Contributions</title>
              <p>Conceptualization, S.Z., J.Z. and Y.Z.; methodology, S.Z., J.Z. and Y.Z.; software, S.Z., D.S. and T.W.; validation, J.Z., T.Z. and Y.Z.; writing—original draft preparation, S.Z. and J.Z.; writing—review and editing, D.S., T.W., T.Z., C.Z. and Y.Z.; supervision, J.Z. and Y.Z. All authors have read and agreed to the published version of the manuscript.</p>
            </notes>
            <notes>
              <title>Funding</title>
              <p>This research was funded by the National Natural Science Foundation of China (NSFC) for Distinguished Young Scholars (No.52025054), and NSFC-Shenzhen Robotics Research Center Project (U1713201 &amp; U2013207).</p>
            </notes>
            <notes>
              <title>Institutional Review Board Statement</title>
              <p>Not applicable.</p>
            </notes>
            <notes>
              <title>Informed Consent Statement</title>
              <p>Not applicable.</p>
            </notes>
            <notes notes-type="data-availability">
              <title>Data Availability Statement</title>
              <p>The data supporting reported results can be obtained in this article.</p>
            </notes>
            <notes notes-type="COI-statement">
              <title>Conflicts of Interest</title>
              <p>The authors declare no conflict of interest.</p>
            </notes>
            <ref-list>
              <title>References</title>
              <ref id="B1-sensors-21-06305">
                <label>1.</label>
                <element-citation publication-type="webpage">
                  <article-title>SpaceX</article-title>
                  <comment>Available online: <ext-link xlink:href="https://www.spacex.com/" ext-link-type="uri">https://www.spacex.com/</ext-link></comment>
                  <date-in-citation content-type="access-date" iso-8601-date="2021-09-20">(accessed on 20 September 2021)</date-in-citation>
                </element-citation>
              </ref>
              <ref id="B2-sensors-21-06305">
                <label>2.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jacobstein</surname>
                      <given-names>N.</given-names>
                    </name>
                    <name>
                      <surname>Bellingham</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Yang</surname>
                      <given-names>G.Z.</given-names>
                    </name>
                  </person-group>
                  <article-title>Robotics for space and marine sciences</article-title>
                  <source>Sci. Robot.</source>
                  <year>2017</year>
                  <volume>2</volume>
                  <fpage>5594</fpage>
                  <pub-id pub-id-type="doi">10.1126/scirobotics.aan5594</pub-id>
                  <?supplied-pmid 33157902?>
                  <pub-id pub-id-type="pmid">33157902</pub-id>
                </element-citation>
              </ref>
              <ref id="B3-sensors-21-06305">
                <label>3.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Chien</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Wagstaff</surname>
                      <given-names>K.L.</given-names>
                    </name>
                  </person-group>
                  <article-title>Robotic space exploration agents</article-title>
                  <source>Sci. Robot.</source>
                  <year>2017</year>
                  <volume>2</volume>
                  <fpage>4831</fpage>
                  <pub-id pub-id-type="doi">10.1126/scirobotics.aan4831</pub-id>
                  <?supplied-pmid 33157898?>
                  <pub-id pub-id-type="pmid">33157898</pub-id>
                </element-citation>
              </ref>
              <ref id="B4-sensors-21-06305">
                <label>4.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lester</surname>
                      <given-names>D.F.</given-names>
                    </name>
                    <name>
                      <surname>Hodges</surname>
                      <given-names>K.V.</given-names>
                    </name>
                    <name>
                      <surname>Anderson</surname>
                      <given-names>R.C.</given-names>
                    </name>
                  </person-group>
                  <article-title>Exploration telepresence: A strategy for optimizing scientific research at remote space destinations</article-title>
                  <source>Sci. Robot.</source>
                  <year>2017</year>
                  <volume>2</volume>
                  <fpage>4383</fpage>
                  <pub-id pub-id-type="doi">10.1126/scirobotics.aan4383</pub-id>
                  <?supplied-pmid 33157896?>
                  <pub-id pub-id-type="pmid">33157896</pub-id>
                </element-citation>
              </ref>
              <ref id="B5-sensors-21-06305">
                <label>5.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Jiang</surname>
                      <given-names>H.</given-names>
                    </name>
                    <name>
                      <surname>Hawkes</surname>
                      <given-names>E.W.</given-names>
                    </name>
                    <name>
                      <surname>Fuller</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Estrada</surname>
                      <given-names>M.A.</given-names>
                    </name>
                    <name>
                      <surname>Suresh</surname>
                      <given-names>S.A.</given-names>
                    </name>
                    <name>
                      <surname>Abcouwer</surname>
                      <given-names>N.</given-names>
                    </name>
                    <name>
                      <surname>Han</surname>
                      <given-names>A.K.</given-names>
                    </name>
                    <name>
                      <surname>Wang</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Ploch</surname>
                      <given-names>C.J.</given-names>
                    </name>
                    <name>
                      <surname>Parness</surname>
                      <given-names>A.</given-names>
                    </name>
                    <etal/>
                  </person-group>
                  <article-title>A robotic device using gecko-inspired adhesives can grasp and manipulate large objects in microgravity</article-title>
                  <source>Sci. Robot.</source>
                  <year>2017</year>
                  <volume>2</volume>
                  <fpage>4545</fpage>
                  <pub-id pub-id-type="doi">10.1126/scirobotics.aan4545</pub-id>
                  <?supplied-pmid 33157899?>
                  <pub-id pub-id-type="pmid">33157899</pub-id>
                </element-citation>
              </ref>
              <ref id="B6-sensors-21-06305">
                <label>6.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Check</surname>
                      <given-names>E.</given-names>
                    </name>
                  </person-group>
                  <article-title>BioShield defence programme set to fund anthrax vaccine</article-title>
                  <source>Nature</source>
                  <year>2004</year>
                  <volume>429</volume>
                  <fpage>4</fpage>
                  <pub-id pub-id-type="doi">10.1038/429004a</pub-id>
                  <?supplied-pmid 15129240?>
                  <pub-id pub-id-type="pmid">15129240</pub-id>
                </element-citation>
              </ref>
              <ref id="B7-sensors-21-06305">
                <label>7.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Seedhouse</surname>
                      <given-names>E.</given-names>
                    </name>
                  </person-group>
                  <source>Life Support Systems for Humans in Space</source>
                  <publisher-name>Springer</publisher-name>
                  <publisher-loc>Berlin/Heidelberg, Germany</publisher-loc>
                  <year>2020</year>
                  <pub-id pub-id-type="doi">10.1007/978-3-030-52859-1</pub-id>
                </element-citation>
              </ref>
              <ref id="B8-sensors-21-06305">
                <label>8.</label>
                <element-citation publication-type="webpage">
                  <article-title>Challenges of Spacewalking—Rick Mastracchio</article-title>
                  <comment>Available online: <ext-link xlink:href="https://www.youtube.com/watch?v=rA42dewZLwg" ext-link-type="uri">https://www.youtube.com/watch?v=rA42dewZLwg</ext-link></comment>
                  <date-in-citation content-type="access-date" iso-8601-date="2021-09-20">(accessed on 20 September 2021)</date-in-citation>
                </element-citation>
              </ref>
              <ref id="B9-sensors-21-06305">
                <label>9.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Nokleby</surname>
                      <given-names>S.B.</given-names>
                    </name>
                  </person-group>
                  <article-title>Singularity analysis of the Canadarm2</article-title>
                  <source>Mech. Mach. Theory</source>
                  <year>2007</year>
                  <volume>42</volume>
                  <fpage>442</fpage>
                  <lpage>454</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.mechmachtheory.2006.04.004</pub-id>
                </element-citation>
              </ref>
              <ref id="B10-sensors-21-06305">
                <label>10.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Abramovici</surname>
                      <given-names>A.</given-names>
                    </name>
                  </person-group>
                  <source>A Successful Exercise in Cheaper, Faster and (Hopefully) Better Systems Engineering</source>
                  <publisher-name>Springer</publisher-name>
                  <publisher-loc>Berlin/Heidelberg, Germany</publisher-loc>
                  <year>2000</year>
                  <fpage>177</fpage>
                  <lpage>200</lpage>
                </element-citation>
              </ref>
              <ref id="B11-sensors-21-06305">
                <label>11.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bluethmann</surname>
                      <given-names>W.</given-names>
                    </name>
                    <name>
                      <surname>Ambrose</surname>
                      <given-names>R.</given-names>
                    </name>
                    <name>
                      <surname>Diftler</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Askew</surname>
                      <given-names>S.</given-names>
                    </name>
                    <name>
                      <surname>Huber</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Goza</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Rehnmark</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Lovchik</surname>
                      <given-names>C.</given-names>
                    </name>
                    <name>
                      <surname>Magruder</surname>
                      <given-names>D.</given-names>
                    </name>
                  </person-group>
                  <article-title>Robonaut: A robot designed to work with humans in space</article-title>
                  <source>Auton. Robot.</source>
                  <year>2003</year>
                  <volume>14</volume>
                  <fpage>179</fpage>
                  <lpage>197</lpage>
                  <pub-id pub-id-type="doi">10.1023/A:1022231703061</pub-id>
                  <?supplied-pmid 12703513?>
                  <pub-id pub-id-type="pmid">12703513</pub-id>
                </element-citation>
              </ref>
              <ref id="B12-sensors-21-06305">
                <label>12.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Diftler</surname>
                      <given-names>M.A.</given-names>
                    </name>
                    <name>
                      <surname>Mehling</surname>
                      <given-names>J.S.</given-names>
                    </name>
                    <name>
                      <surname>Abdallah</surname>
                      <given-names>M.E.</given-names>
                    </name>
                    <name>
                      <surname>Radford</surname>
                      <given-names>N.A.</given-names>
                    </name>
                    <name>
                      <surname>Bridgwater</surname>
                      <given-names>L.B.</given-names>
                    </name>
                    <name>
                      <surname>Sanders</surname>
                      <given-names>A.M.</given-names>
                    </name>
                    <name>
                      <surname>Askew</surname>
                      <given-names>R.S.</given-names>
                    </name>
                    <name>
                      <surname>Linn</surname>
                      <given-names>D.M.</given-names>
                    </name>
                    <name>
                      <surname>Yamokoski</surname>
                      <given-names>J.D.</given-names>
                    </name>
                    <name>
                      <surname>Permenter</surname>
                      <given-names>F.A.</given-names>
                    </name>
                  </person-group>
                  <article-title>Robonaut 2—The first humanoid robot in space</article-title>
                  <source>Proceedings of the 2011 IEEE International Conference on Robotics and Automation</source>
                  <conf-loc>Shanghai, China</conf-loc>
                  <conf-date>9–13 May 2011</conf-date>
                  <fpage>2178</fpage>
                  <lpage>2183</lpage>
                  <pub-id pub-id-type="doi">10.1109/ICRA.2011.5979830</pub-id>
                </element-citation>
              </ref>
              <ref id="B13-sensors-21-06305">
                <label>13.</label>
                <element-citation publication-type="webpage">
                  <article-title>Skybot F-850</article-title>
                  <comment>Available online: <ext-link xlink:href="https://spectrum.ieee.org/russian-humanoid-robot-to-pilot-soyuz-capsule-to-iss-this-week" ext-link-type="uri">https://spectrum.ieee.org/russian-humanoid-robot-to-pilot-soyuz-capsule-to-iss-this-week</ext-link></comment>
                  <date-in-citation content-type="access-date" iso-8601-date="2021-09-20">(accessed on 20 September 2021)</date-in-citation>
                </element-citation>
              </ref>
              <ref id="B14-sensors-21-06305">
                <label>14.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Zykov</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Mytilinaios</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Desnoyer</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>Lipson</surname>
                      <given-names>H.</given-names>
                    </name>
                  </person-group>
                  <article-title>Evolved and Designed Self-Reproducing Modular Robotics</article-title>
                  <source>IEEE Trans. Robot.</source>
                  <year>2007</year>
                  <volume>23</volume>
                  <fpage>308</fpage>
                  <lpage>319</lpage>
                  <pub-id pub-id-type="doi">10.1109/TRO.2007.894685</pub-id>
                </element-citation>
              </ref>
              <ref id="B15-sensors-21-06305">
                <label>15.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Hoyt</surname>
                      <given-names>R.P.</given-names>
                    </name>
                    <name>
                      <surname>Cushing</surname>
                      <given-names>J.I.</given-names>
                    </name>
                    <name>
                      <surname>Slostad</surname>
                      <given-names>J.T.</given-names>
                    </name>
                    <name>
                      <surname>Jimmerson</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Moser</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Kirkos</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>Jaster</surname>
                      <given-names>M.L.</given-names>
                    </name>
                    <name>
                      <surname>Voronka</surname>
                      <given-names>N.R.</given-names>
                    </name>
                  </person-group>
                  <article-title>SpiderFab: An Architecture for Self—Fabricating Space Systems</article-title>
                  <source>Proceedings of the AIAA SPACE 2013 Conference and Exposition</source>
                  <conf-loc>San Diego, CA, USA</conf-loc>
                  <conf-date>10 September 2013</conf-date>
                  <fpage>1</fpage>
                  <lpage>17</lpage>
                  <pub-id pub-id-type="doi">10.2514/6.2013-5509</pub-id>
                </element-citation>
              </ref>
              <ref id="B16-sensors-21-06305">
                <label>16.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bongard</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Zykov</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Lipson</surname>
                      <given-names>H.</given-names>
                    </name>
                  </person-group>
                  <article-title>Resilient machines through continuous self-modeling</article-title>
                  <source>Science</source>
                  <year>2006</year>
                  <volume>314</volume>
                  <fpage>1118</fpage>
                  <lpage>1121</lpage>
                  <pub-id pub-id-type="doi">10.1126/science.1133687</pub-id>
                  <?supplied-pmid 17110570?>
                  <pub-id pub-id-type="pmid">17110570</pub-id>
                </element-citation>
              </ref>
              <ref id="B17-sensors-21-06305">
                <label>17.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Cully</surname>
                      <given-names>A.</given-names>
                    </name>
                    <name>
                      <surname>Clune</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Tarapore</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Mouret</surname>
                      <given-names>J.B.</given-names>
                    </name>
                  </person-group>
                  <article-title>Robots that can adapt like animals</article-title>
                  <source>Nature</source>
                  <year>2015</year>
                  <volume>521</volume>
                  <fpage>503</fpage>
                  <lpage>507</lpage>
                  <pub-id pub-id-type="doi">10.1038/nature14422</pub-id>
                  <?supplied-pmid 26017452?>
                  <pub-id pub-id-type="pmid">26017452</pub-id>
                </element-citation>
              </ref>
              <ref id="B18-sensors-21-06305">
                <label>18.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Lan</surname>
                      <given-names>G.</given-names>
                    </name>
                    <name>
                      <surname>De Carlo</surname>
                      <given-names>M.</given-names>
                    </name>
                    <name>
                      <surname>van Diggelen</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Tomczak</surname>
                      <given-names>J.M.</given-names>
                    </name>
                    <name>
                      <surname>Roijers</surname>
                      <given-names>D.M.</given-names>
                    </name>
                    <name>
                      <surname>Eiben</surname>
                      <given-names>A.</given-names>
                    </name>
                  </person-group>
                  <article-title>Learning directed locomotion in modular robots with evolvable morphologies</article-title>
                  <source>Appl. Soft Comput.</source>
                  <year>2021</year>
                  <volume>111</volume>
                  <fpage>107688</fpage>
                  <pub-id pub-id-type="doi">10.1016/j.asoc.2021.107688</pub-id>
                </element-citation>
              </ref>
              <ref id="B19-sensors-21-06305">
                <label>19.</label>
                <element-citation publication-type="book">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Eiben</surname>
                      <given-names>A.E.</given-names>
                    </name>
                    <name>
                      <surname>Hart</surname>
                      <given-names>E.</given-names>
                    </name>
                    <name>
                      <surname>Timmis</surname>
                      <given-names>J.</given-names>
                    </name>
                    <name>
                      <surname>Tyrrell</surname>
                      <given-names>A.M.</given-names>
                    </name>
                    <name>
                      <surname>Winfield</surname>
                      <given-names>A.F.</given-names>
                    </name>
                  </person-group>
                  <article-title>Towards Autonomous Robot Evolution</article-title>
                  <source>Software Engineering for Robotics</source>
                  <publisher-name>Springer</publisher-name>
                  <publisher-loc>Berlin/Heidelberg, Germany</publisher-loc>
                  <year>2021</year>
                  <fpage>29</fpage>
                  <lpage>51</lpage>
                  <pub-id pub-id-type="doi">10.1007/978-3-030-66494-7_2</pub-id>
                </element-citation>
              </ref>
              <ref id="B20-sensors-21-06305">
                <label>20.</label>
                <element-citation publication-type="gov">
                  <article-title>NASA’s Ironman</article-title>
                  <comment>Available online: <ext-link xlink:href="https://www.nasa.gov/offices/oct/home/feature_exoskeleton.html" ext-link-type="uri">https://www.nasa.gov/offices/oct/home/feature_exoskeleton.html</ext-link></comment>
                  <date-in-citation content-type="access-date" iso-8601-date="2021-09-20">(accessed on 20 September 2021)</date-in-citation>
                </element-citation>
              </ref>
              <ref id="B21-sensors-21-06305">
                <label>21.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Parietti</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Chan</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Asada</surname>
                      <given-names>H.H.</given-names>
                    </name>
                  </person-group>
                  <article-title>Bracing the human body with supernumerary Robotic Limbs for physical assistance and load reduction</article-title>
                  <source>Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)</source>
                  <conf-loc>Hong Kong, China</conf-loc>
                  <conf-date>31 May–7 June 2014</conf-date>
                  <fpage>141</fpage>
                  <lpage>148</lpage>
                  <pub-id pub-id-type="doi">10.1109/ICRA.2014.6906601</pub-id>
                </element-citation>
              </ref>
              <ref id="B22-sensors-21-06305">
                <label>22.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Parietti</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Asada</surname>
                      <given-names>H.H.</given-names>
                    </name>
                  </person-group>
                  <article-title>Supernumerary robotic limbs for human body support</article-title>
                  <source>IEEE Trans. Robot.</source>
                  <year>2016</year>
                  <volume>32</volume>
                  <fpage>301</fpage>
                  <lpage>311</lpage>
                  <pub-id pub-id-type="doi">10.1109/TRO.2016.2520486</pub-id>
                </element-citation>
              </ref>
              <ref id="B23-sensors-21-06305">
                <label>23.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Parietti</surname>
                      <given-names>F.</given-names>
                    </name>
                    <name>
                      <surname>Asada</surname>
                      <given-names>H.H.</given-names>
                    </name>
                  </person-group>
                  <article-title>Supernumerary robotic limbs for aircraft fuselage assembly: Body stabilization and guidance by bracing</article-title>
                  <source>Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)</source>
                  <conf-loc>Hong Kong, China</conf-loc>
                  <conf-date>31 May–7 June 2014</conf-date>
                  <fpage>1176</fpage>
                  <lpage>1183</lpage>
                  <pub-id pub-id-type="doi">10.1109/ICRA.2014.6907002</pub-id>
                </element-citation>
              </ref>
              <ref id="B24-sensors-21-06305">
                <label>24.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Bonilla</surname>
                      <given-names>B.L.</given-names>
                    </name>
                    <name>
                      <surname>Asada</surname>
                      <given-names>H.H.</given-names>
                    </name>
                  </person-group>
                  <article-title>A robot on the shoulder: Coordinated human-wearable robot control using Coloured Petri Nets and Partial Least Squares predictions</article-title>
                  <source>Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)</source>
                  <conf-loc>Hong Kong, China</conf-loc>
                  <conf-date>31 May–7 June 2014</conf-date>
                  <fpage>119</fpage>
                  <lpage>125</lpage>
                  <pub-id pub-id-type="doi">10.1109/ICRA.2014.6906598</pub-id>
                </element-citation>
              </ref>
              <ref id="B25-sensors-21-06305">
                <label>25.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Vatsal</surname>
                      <given-names>V.</given-names>
                    </name>
                    <name>
                      <surname>Hoffman</surname>
                      <given-names>G.</given-names>
                    </name>
                  </person-group>
                  <article-title>Wearing your arm on your sleeve: Studying usage contexts for a wearable robotic forearm</article-title>
                  <source>Proceedings of the 2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</source>
                  <conf-loc>Lisbon, Portugal</conf-loc>
                  <conf-date>28 August–1 September 2017</conf-date>
                  <fpage>974</fpage>
                  <lpage>980</lpage>
                  <pub-id pub-id-type="doi">10.1109/ROMAN.2017.8172421</pub-id>
                </element-citation>
              </ref>
              <ref id="B26-sensors-21-06305">
                <label>26.</label>
                <element-citation publication-type="journal">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Gopinath</surname>
                      <given-names>D.</given-names>
                    </name>
                    <name>
                      <surname>Weinberg</surname>
                      <given-names>G.</given-names>
                    </name>
                  </person-group>
                  <article-title>A generative physical model approach for enhancing the stroke palette for robotic drummers</article-title>
                  <source>Robot. Auton. Syst.</source>
                  <year>2016</year>
                  <volume>86</volume>
                  <fpage>207</fpage>
                  <lpage>215</lpage>
                  <pub-id pub-id-type="doi">10.1016/j.robot.2016.08.020</pub-id>
                </element-citation>
              </ref>
              <ref id="B27-sensors-21-06305">
                <label>27.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sasaki</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Saraiji</surname>
                      <given-names>M.Y.</given-names>
                    </name>
                    <name>
                      <surname>Fernando</surname>
                      <given-names>C.L.</given-names>
                    </name>
                    <name>
                      <surname>Minamizawa</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Inami</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>MetaLimbs: Multiple arms interaction metamorphism</article-title>
                  <source>Proceedings of the ACM SIGGRAPH 2017 Emerging Technologies, SIGGRAPH 2017</source>
                  <conf-loc>Los Angeles, CA, USA</conf-loc>
                  <conf-date>30 July–3 August 2017</conf-date>
                  <fpage>1</fpage>
                  <lpage>3</lpage>
                  <pub-id pub-id-type="doi">10.1145/3084822.3084837</pub-id>
                </element-citation>
              </ref>
              <ref id="B28-sensors-21-06305">
                <label>28.</label>
                <element-citation publication-type="confproc">
                  <person-group person-group-type="author">
                    <name>
                      <surname>Sasaki</surname>
                      <given-names>T.</given-names>
                    </name>
                    <name>
                      <surname>Saraiji</surname>
                      <given-names>M.H.</given-names>
                    </name>
                    <name>
                      <surname>Fernando</surname>
                      <given-names>C.L.</given-names>
                    </name>
                    <name>
                      <surname>Minamizawa</surname>
                      <given-names>K.</given-names>
                    </name>
                    <name>
                      <surname>Inami</surname>
                      <given-names>M.</given-names>
                    </name>
                  </person-group>
                  <article-title>MetaLimbs: Metamorphosis for multiple arms interaction using artificial limbs</article-title>
                  <source>Proceedings of the ACM SIGGRAPH 2017 Emerging Technologies, SIGGRAPH 2017</source>
                  <conf-loc>Los Angeles, CA, USA</conf-loc>
                  <conf-date>30 July–3 August 2017</conf-date>
                  <fpage>1</fpage>
                  <lpage>2</lpage>
                  <pub-id pub-id-type="doi">10.1145/3102163.3102166</pub-id>
                </element-citation>
              </ref>
            </ref-list>
          </back>
          <floats-group>
            <fig position="float" id="sensors-21-06305-f001">
              <label>Figure 1</label>
              <caption>
                <p>Simplified environment of ISS, and the render map of the AstroLimbs. (<bold>a</bold>,<bold>b</bold>) Real scene of ISS. (<bold>c</bold>,<bold>d</bold>) Extravehicular activities on the truss of ISS. (<bold>e</bold>) Render map of the AstroLimbs.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g001" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f002">
              <label>Figure 2</label>
              <caption>
                <p>Wearable robotic limbs for astronaut extravehicular activities assistance. (<bold>a</bold>) Rotation diagram of basic module. (<bold>b</bold>) Schematic diagram of the AstroLimbs. (<bold>c</bold>) 6 DOFs configuration of the right AstroLimb. (<bold>d</bold>) Basic modules. (<bold>e</bold>) Wearing display of the AstroLimbs. (<bold>f</bold>) Reconfiguration of the AstroLimb.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g002" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f003">
              <label>Figure 3</label>
              <caption>
                <p>Determination of the AstroLimbs state. (<bold>a</bold>) Schematic diagram of operation state. (<bold>b</bold>) Determination of operation state.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g003" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f004">
              <label>Figure 4</label>
              <caption>
                <p>Simulation environment setup based in the Vrep. (<bold>a</bold>) Coordinate system setting and motion parameters of the AstroLimbs. (<bold>b</bold>) Moving state on the three different work planes of ISS.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g004" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f005">
              <label>Figure 5</label>
              <caption>
                <p>Simulation environment setup based on the Vrep.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g005" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f006">
              <label>Figure 6</label>
              <caption>
                <p>The number of steps of AstroLimbs for each training.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g006" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f007">
              <label>Figure 7</label>
              <caption>
                <p>Reward value of AstroLimbs for each training.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g007" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f008">
              <label>Figure 8</label>
              <caption>
                <p>The number of steps required for the AstroLimbs to reach the target from different state points.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g008" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f009">
              <label>Figure 9</label>
              <caption>
                <p>Sequential diagram of the autonomous movement simulation. (<bold>a</bold>) The state of the robot when standing at the initial point. (<bold>b</bold>) State after the 1st step. (<bold>c</bold>) State after the 2nd step. (<bold>d</bold>) State after the 3rd step. (<bold>e</bold>) State after the 4th step. (<bold>f</bold>) State after the 5th step.(<bold>g</bold>) State after the 6th step. (<bold>h</bold>) State after the 7th step. (<bold>i</bold>) State after the 8th step. (<bold>j</bold>) State after the 9th step. (<bold>k</bold>) State after the 10th step. (<bold>l</bold>) State after the 11th step to reach the final target.</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g009" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f010">
              <label>Figure 10</label>
              <caption>
                <p>The angle variation of each joint. (Action 9 according to <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>).</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g010" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f011">
              <label>Figure 11</label>
              <caption>
                <p>The angular velocity variation of each joint. (Action 9 according to <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>).</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g011" position="float"/>
            </fig>
            <fig position="float" id="sensors-21-06305-f012">
              <label>Figure 12</label>
              <caption>
                <p>The angular acceleration variation of each joint. (Action 9 according to <xref rid="sensors-21-06305-t001" ref-type="table">Table 1</xref>).</p>
              </caption>
              <graphic xlink:href="sensors-21-06305-g012" position="float"/>
            </fig>
            <table-wrap position="float" id="sensors-21-06305-t001">
              <object-id pub-id-type="pii">sensors-21-06305-t001_Table 1</object-id>
              <label>Table 1</label>
              <caption>
                <p>Determination of effective actions of the AstroLimbs.</p>
              </caption>
              <table frame="hsides" rules="groups">
                <thead>
                  <tr>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Eq-Coordinate</th>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Action Mode</th>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Eq-Coordinate</th>
                    <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Action Mode</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, 0, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, 1, −1}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">B</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, 0, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, −1, 1}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">C</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">3</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, 1, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">10</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, −1, 1}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">C</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">4</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, 1, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">11</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, −1, −2}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">D</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">5</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, −1, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">12</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{2, −1, −2}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">D</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" rowspan="1" colspan="1">6</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, −1, 0}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">A</italic>
                    </td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">13</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">{1, 1, 2}</td>
                    <td align="center" valign="middle" rowspan="1" colspan="1">
                      <italic toggle="yes">E</italic>
                    </td>
                  </tr>
                  <tr>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">{1, 1, −1}</td>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
                      <italic toggle="yes">B</italic>
                    </td>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">{2, 1, 2}</td>
                    <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
                      <italic toggle="yes">E</italic>
                    </td>
                  </tr>
                </tbody>
              </table>
            </table-wrap>
          </floats-group>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
