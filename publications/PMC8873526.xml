<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2023-02-23T14:48:30Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8873526" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8873526</identifier>
        <datestamp>2022-02-26</datestamp>
        <setSpec>frontphysiol</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" dtd-version="1.3" xml:lang="en" article-type="research-article">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Front Physiol</journal-id>
              <journal-id journal-id-type="iso-abbrev">Front Physiol</journal-id>
              <journal-id journal-id-type="publisher-id">Front. Physiol.</journal-id>
              <journal-title-group>
                <journal-title>Frontiers in Physiology</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1664-042X</issn>
              <publisher>
                <publisher-name>Frontiers Media S.A.</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8873526</article-id>
              <article-id pub-id-type="pmcid">PMC8873526</article-id>
              <article-id pub-id-type="pmc-uid">8873526</article-id>
              <article-id pub-id-type="pmid">35222056</article-id>
              <article-id pub-id-type="doi">10.3389/fphys.2021.751016</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Physiology</subject>
                  <subj-group>
                    <subject>Original Research</subject>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Assessment of the Psychophysiological State of Female Operators Under Simulated Microgravity</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author" corresp="yes">
                  <name>
                    <surname>Lebedeva</surname>
                    <given-names>Svetlana</given-names>
                  </name>
                  <xref rid="aff1" ref-type="aff">
                    <sup>1</sup>
                  </xref>
                  <xref rid="c001" ref-type="corresp">
                    <sup>*</sup>
                  </xref>
                  <uri xlink:href="http://loop.frontiersin.org/people/1355213/overview"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Shved</surname>
                    <given-names>Dmitry</given-names>
                  </name>
                  <xref rid="aff1" ref-type="aff">
                    <sup>1</sup>
                  </xref>
                  <xref rid="aff2" ref-type="aff">
                    <sup>2</sup>
                  </xref>
                  <uri xlink:href="http://loop.frontiersin.org/people/1207954/overview"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Savinkina</surname>
                    <given-names>Alexandra</given-names>
                  </name>
                  <xref rid="aff1" ref-type="aff">
                    <sup>1</sup>
                  </xref>
                </contrib>
              </contrib-group>
              <aff id="aff1"><sup>1</sup><institution>Russian Federation State Scientific Center, Institute of Biomedical Problems of the Russian Academy of Sciences</institution>, <addr-line>Moscow</addr-line>, <country>Russia</country></aff>
              <aff id="aff2"><sup>2</sup><institution>Moscow Aviation Institute, National Research University</institution>, <addr-line>Moscow</addr-line>, <country>Russia</country></aff>
              <author-notes>
                <fn fn-type="edited-by">
                  <p>Edited by: Floris L. Wuyts, University of Antwerp, Belgium</p>
                </fn>
                <fn fn-type="edited-by">
                  <p>Reviewed by: Thais Russomano, InnovaSpace, United Kingdom; Anna Maria Aloisi, University of Siena, Italy</p>
                </fn>
                <corresp id="c001">*Correspondence: Svetlana Lebedeva, <email>sveta-firefox@yandex.ru</email></corresp>
                <fn fn-type="other" id="fn004">
                  <p>This article was submitted to Environmental, Aviation and Space Physiology, a section of the journal Frontiers in Physiology</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>11</day>
                <month>2</month>
                <year>2022</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2021</year>
              </pub-date>
              <volume>12</volume>
              <elocation-id>751016</elocation-id>
              <history>
                <date date-type="received">
                  <day>31</day>
                  <month>7</month>
                  <year>2021</year>
                </date>
                <date date-type="accepted">
                  <day>29</day>
                  <month>12</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Copyright © 2022 Lebedeva, Shved and Savinkina.</copyright-statement>
                <copyright-year>2022</copyright-year>
                <copyright-holder>Lebedeva, Shved and Savinkina</copyright-holder>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
                </license>
              </permissions>
              <abstract>
                <p>The article describes methods of non-verbal speech characteristics analysis used to determine psychophysiological state of female subjects under simulated microgravity conditions (“dry” immersion, DI), as well as the results of the study. A number of indicators of the acute period of adaptation to microgravity conditions was described. The acute adaptation period in female subjects began earlier (evening of the 1st day of DI) and ended faster than in male ones in previous studies (2nd day of DI). This was indicated by a decrease in the level of state anxiety (STAI, <italic>p</italic> &lt; 0,05) and depression-dejection [Profile of Mood States (POMS), <italic>p</italic> &lt; 0,05], as well as a decrease in pitch (<italic>p</italic> &lt; 0,05) and voice intensity (<italic>p</italic> &lt; 0,05). In addition, women, apparently, used the “freeze” coping strategy – the proportion of neutral facial expressions on the most intense days of the experiment was at maximum. The subjects in this experiment assessed their feelings and emotions better, giving more accurate answers in self-assessment questionnaires, but at the same time tried to look and sound as calm and confident as possible, controlling their expressions. Same trends in the subjects’ cognitive performance were identified as in similar experimental conditions earlier: the subjects’ psychophysiological excitement corresponded to better performance in sensorimotor tasks. The difference was in the speed of mathematical computation: women in the present study performed the computation faster on the same days when they made fewer pauses in speech, while in men in previous experiments this relationship was inverse.</p>
              </abstract>
              <kwd-group>
                <kwd>dry immersion</kwd>
                <kwd>women</kwd>
                <kwd>ground-based model of microgravity</kwd>
                <kwd>NAIAD-2020</kwd>
                <kwd>human operator performance</kwd>
                <kwd>psychophysiological state</kwd>
                <kwd>speech analysis</kwd>
              </kwd-group>
              <funding-group>
                <award-group>
                  <funding-source id="cn001">
                    <institution-wrap>
                      <institution>Russian Academy of Sciences</institution>
                      <institution-id institution-id-type="doi">10.13039/501100002674</institution-id>
                    </institution-wrap>
                  </funding-source>
                </award-group>
              </funding-group>
              <counts>
                <fig-count count="7"/>
                <table-count count="2"/>
                <equation-count count="0"/>
                <ref-count count="51"/>
                <page-count count="11"/>
                <word-count count="7689"/>
              </counts>
            </article-meta>
          </front>
          <body>
            <sec sec-type="intro" id="S1">
              <title>Introduction</title>
              <p>In the context of the possibility of long-term flights into deep space, new approaches are currently being developed to create systems for psychophysiological support of the crew. Among the main requirements for such systems there are increased autonomy and minimal invasiveness (<xref rid="B9" ref-type="bibr">Egorov, 2001</xref>; <xref rid="B7" ref-type="bibr">Cermack, 2006</xref>). Such methods would allow for continuous monitoring of the crew members’ condition, without interfering with their regular activities and with minimal involvement of Mission control specialists.</p>
              <p>One of the methods that meets these criteria is automated analysis of psychologically and psychophysiologically relevant characteristics of human operators’ speech (<xref rid="B17" ref-type="bibr">Johannes et al., 2000</xref>; <xref rid="B3" ref-type="bibr">Alberdi et al., 2016</xref>; <xref rid="B16" ref-type="bibr">Gushin et al., 2016</xref>).</p>
              <p>Nevertheless, speech is studied mainly using content analysis, which limits the possibility of correct interpretation of the subject’s emotional and psychophysiological state (<xref rid="B30" ref-type="bibr">Nikonov, 1985</xref>). On the other hand, the acoustic characteristics of speech are less susceptible to conscious control and better reflect the deep features of the human functional state. For this reason, they have been used for a long time in studies devoted to assessing the functional state of a person in extreme conditions (<xref rid="B20" ref-type="bibr">Kartavenko, 2005</xref>).</p>
              <p>Previously, the study of the speech acoustic characteristics was successfully carried out in a number of analog and space experiments (<xref rid="B18" ref-type="bibr">Johannes et al., 2008</xref>; <xref rid="B16" ref-type="bibr">Gushin et al., 2016</xref>; <xref rid="B15" ref-type="bibr">Gushchin et al., 2018</xref>; <xref rid="B41" ref-type="bibr">Supolkina et al., 2019</xref>). The technological and methodological progress over the years allows the researchers to bring their studies to a new level within the framework of the modern approach, which ultimately presupposes minimizing the subjectivity and invasiveness of psychophysiological and psychological techniques.</p>
              <p>At the same time, acoustic analysis of speech often shows reproducibility limitations due to varying experimental conditions. One of the most studied characteristics of speech, fundamental frequency (F0), usually increases when a person experiences physiological or psychological stress (<xref rid="B12" ref-type="bibr">Giddens et al., 2013</xref>). However, in a number of studies this was not confirmed. These discrepancies may be associated with different recording conditions, nature of the stress factors, and the individual characteristics of the subjects. Thus, in order to minimize the differences caused by various simulated factors of space flight as well as other possible interfering factors, it is reasonable to analyze the voices of test subjects under the same experimental conditions (<xref rid="B29" ref-type="bibr">National Aeronautics and Space Administration and the National Center for Gender Physiology and Environmental Adaptation, 2002</xref>; <xref rid="B33" ref-type="bibr">Park and Stepp, 2019</xref>).</p>
              <p>The “dry” immersion is currently recognized as the best model for long-term simulation of weightlessness and support-free conditions (<xref rid="B28" ref-type="bibr">Mikhailov et al., 1995</xref>; <xref rid="B46" ref-type="bibr">Tomilovskaya et al., 2019</xref>). Thus, the conditions of “dry” immersion make it possible to study the psychophysiological state of the subjects in the conditions closest to a real space flight.</p>
              <p>The technology and experimental approach have been known and applied since the 1970s, but until the year 2020, only male subjects participated (<xref rid="B38" ref-type="bibr">Shul’zhenko and Vill-Villiams, 1976</xref>; <xref rid="B32" ref-type="bibr">Orlov, 1985</xref>). Taking into account the underrepresentation of women in space, as well as the small number of ground-based simulation experiments with their participation (<xref rid="B29" ref-type="bibr">National Aeronautics and Space Administration and the National Center for Gender Physiology and Environmental Adaptation, 2002</xref>; <xref rid="B37" ref-type="bibr">Saralyn, 2006</xref>), it was necessary to start experimental studies with women under conditions of “dry” immersion in order to assess not only the physiological reactions of adaptation to microgravity conditions, but also the psychophysiological response to this type of stress.</p>
              <p>The aim of this study was to assess the female subjects’ psychophysiological response to physiological stress caused by adaptation to the conditions of simulated microgravity, and also to determine whether it differs from the analogous response in male subjects in the same conditions.</p>
            </sec>
            <sec sec-type="materials|methods" id="S2">
              <title>Materials and Methods</title>
              <sec id="S2.SS1">
                <title>Participants</title>
                <p>The study involved 6 healthy female volunteers aged 24 to 39 years. The studies were carried out in the same periods of the participants’ natural menstrual cycle (7th–10th days of MC).</p>
              </sec>
              <sec id="S2.SS2">
                <title>Bioethics and Informed Consent</title>
                <p>The conducted studies were approved by the Bioethical Commission of the Institute of Biomedical Problems of RAS (Protocol No. 544 of July 16, 2020) and fully complied with the principles of the 1964 Declaration of Helsinki. Each study participant voluntarily signed an informed consent after explaining to her the potential risks, benefits and nature of the upcoming study.</p>
              </sec>
              <sec id="S2.SS3">
                <title>Design of the Study</title>
                <p>From September 7 to November 30, 2020, the IBMP RAS conducted the world’s first “dry” immersion experiment with the participation of female volunteers («NAIAD-2020») (<xref rid="B45" ref-type="bibr">Tomilovskaya et al., 2021</xref>).</p>
                <p>The method used in our study is based both on the methodological approaches implemented in previous space and analog experiments, and on recent methods and technologies of speech acoustic analysis.</p>
                <p>The main material for the analysis were audio recordings of the subjects’ speech during the morning and evening reports on daily events, health and mood (analogous to daily planning conferences, or DPCs, the ISS-MCC standard communication procedure). The reports were recorded right after waking up (8–9 AM) and before going to sleep (9–10 PM). Portable voice recorders Zoom H1 were used, positioned at 15 cm from the subject’s mouth during the recording.</p>
                <p>Simultaneously with the audio recording of DPC audio messages, for the first time, within the framework of the experiment in the conditions of “dry” immersion, video recording was included to our experimental protocol for the analysis of basic emotions using facial expressions (<xref rid="B36" ref-type="bibr">Sanchez et al., 2014</xref>). Within the united methodical approach, acoustic analysis of speech and analysis of facial expressions can become promising means of remote monitoring of the psychoemotional and psychophysiological state of human operator both in space flight and in other extreme conditions (<xref rid="B11" ref-type="bibr">Fontes and Madureira, 2019</xref>; <xref rid="B14" ref-type="bibr">Gushchin et al., 2020</xref>).</p>
                <p>We studied only the period of acute adaptation in order to reveal the differences between the female and male psychophysiological responses to adaptation to microgravity conditions. We also used additional cognitive and sensorimotor tests, facial expression assessment using the FaceReader software, Spielberger’ state-trait anxiety inventory (STAI) and Profile of Mood States (POMS), as well as medical control data: systolic (SBP) and diastolic (DBP) blood pressure, and heart rate (HR) provided by Dr. E.S. Tomilovskaya.</p>
              </sec>
              <sec id="S2.SS4">
                <title>Speech Acoustic Characteristics Analysis</title>
                <p>Within the framework of this study, the main method was the analysis of the acoustic characteristics of speech reflecting the functional state of the subjects, with the Praat software (<xref rid="B5" ref-type="bibr">Boersma and Weenink, 2018</xref>). We analyzed speech segments unified by the audio reporting protocol, in order to minimize the impact of varying content of statements. The speech fundamental frequency (F0) (Mean and Median pitch values, as calculated by the Praat software algorithm within every acoustic sample), intensity (speech volume), the number of voice pulses and pauses in speech, shimmer and jitter were studied in dynamics over the course of immersion. These indicators are often used as correlates of emotional and psychophysiological stress and pathological conditions in humans, as well as to describe a person’s individual speech “portrait” in order to more reliably identify individual differences in stress responses (<xref rid="B24" ref-type="bibr">Lebedeva et al., 2020</xref>; <xref rid="B25" ref-type="bibr">Lebedeva and Shved, 2021</xref>).</p>
                <p>One of the first still the most studied parameters of speech signal is the pitch (fundamental frequency, F0) (<xref rid="B6" ref-type="bibr">Buchanan et al., 2014</xref>; <xref rid="B34" ref-type="bibr">Pisanski et al., 2018</xref>). Its measurement made it possible to solve a number of practical problems in speech technologies development, such as the speaker’s gender identification, determining their emotional state, speech recognition, as well as identifying the functional state of the vocal apparatus (<xref rid="B19" ref-type="bibr">Johannes et al., 2007</xref>; <xref rid="B44" ref-type="bibr">Teixeira et al., 2011</xref>; <xref rid="B3" ref-type="bibr">Alberdi et al., 2016</xref>; <xref rid="B2" ref-type="bibr">Akçay and Oguz</xref>, <xref rid="B2" ref-type="bibr">2020</xref>).</p>
                <p>When measuring the intensity (speech volume), we took into account that in calmly speaking subjects its average value is 40–60 dB, and in an excited state – 70–80 dB. Changes in the intensity are an important diagnostic feature in assessing the psychophysiological state of a person (<xref rid="B35" ref-type="bibr">Rothkrantz, 2004</xref>; <xref rid="B50" ref-type="bibr">Zhang, 2016</xref>).</p>
                <p>Unvoiced fragments length is an absolute value corresponding to the physical duration of the pauses, i.e., a break in sound when the average sound pressure drops to zero at the junction between two sound segments. In relation to the duration of the utterance, the percentage of pauses that a person makes between words and phrases is calculated. This value may indicate a state of psychophysiological tension or asthenization (<xref rid="B6" ref-type="bibr">Buchanan et al., 2014</xref>).</p>
                <p>The use of jitter and shimmer effects is important for determining the voice pathologies and is often used in the clinical studies (<xref rid="B51" ref-type="bibr">Zwetsch et al., 2006</xref>; <xref rid="B44" ref-type="bibr">Teixeira et al., 2011</xref>). Jitter is a measure of period-to-period fluctuations in F0, showing involuntary changes in the frequency of adjacent vibrational cycles of the vocal folds. Shimmer is a measure similar to jitter, which characterizes the period-to-period variability of the amplitude value. The reason for the widespread use of jitter and shimmer parameters in clinical studies is that the structure of vibrations of the vocal folds has a periodic nature for healthy voices, while this periodicity in the structure of vibrations is significantly impaired in the presence of pathological changes (<xref rid="B42" ref-type="bibr">Teixeira and Fernandes, 2014</xref>; <xref rid="B43" ref-type="bibr">Teixeira and Gonçalves, 2016</xref>). However, some studies show that changes in the functional state of a human operator can also lead to changes in their voice’s F0 and may be a diagnostic sign of significant distress.</p>
              </sec>
              <sec id="S2.SS5">
                <title>Facial Expressions Analysis</title>
                <p>The analysis of the subjects’ facial expressions was carried out using the FaceReader software. The software’s algorithm allows detection of neutral emotional state, as well as six basic emotions according to the generally accepted classification of <xref rid="B10" ref-type="bibr">Ekman and Friesen (1978)</xref> (happiness, surprise, sadness, anger, fear, disgust), the general valence of emotions and the level of arousal. The daily video reports were used for the analysis. The FaceReader assesses the general level of a person’s arousal based on the number of facial movements they performs per unit of time. A deep neural network algorithm is used, working in three main stages: detecting a face in the presented image, building a model based on 500 key points and classifying facial expressions (<xref rid="B26" ref-type="bibr">Loijens and Krips, 2018</xref>). It is worth noting that a comparison of the expert assessments and the FaceReader software showed its 95% accuracy (<xref rid="B13" ref-type="bibr">Gusev et al., 2018</xref>; <xref rid="B40" ref-type="bibr">Stöckli et al., 2018</xref>).</p>
              </sec>
              <sec id="S2.SS6">
                <title>Auxiliary Tests and Questionnaires</title>
                <p>The subjects performed computer-aided tests, including psychological questionnaires, twice a day. The State-Trait Anxiety Inventory (STAI) (only the state anxiety was measured) (<xref rid="B39" ref-type="bibr">Spielberger, 2010</xref>) and (POMS; <xref rid="B27" ref-type="bibr">Mcnair et al., 1971</xref>) questionnaire were used.</p>
                <p>Then the subjects performed sensorimotor and cognitive tests simulating operator activity: reaction to a moving object (RMO extrapolation and coordination tasks), short-term memory tests, simple mathematical calculation, response speed (<xref rid="B48" ref-type="bibr">Ushakov et al., 2015</xref>).</p>
                <p>In the morning after waking up and in the evening before going to bed, medical control was carried out, including measurement of body temperature, heart rate, blood pressure (systolic and diastolic). The data are supplementary to the main research, and are provided by Dr. E.S. Tomilovskaya.</p>
                <p>The experimental schedule is presented in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
                <table-wrap position="float" id="T1">
                  <label>TABLE 1</label>
                  <caption>
                    <p>Design of the psychophysiological study of female 3-day dry immersion.</p>
                  </caption>
                  <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
                    <thead>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Approaches and techniques used</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Timing</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Duration</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Explanations</td>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Medical control</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">7:30-8 am</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Assessment of body temperature, heart rate, blood pressure (systolic and diastolic).</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Speech acoustic analysis</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">8 am</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">F0 (Mean and Median), speech signal intensity, number of pulses, unvoiced speech fragments, jitter and shimmer were analyzed in voice recordings.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Facial expressions analysis</td>
                        <td rowspan="1" colspan="1"/>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="left" rowspan="1" colspan="1">Emotional state assessment using FaceReader software.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" colspan="4" rowspan="1">
                          <bold>Morning experiments, breakfast</bold>
                        </td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">State-trait anxiety inventory (STAI)</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">10 am</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">1 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Analysis of the subjective assessment of state anxiety.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Profile of mood states (POMS)</td>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Analysis of the subjective mood assessment.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Cognitive and sensorimotor tests</td>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="center" rowspan="1" colspan="1">10 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Human operator activity analysis using the computer-aided cognitive and sensorimotor tests.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" colspan="4" rowspan="1">
                          <bold>Daytime experiments, lunch, rest</bold>
                        </td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">State-trait anxiety inventory (STAI)</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">6–7 pm</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">1 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Analysis of the subjective assessment of state anxiety.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Profile of mood states (POMS)</td>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Analysis of the subjective mood assessment.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Cognitive and sensorimotor tests</td>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="center" rowspan="1" colspan="1">10 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Human operator activity analysis using the computer-aided cognitive and sensorimotor tests.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" colspan="4" rowspan="1">
                          <bold>Dinner, rest</bold>
                        </td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Medical control</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">9 pm</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">Assessment of body temperature, heart rate, blood pressure (systolic and diastolic).</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Speech acoustic analysis</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">9–10 pm</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">5 min</td>
                        <td valign="top" align="left" rowspan="1" colspan="1">F0 (Mean and Median), speech signal intensity, number of pulses, unvoiced speech fragments, jitter and shimmer were analyzed in voice recordings.</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Facial expressions analysis</td>
                        <td rowspan="1" colspan="1"/>
                        <td rowspan="1" colspan="1"/>
                        <td valign="top" align="left" rowspan="1" colspan="1">Emotional state assessment using FaceReader software.</td>
                      </tr>
                    </tbody>
                  </table>
                </table-wrap>
              </sec>
              <sec id="S2.SS7">
                <title>Statistical Analysis</title>
                <p>The used statistical methods included factor analysis by the principal component extraction method (Varimax rotation with Kaiser normalization), correlation analysis (Pearson’s correlation), comparison of paired samples means (Wilcoxon <italic>t</italic>-test), tests of between-subjects effects (ANOVA).</p>
              </sec>
            </sec>
            <sec sec-type="results" id="S3">
              <title>Results</title>
              <sec id="S3.SS1">
                <title>Acoustic Analysis of Speech</title>
                <p>The values of Mean pitch (fundamental frequency, F0) in the subjects were 205.4 (3.9) Hz on average. The values of Median pitch were 198.4 (3.8) Hz on average. The data was normally distributed. Mean pitch showed a significant decrease by the morning of day 2 in comparison with the evening of the previous day (<italic>p</italic> = 0,04), in 5 out of 6 subjects (<xref rid="F1" ref-type="fig">Figure 1</xref>). A similar result was obtained by Median pitch measurements. In 1 out of 6 subjects, two insignificant decreases in F0 were observed in the evening of the 1st day and in the morning of the 3rd day of the immersion.</p>
                <fig position="float" id="F1">
                  <label>FIGURE 1</label>
                  <caption>
                    <p>Average mean pitch per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g001" position="float"/>
                </fig>
                <p>The values of speech signal intensity (speech volume) were 80.2 (1.2) dB on average, the data was normally distributed. The speech volume increased significantly by the evening of the day 1 in all subjects (<italic>p</italic> = 0,04) (<xref rid="F2" ref-type="fig">Figure 2</xref>). An insignificant decrease in the speech volume was observed only in the evening of the 2nd day.</p>
                <fig position="float" id="F2">
                  <label>FIGURE 2</label>
                  <caption>
                    <p>Average intensity per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g002" position="float"/>
                </fig>
              </sec>
              <sec id="S3.SS2">
                <title>Basic Emotions in Facial Expressions (FaceReader Software)</title>
                <p>Video recording took place simultaneously with speech recording every day, in the morning and in the evening. Based on the results of this study, it was not possible to identify significant trends in basic emotions changes during the immersion. Nevertheless, we were able to identify the dynamics of “neutral” emotional state (neutral facial expression) in the course of the experiment: it gradually decreased (<italic>R</italic><sup>2</sup> = 0.7) (<xref rid="F3" ref-type="fig">Figure 3</xref>).</p>
                <fig position="float" id="F3">
                  <label>FIGURE 3</label>
                  <caption>
                    <p>Average neutral emotion (facial expression) per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g003" position="float"/>
                </fig>
              </sec>
              <sec id="S3.SS3">
                <title>Psychological Questionnaires</title>
                <p>The POMS questionnaire was completed twice a day, in the morning and in the evening, throughout the experiment.</p>
                <p>In the evening of the 1st day, a sharp decrease in the subjectively perceived Vigor-Activity (<italic>p</italic> = 0.04) and a significant increase in Depression-Dejection (<italic>p</italic> = 0.04) were revealed (<xref rid="F4" ref-type="fig">Figure 4</xref>). By the morning of the 2nd day, the level of Depression-Dejection significantly decreased (<italic>p</italic> = 0.04), as the level of Vigor-Activity slightly increased, while Fatigue decreased (the difference was not statistically significant). On the last day of the experiment, a sharp decrease in Fatigue-Inertia was observed (<italic>p</italic> = 0.04).</p>
                <fig position="float" id="F4">
                  <label>FIGURE 4</label>
                  <caption>
                    <p>Average mood states (Vigor-Activity, Depression-Dejection and Fatigue-Inertia) per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g004" position="float"/>
                </fig>
                <p>The state anxiety test according to the STAI questionnaire, presented every day in the morning and in the evening, showed a change in the level of anxiety. The test results can be interpreted as a mild form of S-anxiety (scores less than 30 points) and moderate form of S-anxiety (scores from 31 to 44 points). The peak in the state anxiety was observed in the evening of the first immersion day, which indicates the beginning of the acute phase of adaptation (<xref rid="F5" ref-type="fig">Figure 5</xref>).</p>
                <fig position="float" id="F5">
                  <label>FIGURE 5</label>
                  <caption>
                    <p>Average state anxiety per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g005" position="float"/>
                </fig>
              </sec>
              <sec id="S3.SS4">
                <title>Cognitive and Sensorimotor Tests</title>
                <p>Computer tests performed in the morning and evening throughout the DI experiment showed variability in some of the cognitive and sensorimotor functions of the subjects.</p>
                <p>The test for sensorimotor coordination “RMO Extrapolation” (Reaction to a Moving Object, motor response to a moving and vanishing point) showed a gradual decrease in error/lability values (<xref rid="F6" ref-type="fig">Figure 6</xref>).</p>
                <fig position="float" id="F6">
                  <label>FIGURE 6</label>
                  <caption>
                    <p>Average error/lability in RMO Extrapolation test per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g006" position="float"/>
                </fig>
                <p>The time for simple mathematical calculations also decreased during the DI experiment (<xref rid="F7" ref-type="fig">Figure 7</xref>).</p>
                <fig position="float" id="F7">
                  <label>FIGURE 7</label>
                  <caption>
                    <p>Average time for simple math calculations per morning/evening during the 3-days “dry” immersion experiment. Mean ± SEM.</p>
                  </caption>
                  <graphic xlink:href="fphys-12-751016-g007" position="float"/>
                </fig>
              </sec>
              <sec id="S3.SS5">
                <title>Statistical Analysis</title>
                <p>We carried out a factor analysis of data on speech acoustics, the results of cognitive tests, facial expressions, the STAI test results, the POMS questionnaire results and medical control. We used the principal component analysis (rotation method: Varimax with Kaiser normalization. Rotation converged in 12 iterations). The analysis made it possible to identify the components that are significant for this study.</p>
                <p>The first component of the resulting matrix shows an inverse relationship between the level of speech intensity and the percentage of pauses, decision time when math calculation, anxiety, hostility, depression, fatigue, anxiety and confusion, and a direct relationship with systolic blood pressure (SBP), activity and friendliness. This component can be described as a state in which a person speaks in a quieter voice, pauses more, solves mathematical equations more slowly, and notes anxiety, hostility, depression, fatigue and confusion, while their SBP is low. The flip side of this component describes a more active and friendly person, with a higher SBP, solving mathematical equations quickly, speaking in a louder voice and making fewer pauses in speech.</p>
                <p>The second component shows the inverse relationship between the speech acoustic characteristics (the number of pulses and jitter) and the results of the RMO Extrapolation sensorimotor test (error/lability values). This component could be described as a state of a person in which they utter fewer sounds and their voice «trembles» less, and at the same time they cope better with sensorimotor tasks that require relying on internal time.</p>
                <p>The third component showed the relationship between the facial expression of basic emotions according to the FaceReader software: an inverse relationship between sadness and happiness, valence, and diastolic blood pressure (DBP). This component could be described as a state of a person in which they have a higher DBP, and their facial expressions speak of a state of happiness and vivacity.</p>
                <p>To clarify the obtained relationships within the components, we carried out an additional correlation analysis (Pearson’s correlation).</p>
              </sec>
              <sec id="S3.SS6">
                <title>Speech Acoustic Characteristics and the Results of Cognitive Tests</title>
                <p>The study revealed significant negative correlations (<italic>p</italic> &lt; 0.01) between such speech characteristic as intensity and the number of pulses, and error/lability values when performing RMO Extrapolation, as well as the simple math calculations time. Also, significant positive correlations were noted between the number of pauses in speech and error/lability values when performing RMO Extrapolation and RMO Coordination tests (<italic>p</italic> &lt; 0.05) and the simple math calculations time (<italic>p</italic> &lt; 0.0001). There was also a positive correlation between Median pitch and the simple math calculations time (<italic>p</italic> &lt; 0.0001). Jitter was inversely correlated with errors in solving mathematical equations (<italic>p</italic> = 0.01).</p>
              </sec>
              <sec id="S3.SS7">
                <title>Speech Acoustic Characteristics and the Results of Medical Control</title>
                <p>Intensity (<italic>p</italic> = 0.001) and the number of pulses (<italic>p</italic> = 0.04) were positively correlated with systolic BP and shimmer was negatively correlated (<italic>p</italic> = 0.001). Intensity (<italic>p</italic> &lt; 0.0001) and the number of pulses (<italic>p</italic> = 0.002) were positively correlated with diastolic BP, and Median pitch (<italic>p</italic> = 0.02), pauses (<italic>p</italic> = 0.006), and shimmer (<italic>p</italic> = 0.02) were negatively correlated. The number of pulses positively correlated with heart rate (<italic>p</italic> = 0.04).</p>
              </sec>
              <sec id="S3.SS8">
                <title>Speech Acoustic Characteristics and the Results of the Emotions Analysis by Facial Expressions</title>
                <p>The number of pulses negatively correlated with «neutral» facial expression (<italic>p</italic> = 0.02), and the percentage of pauses correlated positively (<italic>p</italic> = 0.01). Shimmer positively correlated with the emotion of fear (<italic>p</italic> = 0.001).</p>
              </sec>
              <sec id="S3.SS9">
                <title>Speech Acoustic Characteristics and the Results of Self-Assessment Questionnaires</title>
                <sec id="S3.SS9.SSS1">
                  <title>The Level of State Anxiety</title>
                  <p>The state anxiety level was positively correlated with Median pitch (<italic>p</italic> = 0.005) and the percentage of pauses (<italic>p</italic> = 0.006), and the number of pulses (<italic>p</italic> = 0.04) was negatively correlated.</p>
                </sec>
                <sec id="S3.SS9.SSS2">
                  <title>Profile of Mood States</title>
                  <p>Median pitch (<italic>p</italic> = 0.01 and <italic>p</italic> = 0.005) and the number of pauses (<italic>p</italic> = 0.01 and <italic>p</italic> = 0.005) correlated with the “hostility” and “depression” scales. Pauses correlated with the fatigue scale (<italic>p</italic> &lt; 0.05). Intensity (<italic>p</italic> = 0.02) and the number of pulses (<italic>p</italic> = 0.007 and <italic>p</italic> = 0.003) were correlated with the “activity” and “friendliness” scales, and pauses (<italic>p</italic> = 0.008 and <italic>p</italic> &lt; 0.0001) were negatively correlated; in addition, Median pitch (<italic>p</italic> = 0.008) was negatively correlated with “friendliness”. Median pitch (<italic>p</italic> = 0.002 and <italic>p</italic> = 0.003) and pauses (<italic>p</italic> = 0.003 and <italic>p</italic> = 0.001) positively correlated with the scales “anxiety” and “confusion”, and in addition, the number of pulses (<italic>p</italic> &lt; 0, 0001).</p>
                </sec>
              </sec>
              <sec id="S3.SS10">
                <title>Analysis of Basic Emotions by Facial Expressions</title>
                <p>Despite the fact that this study did not show a significant number of correlations between basic emotions and data from other methods, we conducted tests of between-subjects effects. The results are presented in <xref rid="T2" ref-type="table">Table 2</xref>.</p>
                <table-wrap position="float" id="T2">
                  <label>TABLE 2</label>
                  <caption>
                    <p>Tests of between-subjects effects with basic emotions and days covariates.</p>
                  </caption>
                  <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
                    <thead>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Dependent variable:<hr/></td>
                        <td valign="top" align="center" rowspan="1" colspan="1">“RMO extrapolation” error/lability<hr/></td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Time for math calculations<hr/></td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Median pitch<hr/></td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Jitter<hr/></td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Source</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Sig.</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Sig.</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Sig.</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">Sig.</td>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Corrected model</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,000</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,000</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,011</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,062</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Intercept</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,000</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,007</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,004</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,666</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">N day</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,003</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,119</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,446</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,079</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Neutral</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,002</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,052</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,568</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,073</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Happy</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,026</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,088</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,685</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,036</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Sad</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,160</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,139</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,725</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,043</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Angry</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,187</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,120</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,046</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,037</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Surprised</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,023</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,052</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,905</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,174</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Scared</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,120</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,471</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,588</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,091</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Disgusted</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,116</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,134</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,857</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,048</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Valence</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,059</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,101</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,541</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,037</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Arousal</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,050</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,350</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,029</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,274</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Subject name</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,000</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,000</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,004</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,010</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Am/Pm</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,323</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,119</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,230</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,475</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Subject name Am/Pm</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,030</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,288</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,016</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,397</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">R squared</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,949</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,960</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,883</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,747</td>
                      </tr>
                      <tr>
                        <td valign="top" align="left" rowspan="1" colspan="1">Adjusted R squared</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,852</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,884</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,658</td>
                        <td valign="top" align="center" rowspan="1" colspan="1">0,263</td>
                      </tr>
                    </tbody>
                  </table>
                </table-wrap>
                <p>He showed the influence of such factors as the person of the subject, the number of the day, morning or evening, as well as basic emotions according to FaceReader on the results of cognitive and sensorimotor tests and some acoustic parameters. The results of the analysis show that the person of the subject had the greatest influence, and in some cases, it depended on the time of day (morning or evening). The results of the RMO Extrapolation test were also influenced by the number of the day (which correlates with <italic>R</italic><sup>2</sup> for these values).</p>
                <p>“Neutral” emotional state influenced the results of RMO Extrapolation and simple calculations. State of “Happiness” influenced the results of RMO Extrapolation and jitter. Jitter was also affected by “Sad” and “Disgusted” emotions. “Surprised” state affected accuracy in RMO Extrapolation and simple calculations.</p>
                <p>“Arousal” influenced the results of the RMO Extrapolation and the Median pitch. “Valence” influenced the results of RMO Extrapolation and jitter.</p>
              </sec>
            </sec>
            <sec sec-type="discussion" id="S4">
              <title>Discussion</title>
              <p>According to the results of our study, the acute period of adaptation in women under simulated microgravity began in the evening of the 1st day and ended in the morning of the 2nd day of immersion. This is indicated by the results of the speech acoustic analysis and self-assessment questionnaires, in which the subjects noted an increase in anxiety and depression, and a decrease in activity. This was compared with the data obtained in the same experiment regarding the attitude of the subjects to their physical discomfort (such as general discomfort, back pain and abdominal pain) also peaking at the 1st day and decreasing by the 2nd day evening (<xref rid="B45" ref-type="bibr">Tomilovskaya et al., 2021</xref>). Previously, in studies with participation of astronauts (58% of whom were female) it was shown that approximately half of all astronauts report back pain during the early stages of spaceflight: back pain was most often reported on the first and 2nd days of space flight (<xref rid="B21" ref-type="bibr">Kerstman et al., 2012</xref>).</p>
              <p>The presence of an acute adaptation period was indicated by a change in the pitch and intensity of the subjects’ voices, which confirms the importance of these non-verbal characteristics of speech for assessing the psychophysiological state of a person. It should be noted that the dynamics of changes in pitch, when compared with the same period of adaptation in men, was less pronounced. In connection with stress, Mean and Median pitch in women significantly increased by the evening of the 1st day in 5 out of 6 subjects, and then decreased to the initial values, and did not show significant fluctuations as it was shown in men under similar conditions. Judging by this indicator, psychophysiological stress in the process of adaptation to microgravity conditions lasted less in women – in a similar experiment, the acute adaptation period in men ended on immersion day 3 (F0 and the number of pulses decreased by the 3rd day) (<xref rid="B24" ref-type="bibr">Lebedeva et al., 2020</xref>).</p>
              <p>Similar results in terms of sex differences in stress responses were reported previously. A stronger increase in cortisol levels in response to stress in men than in women was shown in some studies (<xref rid="B22" ref-type="bibr">Kudielka and Kirschbaum, 2005</xref>). This physiological phenomenon can also cause a stronger increase in some acoustic parameters of the subjects’ speech (<xref rid="B6" ref-type="bibr">Buchanan et al., 2014</xref>; <xref rid="B3" ref-type="bibr">Alberdi et al., 2016</xref>; <xref rid="B34" ref-type="bibr">Pisanski et al., 2018</xref>). At the same time, changes in the subjects’ voice intensity in our study turned out to be almost identical with the same indicator dynamics in male subject during the same period of acute adaptation.</p>
              <p>Cognitive tests performed in the morning and evening throughout the experiment showed variability in some mental and sensorimotor functions. The “RMO Extrapolation” test showed a gradual decrease in error/lability values, which correlates with the results of sensorimotor tests obtained from male subjects in longer experiments with “dry” immersion (<xref rid="B24" ref-type="bibr">Lebedeva et al., 2020</xref>). The time of simple math equations solving also decreased significantly. We suppose that the observed trends were influenced both by the training effect and stress level decrease. Some authors note that lower quality of sensorimotor and calculation tasks results under simulated (head-down bed rest, parabolic flight) and real space flight conditions may be caused by additional stress associated with increased cognitive load (<xref rid="B49" ref-type="bibr">Wollseiffen et al., 2016</xref>; <xref rid="B31" ref-type="bibr">Oluwafemi et al., 2021</xref>). Other studies have also shown that “dual-tasking” costs increase for reaction-time tasks requiring rhythm production, and to a lesser degree, visuo-spatial transformation, compared with regular choice reaction-time tasks (<xref rid="B4" ref-type="bibr">Bock et al., 2010</xref>). However, in the present study we found no significant difference in performance improvement in two types of tasks: sensorimotor (RMO) and cognitive (mathematical computation), although the sensorimotor task performance is more consistent with the dual-task paradigm than the computation. It is necessary to conduct further studies of longer duration in order to find out the dynamics of these performance changes, and the factors influencing it.</p>
              <p>It should be noted that a similar relationship was found between the acoustic characteristics of speech and the sensorimotor performance in the experiment with female subjects and in a similar experiment with men: higher speech volume and the number of pulses were associated with more accurate performance of sensorimotor tasks. This was probably due to an activation tendency in the subjects’ functional state (<xref rid="B8" ref-type="bibr">Cohen et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abur et al., 2021</xref>). A significant difference between the female and male samples was a positive (rather than negative, as in men) correlation between the number of pauses in speech and the time of mathematical equations solving. We assume that this distinction needs additional research. Pauses in speech may be interpreted as a sign of concentration, self-control – a transition to the inner voice in order to articulate certain attitudes and rules (<xref rid="B47" ref-type="bibr">Tullett and Inzlicht, 2010</xref>). We should also note that the female subjects participated in a 3-day experiment, while the male subjects participated in a 21-day study. Different duration of the “dry” immersion can by itself explain the possible difference in the reasons why the subjects used self-control. In the short experiment with women, the time of mathematical computation was decreasing, as also were the subjects’ anxiety and depression indicators (according to STAI and POMS). It can be assumed that the larger percentage of speech pauses and the longer time spent on mathematical computation were both associated with the subjects’ physical unwellness in the 1st days of adaptation, and, subsequently, with the increased need for self-control (in order to fulfill their tasks despite their current state). We suppose that the reason that female subjects made more pauses in speech during their first audio reports could be that they made additional efforts for self-regulation, and were also more worried about the correct task results, so they additionally used the inner voice to recite the rules of the task (<xref rid="B23" ref-type="bibr">Laukka et al., 2008</xref>). At the same time, the male sample, while solving the computation task at a much later period of the experiment, probably used the inner voice to decelerate impulsive responding. I.e., on the days when the male subjects felt more disinhibited (and, subsequently, spoke faster, with less pauses), they tried to take more time for better computation performance, slowing down their motor reaction (pressing a key to respond) (<xref rid="B47" ref-type="bibr">Tullett and Inzlicht, 2010</xref>).</p>
              <p>Also, the distinction of the female sample were the significant correlations between objective psychophysiological indicators (acoustic analysis of speech and analysis of facial expressions) and the results of self-assessment tests. The results of self-assessment questionnaires correlate well with each other and with the data of acoustic analysis of speech. This indicates that the subjects in the present study interpreted their psychological state well and answered honestly to the questionnaire questions.</p>
              <p>The method of the basic emotions analysis using facial expressions revealed some limitations of this study: the body position (recumbent), as well as the redistribution of body fluids in the cranial direction, could affect the quality of the analysis. The most informative was the indicator of “neutral” emotional state – during the 3-day exposure, it significantly decreased. It should be noted that “neutral” emotional states positively correlated with the percentage of pauses in speech and negatively – with vocal pulses. A similar pattern was found between the same acoustic indicators and the subjects’ perception of anxiety (STAI and POMS) and confusion (POMS). This can be interpreted as a mild variant of a “freeze” stress reaction, when a person speaks less, their face becomes less emotional, and at the same time they feel anxious and confused. Some studies have noted similar reactions in connection with social stress (social phobias): under the influence of increasing anxiety, the percentage of pauses in voluntary speech increases (<xref rid="B23" ref-type="bibr">Laukka et al., 2008</xref>; <xref rid="B6" ref-type="bibr">Buchanan et al., 2014</xref>).</p>
            </sec>
            <sec sec-type="conclusion" id="S5">
              <title>Conclusion</title>
              <p>The conducted psychophysiological study revealed some indicators of the acute period of adaptation to microgravity conditions. For the first time conducted with the participation of female subjects, this study showed possible differences from all-male samples: in the duration and specificity of adaptation to «dry» immersion conditions, in a more accurate reflection of one’s state in questionnaires, as well as in some patterns of correlations between the acoustic characteristics of speech and the results of cognitive tests.</p>
              <p>The acute adaptation period in female subjects began earlier and ended faster than in male ones in previous studies. This was indicated by a decrease in the level of state anxiety (STAI) and depression-dejection (POMS), as well as a decrease in pitch and voice intensity. Women in this study reacted to the adaptation stress differently than men previously: a significant decrease in pitch was shown, while in men under the same conditions the opposite was more often observed. In addition, women, apparently, used the “freeze” coping strategy – the proportion of neutral facial expressions on the most intense days of the experiment was at maximum. Thus, the subjects in this experiment understood their feelings and emotions better, giving more accurate answers in self-assessment questionnaires, but at the same time tried to look and sound as calm and confident as possible, controlling their expressions.</p>
              <p>Same trends in the subjects’ cognitive performance were identified as in similar experimental conditions earlier: an excited state (high intensity and a higher number of pulses in speech) corresponded to better performance of sensorimotor tasks. The difference was in the speed of mathematical computation: women in the present study performed the computation faster on the same days when they made fewer pauses in speech (i.e., spoke more quickly), while in men in previous experiments this relationship was inverse: on the days when male subjects made more pauses in speech, they performed the computation faster.</p>
              <p>The results obtained need to be corroborated both in the «dry» immersion model and in other physiologically stressful conditions. In studies related to speech, facial expressions and cognitive performance, it is necessary to take into account the subjects’ individual differences, and also, the specific influence of the experimental conditions and the method of obtaining experimental data.</p>
              <p>In order to get a better understanding of the influence of physiologically stressful conditions on the human operator’s psychophysiological state, further studies with the participation of women are required.</p>
            </sec>
            <sec sec-type="data-availability" id="S6">
              <title>Data Availability Statement</title>
              <p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p>
            </sec>
            <sec id="S7">
              <title>Ethics Statement</title>
              <p>The studies involving human participants were reviewed and approved by Bioethical Commission of the Institute of Biomedical Problems of RAS. The patients/participants provided their written informed consent to participate in this study.</p>
            </sec>
            <sec id="S8">
              <title>Author Contributions</title>
              <p>SL prepared the analysis of acoustic speech characteristic, sensorimotor cognitive tests and psychological questionnaire, and wrote the draft of the manuscript. AS prepared the analysis of FaceReader data. DS made the manuscript revisions. All authors contributed to the article and approved the submitted version.</p>
            </sec>
            <sec sec-type="COI-statement" id="conf1">
              <title>Conflict of Interest</title>
              <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
            </sec>
            <sec sec-type="disclaimer" id="pudiscl1">
              <title>Publisher’s Note</title>
              <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
            </sec>
          </body>
          <back>
            <sec sec-type="funding-information" id="S9">
              <title>Funding</title>
              <p>This study was supported by the Russian Academy of Sciences (63.2).</p>
            </sec>
            <ack>
              <p>The authors are grateful to the women who participated in this study and the team of the Institute of Biomedical Problems, and in particular Elena Tomilovskaya and Liubov Amirova who played the key role in the organization of the experiment.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="B1">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abur</surname><given-names>D.</given-names></name><name><surname>MacPherson</surname><given-names>M. K.</given-names></name><name><surname>Shembel</surname><given-names>A. C.</given-names></name><name><surname>Stepp</surname><given-names>C. E.</given-names></name></person-group> (<year>2021</year>). <article-title>Acoustic Measures of Voice and Physiologic Measures of Autonomic Arousal During Speech as a Function of Cognitive Load in Older Adults.</article-title>
<source><italic>J. Voice</italic></source>
<volume>2021</volume>:<fpage>27</fpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2020.12.027</pub-id>
<?supplied-pmid 33509665?><pub-id pub-id-type="pmid">33509665</pub-id></mixed-citation>
              </ref>
              <ref id="B2">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akçay</surname><given-names>M. B.</given-names></name><name><surname>Oguz</surname><given-names>K.</given-names></name></person-group> (<year>2020</year>). <article-title>Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers.</article-title>
<source><italic>Speech Comm.</italic></source>
<volume>116</volume>
<fpage>56</fpage>–<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1016/j.specom.2019.12.001</pub-id></mixed-citation>
              </ref>
              <ref id="B3">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alberdi</surname><given-names>A.</given-names></name><name><surname>Aztiria</surname><given-names>A.</given-names></name><name><surname>Basarab</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Towards an automatic early stress recognition system for office environments based on multimodal measurements: a review.</article-title>
<source><italic>J. Biomed. Inform.</italic></source>
<volume>59</volume>
<fpage>49</fpage>–<lpage>75</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2015.11.007</pub-id>
<?supplied-pmid 26621099?><pub-id pub-id-type="pmid">26621099</pub-id></mixed-citation>
              </ref>
              <ref id="B4">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>O.</given-names></name><name><surname>Weigelt</surname><given-names>C.</given-names></name><name><surname>Bloomberg</surname><given-names>J. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Cognitive demand of human sensorimotor performance during an extended space mission: a dual-task study.</article-title>
<source><italic>Aviat. Space Environ. Med.</italic></source>
<volume>81</volume>
<fpage>819</fpage>–<lpage>824</lpage>. <pub-id pub-id-type="doi">10.3357/asem.2608.2010</pub-id>
<?supplied-pmid 20824987?><pub-id pub-id-type="pmid">20824987</pub-id></mixed-citation>
              </ref>
              <ref id="B5">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boersma</surname><given-names>P.</given-names></name><name><surname>Weenink</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <source><italic>Praat: doing phonetics by computer [Computer program]. Version 6.0.37.</italic></source> Available online at: from <ext-link xlink:href="http://www.praat.org" ext-link-type="uri">http://www.praat.org</ext-link>
<comment>(accessed date 14 March 2018)</comment></mixed-citation>
              </ref>
              <ref id="B6">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buchanan</surname><given-names>T. W.</given-names></name><name><surname>Laures-Gore</surname><given-names>J. S.</given-names></name><name><surname>Duff</surname><given-names>M. C.</given-names></name></person-group> (<year>2014</year>). <article-title>Acute stress reduces speech fluency.</article-title>
<source><italic>Biol. Psychol.</italic></source>
<volume>97</volume>
<fpage>60</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2014.02.005</pub-id>
<?supplied-pmid 24555989?><pub-id pub-id-type="pmid">24555989</pub-id></mixed-citation>
              </ref>
              <ref id="B7">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cermack</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Monitoring and telemedicine support in remote environments and in human space flight.</article-title>
<source><italic>Br. J. Anaesth.</italic></source>
<volume>97</volume>
<fpage>107</fpage>–<lpage>114</lpage>. <pub-id pub-id-type="doi">10.1093/bja/ael132</pub-id>
<?supplied-pmid 16731572?><pub-id pub-id-type="pmid">16731572</pub-id></mixed-citation>
              </ref>
              <ref id="B8">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>A. O.</given-names></name><name><surname>Dellarco</surname><given-names>D. V.</given-names></name><name><surname>Breiner</surname><given-names>K.</given-names></name><name><surname>Helion</surname><given-names>C.</given-names></name><name><surname>Heller</surname><given-names>A. S.</given-names></name><name><surname>Rahdar</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>The Impact of Emotional States on Cognitive Control Circuitry and Function.</article-title>
<source><italic>J. Cogn. Neurosci.</italic></source>
<volume>28</volume>
<fpage>446</fpage>–<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00906</pub-id><pub-id pub-id-type="pmid">26601909</pub-id></mixed-citation>
              </ref>
              <ref id="B9">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egorov</surname><given-names>A. D.</given-names></name></person-group> (<year>2001</year>). <article-title>Theory and methodology of medical control in long space flights. Official speech. RAS. SSC RF – IBMP RAS. Moscow.</article-title> Available online at: <ext-link xlink:href="http://www.imbp.ru/webpages/win1251/science/Egorov_actsp.html" ext-link-type="uri">http://www.imbp.ru/webpages/win1251/science/Egorov_actsp.html</ext-link>
<comment>(accessed January 5, 2022)</comment>.</mixed-citation>
              </ref>
              <ref id="B10">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P.</given-names></name><name><surname>Friesen</surname><given-names>W. V.</given-names></name></person-group> (<year>1978</year>). <source><italic>Manual for the facial action coding system.</italic></source>
<publisher-loc>Palo Alto</publisher-loc>: <publisher-name>Consulting Psychologists Press</publisher-name>. <pub-id pub-id-type="doi">10.1037/t27734-000</pub-id></mixed-citation>
              </ref>
              <ref id="B11">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fontes</surname><given-names>M.</given-names></name><name><surname>Madureira</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). “<article-title>Vocal and facial expressions and meaning effects in speech expressivity</article-title>,” in <source><italic>Proceedings of 10th International Conference on Experimental Linguistics, 25-27 September</italic></source> (<publisher-loc>Lisbon</publisher-loc>). <pub-id pub-id-type="doi">10.36505/ExLing-2019/10/0020/000382</pub-id></mixed-citation>
              </ref>
              <ref id="B12">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giddens</surname><given-names>C. L.</given-names></name><name><surname>Barron</surname><given-names>K. W.</given-names></name><name><surname>Byrd-Craven</surname><given-names>J.</given-names></name><name><surname>Clark</surname><given-names>K. F.</given-names></name><name><surname>Winter</surname><given-names>A. S.</given-names></name></person-group> (<year>2013</year>). <article-title>Vocal indices of stress: a review.</article-title>
<source><italic>J. Voice</italic></source>
<volume>27</volume>
<fpage>.e21</fpage>–<lpage>.e390</lpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2012.12.010</pub-id>
<?supplied-pmid 23462686?><pub-id pub-id-type="pmid">23462686</pub-id></mixed-citation>
              </ref>
              <ref id="B13">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gusev</surname><given-names>A. N.</given-names></name><name><surname>Engalychev</surname><given-names>V. F.</given-names></name><name><surname>Zakharova</surname><given-names>N. A.</given-names></name></person-group> (<year>2018</year>). “<article-title>Modern trends in the use of software and hardware in assessing the psychoemotional state of a person</article-title>,” in <source><italic>Hardware in psychological training (in Russian)</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Karayani</surname><given-names>A. G.</given-names></name><name><surname>Danilov</surname><given-names>S. I.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Military University</publisher-name>), <fpage>110</fpage>–<lpage>117</lpage>.</mixed-citation>
              </ref>
              <ref id="B14">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gushchin</surname><given-names>V. I.</given-names></name><name><surname>Savinkina</surname><given-names>A. O.</given-names></name><name><surname>Shved</surname><given-names>D. M.</given-names></name></person-group> (<year>2020</year>). “<article-title>Analysis of the emotional state participants in a 4-month isolation experiment using the assessment method facial expressions FaceReader</article-title>,” in <source><italic>Abstracts of the IV International Scientific practical conference “Topical issues of forensic psychological examination and comprehensive examination with the participation of a psychologist. Modern computer technologies in expert practice”. December 18-19</italic></source> (<publisher-loc>Kaluga</publisher-loc>), <fpage>9</fpage>.</mixed-citation>
              </ref>
              <ref id="B15">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gushchin</surname><given-names>V. I.</given-names></name><name><surname>Vinokhodova</surname><given-names>A. G.</given-names></name><name><surname>Komissarova</surname><given-names>D. V.</given-names></name><name><surname>Belakovsky</surname><given-names>M. S.</given-names></name><name><surname>Orlov</surname><given-names>O. I.</given-names></name></person-group> (<year>2018</year>). <article-title>Experiments with isolation: the past, present and future.</article-title>
<source><italic>Aviak. Ekologic. Med.</italic></source>
<volume>4</volume>:<fpage>5</fpage>. <pub-id pub-id-type="doi">10.21687/0233-528X-2018-52-4-5-16</pub-id></mixed-citation>
              </ref>
              <ref id="B16">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gushin</surname><given-names>V. I.</given-names></name><name><surname>Yusupova</surname><given-names>A. K.</given-names></name><name><surname>Shved</surname><given-names>D. M.</given-names></name><name><surname>Shueva</surname><given-names>L. V.</given-names></name><name><surname>Vinokhodova</surname><given-names>A.</given-names></name><name><surname>Bubeev</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>The evolution of methodological approaches to the psychological analysis of the crew communications with Mission Control Center.</article-title>
<source><italic>REACH – Rev. Hum. Space Explorat.</italic></source>
<volume>1</volume>
<fpage>74</fpage>–<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1016/j.reach.2016.05.001</pub-id></mixed-citation>
              </ref>
              <ref id="B17">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johannes</surname><given-names>B.</given-names></name><name><surname>Salnitski</surname><given-names>V. P.</given-names></name><name><surname>Gunga</surname><given-names>H. C.</given-names></name><name><surname>Kirsch</surname><given-names>K.</given-names></name></person-group> (<year>2000</year>). <article-title>Voice stress monitoring in space: possibilities and limits.</article-title>
<source><italic>Aviat Space Environ Med.</italic></source>
<volume>71</volume>(<issue>9 Suppl.</issue>), <fpage>58</fpage>–<lpage>65</lpage>.</mixed-citation>
              </ref>
              <ref id="B18">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johannes</surname><given-names>B.</given-names></name><name><surname>Salnitski</surname><given-names>V.</given-names></name><name><surname>Soll</surname><given-names>H.</given-names></name><name><surname>Rauch</surname><given-names>M.</given-names></name><name><surname>Hoermann</surname><given-names>H.</given-names></name></person-group> (<year>2008</year>). <article-title>Deindividualized psychophysiological strain assessment during a flight simulation test – validation of a space methodology.</article-title>
<source><italic>Acta Astronaut.</italic></source>
<volume>63</volume>
<fpage>791</fpage>–<lpage>799</lpage>.</mixed-citation>
              </ref>
              <ref id="B19">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johannes</surname><given-names>B.</given-names></name><name><surname>Wittels</surname><given-names>P.</given-names></name><name><surname>Enne</surname><given-names>R.</given-names></name><name><surname>Eisinger</surname><given-names>G.</given-names></name><name><surname>Castro</surname><given-names>C. A.</given-names></name><name><surname>Thomas</surname><given-names>J. L.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Non-linear function model of voice pitch dependency on physical and mental load.</article-title>
<source><italic>Eur. J. Appl. Physiol.</italic></source>
<volume>101</volume>
<fpage>267</fpage>–<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1007/s00421-007-0496-6</pub-id>
<?supplied-pmid 17554549?><pub-id pub-id-type="pmid">17554549</pub-id></mixed-citation>
              </ref>
              <ref id="B20">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kartavenko</surname><given-names>M. V.</given-names></name></person-group> (<year>2005</year>). <article-title>About the use of acoustic characteristics of speech for the diagnosis of human mental states.</article-title>
<source><italic>Izvestiya YuFU. Tekhnicheskie nauki</italic></source>
<volume>2005</volume>:<fpage>5</fpage>.</mixed-citation>
              </ref>
              <ref id="B21">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerstman</surname><given-names>E. L.</given-names></name><name><surname>Scheuring</surname><given-names>R. A.</given-names></name><name><surname>Barnes</surname><given-names>M. G.</given-names></name><name><surname>DeKorse</surname><given-names>T. B.</given-names></name><name><surname>Saile</surname><given-names>L. G.</given-names></name></person-group> (<year>2012</year>). <article-title>Space adaptation back pain: a retrospective study.</article-title>
<source><italic>Aviat. Space Environ. Med.</italic></source>
<volume>83</volume>
<fpage>2</fpage>–<lpage>7</lpage>. <pub-id pub-id-type="doi">10.3357/ASEM.2876.2012</pub-id>
<?supplied-pmid 22272509?><pub-id pub-id-type="pmid">22272509</pub-id></mixed-citation>
              </ref>
              <ref id="B22">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kudielka</surname><given-names>B. M.</given-names></name><name><surname>Kirschbaum</surname><given-names>C.</given-names></name></person-group> (<year>2005</year>). <article-title>Sex differences in HPA axis responses to stress: a review.</article-title>
<source><italic>Biol. Psychol.</italic></source>
<volume>69</volume>
<fpage>113</fpage>–<lpage>132</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2004.11.009</pub-id>
<?supplied-pmid 15740829?><pub-id pub-id-type="pmid">15740829</pub-id></mixed-citation>
              </ref>
              <ref id="B23">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laukka</surname><given-names>P.</given-names></name><name><surname>Linnman</surname><given-names>C.</given-names></name><name><surname>Ahs</surname><given-names>F.</given-names></name><name><surname>Pissiota</surname><given-names>A.</given-names></name><name><surname>Fran</surname><given-names>O.</given-names></name><name><surname>Faria</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>In a nervous voice: Acoustic analysis and perception of anxiety in social phobics’ speech.</article-title>
<source><italic>J. Nonverb. Behav.</italic></source>
<volume>32</volume>
<fpage>195</fpage>–<lpage>214</lpage>. <pub-id pub-id-type="doi">10.1007/s10919-008-0055-9</pub-id></mixed-citation>
              </ref>
              <ref id="B24">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebedeva</surname><given-names>S. A.</given-names></name><name><surname>Shved</surname><given-names>D. M.</given-names></name><name><surname>Fedyai</surname><given-names>S. O.</given-names></name></person-group> (<year>2020</year>). <article-title>Investigation of human psychophysiological state in the conditions simulating the microgravity effects using the acoustic method of speech analysis.</article-title>
<source><italic>Aviakosmicheskaya i Ekologicheskaya Meditsina</italic></source>
<volume>54</volume>
<fpage>45</fpage>–<lpage>51</lpage>. <pub-id pub-id-type="doi">10.21687/0233-528x-2020-54-2-45-51</pub-id></mixed-citation>
              </ref>
              <ref id="B25">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebedeva</surname><given-names>S. A.</given-names></name><name><surname>Shved</surname><given-names>D. M.</given-names></name></person-group> (<year>2021</year>). <article-title>Comparison of the human psychophysiological status in the conditions of simulated microgravity without countermeasures and during rotation on a short-arm centrifuge.</article-title>
<source><italic>Aviakosmicheskaya i Ekologicheskaya Meditsina</italic></source>
<volume>55</volume>
<fpage>98</fpage>–<lpage>101</lpage>. <pub-id pub-id-type="doi">10.21687/0233-528x-2021-55-2-98-101</pub-id></mixed-citation>
              </ref>
              <ref id="B26">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Loijens</surname><given-names>L.</given-names></name><name><surname>Krips</surname><given-names>O.</given-names></name></person-group> (<year>2018</year>). <source><italic>FaceReader Methodology Note.</italic></source>
<publisher-loc>Netherlands</publisher-loc>: <publisher-name>Behavioral research consultants at Noldus Information Technology</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B27">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mcnair</surname><given-names>D. M.</given-names></name><name><surname>Lorr</surname><given-names>M.</given-names></name><name><surname>Droppleman</surname><given-names>L. F.</given-names></name></person-group> (<year>1971</year>). <source><italic>Manual for the profile of mood states.</italic></source>
<publisher-loc>San. Diego, CA</publisher-loc>: <publisher-name>Educational and Industrial Testing Services</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B28">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikhailov</surname><given-names>V. M.</given-names></name><name><surname>Reushkin</surname><given-names>V. N.</given-names></name><name><surname>Reushkina</surname><given-names>G. D.</given-names></name><name><surname>Sebekina</surname><given-names>T. V.</given-names></name><name><surname>Smirnova</surname><given-names>T. M.</given-names></name></person-group> (<year>1995</year>). <article-title>Using variance analysis for the influence of immersion and individuality on the variability of orthostatic reactions.</article-title>
<source><italic>Aviakosm Ekolog Med.</italic></source>
<volume>6</volume>
<fpage>26</fpage>–<lpage>32</lpage>.</mixed-citation>
              </ref>
              <ref id="B29">
                <mixed-citation publication-type="journal"><collab>National Aeronautics and Space Administration and the National Center for Gender Physiology and Environmental Adaptation</collab> (<year>2002</year>). <source><italic>Sex, Space and Environmental Adaptation: A National Workshop on Research Priorities on Sex Differences in Human Responses to Challenging Environments.</italic></source> Available online at: <ext-link xlink:href="https://www.nasa.gov/pdf/185051main_environmental_adaptation_workshop_11-2002.pdf" ext-link-type="uri">https://www.nasa.gov/pdf/185051main_environmental_adaptation_workshop_11-2002.pdf</ext-link>
<comment>(accessed June 31, 2021)</comment>.</mixed-citation>
              </ref>
              <ref id="B30">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nikonov</surname><given-names>A. V.</given-names></name></person-group> (<year>1985</year>). <source><italic>Psychological problems of acoustic diagnostics of functional states of an operator.</italic></source>
<publisher-loc>Moscow</publisher-loc>: <publisher-name>Psychological problems of activity in special conditions</publisher-name>, <fpage>136</fpage>–<lpage>153</lpage>.</mixed-citation>
              </ref>
              <ref id="B31">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oluwafemi</surname><given-names>F. A.</given-names></name><name><surname>Abdelbaki</surname><given-names>R.</given-names></name><name><surname>Lai</surname><given-names>J. C.-Y.</given-names></name><name><surname>Mora-Almanza</surname><given-names>J. G.</given-names></name><name><surname>Afolayan</surname><given-names>E. M.</given-names></name></person-group> (<year>2021</year>). <article-title>A review of astronaut mental health in manned missions: Potential interventions for cognitive and mental health challenges.</article-title>
<source><italic>Life Sci. Space Res.</italic></source>
<volume>28</volume>
<fpage>26</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1016/j.lssr.2020.12.002</pub-id>
<?supplied-pmid 33612177?><pub-id pub-id-type="pmid">33612177</pub-id></mixed-citation>
              </ref>
              <ref id="B32">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orlov</surname><given-names>V. N.</given-names></name></person-group> (<year>1985</year>). <article-title>Influence of Dry Immersion model on the performance of water-salt exchange, aldosterone and cortisol level in plasma in patients with different degree of hydration of the body.</article-title>
<source><italic>Space Biol. Aerospace Med.</italic></source>
<volume>4</volume>
<fpage>42</fpage>–<lpage>45</lpage>.</mixed-citation>
              </ref>
              <ref id="B33">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>Y.</given-names></name><name><surname>Stepp</surname><given-names>C. E.</given-names></name></person-group> (<year>2019</year>). <article-title>The Effects of Stress Type, Vowel Identity, Baseline f0, and Loudness on the Relative Fundamental Frequency of Individuals With Healthy Voices.</article-title>
<source><italic>J. Voice</italic></source>
<volume>33</volume>
<fpage>603</fpage>–<lpage>610</lpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2018.04.004</pub-id>
<?supplied-pmid 30078521?><pub-id pub-id-type="pmid">30078521</pub-id></mixed-citation>
              </ref>
              <ref id="B34">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pisanski</surname><given-names>K.</given-names></name><name><surname>Aleksander</surname><given-names>K.</given-names></name><name><surname>Luba</surname><given-names>J.</given-names></name><name><surname>Judyta</surname><given-names>N.</given-names></name><name><surname>Amelia</surname><given-names>W.</given-names></name><name><surname>Kamil</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Multimodal stress detection: testing for covariation in vocal, hormonal and physiological responses to Trier Social Stress Test.</article-title>
<source><italic>Horm Behav.</italic></source>
<volume>106</volume>
<fpage>52</fpage>–<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1016/j.yhbeh.2018.08.014</pub-id>
<?supplied-pmid 30189213?><pub-id pub-id-type="pmid">30189213</pub-id></mixed-citation>
              </ref>
              <ref id="B35">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rothkrantz</surname><given-names>J. M.</given-names></name></person-group> (<year>2004</year>). “<article-title>Voice stress analysis</article-title>,” in <source><italic>Conference Paper in Lecture Notes in Computer Science</italic></source> (<publisher-name>Springer Science+Business Media</publisher-name>).</mixed-citation>
              </ref>
              <ref id="B36">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez</surname><given-names>K.</given-names></name><name><surname>Oates</surname><given-names>J.</given-names></name><name><surname>Dacakis</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Speech and voice range profilesof adults with untrained normal voices: Methodological implications.</article-title>
<source><italic>Logop Phoniatr. Vocol.</italic></source>
<volume>39</volume>
<fpage>62</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.3109/14015439.2013.777109</pub-id>
<?supplied-pmid 23590284?><pub-id pub-id-type="pmid">23590284</pub-id></mixed-citation>
              </ref>
              <ref id="B37">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saralyn</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>The impact of sex and gender on human adaptation to space.</article-title>
<source><italic>Gend. Med. Vol.</italic></source>
<volume>3</volume>:<fpage>22</fpage>.</mixed-citation>
              </ref>
              <ref id="B38">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shul’zhenko</surname><given-names>E. B.</given-names></name><name><surname>Vill-Villiams</surname><given-names>I. F.</given-names></name></person-group> (<year>1976</year>). <article-title>Possibility of carrying outprolonged water immersion by the method of “dry” immersion (in Russian).</article-title>
<source><italic>Kosm. Biol. Aviakosm. Med.</italic></source>
<volume>10</volume>
<fpage>82</fpage>–<lpage>84</lpage>.</mixed-citation>
              </ref>
              <ref id="B39">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spielberger</surname><given-names>C. D.</given-names></name></person-group> (<year>2010</year>). <source><italic>State-trait anxiety inventory. The Corsini encyclopedia of psychology.</italic></source>
<publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley &amp; Sons, Inc</publisher-name>. <pub-id pub-id-type="doi">10.1002/9780470479216.corpsy0943</pub-id></mixed-citation>
              </ref>
              <ref id="B40">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stöckli</surname><given-names>S.</given-names></name><name><surname>Schulte-Mecklenbeck</surname><given-names>M.</given-names></name><name><surname>Borer</surname><given-names>S.</given-names></name><name><surname>Samson</surname><given-names>A. C.</given-names></name></person-group> (<year>2018</year>). <article-title>Facial expression analysis with AFFDEX and FACET: A validation study.</article-title>
<source><italic>Behav. Res. Methods. V.</italic></source>
<volume>50</volume>
<fpage>1446</fpage>–<lpage>1460</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-017-0996-1</pub-id>
<?supplied-pmid 29218587?><pub-id pub-id-type="pmid">29218587</pub-id></mixed-citation>
              </ref>
              <ref id="B41">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Supolkina</surname><given-names>N. S.</given-names></name><name><surname>Yusupova</surname><given-names>A. K.</given-names></name><name><surname>Shved</surname><given-names>D. M.</given-names></name><name><surname>Chekalina</surname><given-names>A. I.</given-names></name><name><surname>Sarantsev</surname><given-names>S. V.</given-names></name><name><surname>Gushchin</surname><given-names>V. I.</given-names></name></person-group> (<year>2019</year>). <article-title>Communication behavior of the crew when communicating with the control center in experiment sirius-17.</article-title>
<source><italic>Aerosp. Env. Med.</italic></source>
<volume>53</volume>
<fpage>68</fpage>–<lpage>73</lpage>. <pub-id pub-id-type="doi">10.21687/0233-528X-2019-53-2-68-73</pub-id></mixed-citation>
              </ref>
              <ref id="B42">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teixeira</surname><given-names>J. P.</given-names></name><name><surname>Fernandes</surname><given-names>P. O.</given-names></name></person-group> (<year>2014</year>). <article-title>Jitter, Shimmer and HNR classification within gender, tones and vowels in healthy voices.</article-title>
<source><italic>Proced.</italic></source> T<source><italic>ech.</italic></source>
<volume>16</volume>
<fpage>1228</fpage>–<lpage>1237</lpage>. <pub-id pub-id-type="doi">10.1016/j.protcy.2014.10.138</pub-id></mixed-citation>
              </ref>
              <ref id="B43">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teixeira</surname><given-names>J. P.</given-names></name><name><surname>Gonçalves</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Algorithm for jitter and shimmer measurement in pathologic voices.</article-title>
<source><italic>Proced. Comp. Sci.</italic></source>
<volume>100</volume>
<fpage>271</fpage>–<lpage>279</lpage>. <pub-id pub-id-type="doi">10.1016/j.procs.2016.09.155</pub-id></mixed-citation>
              </ref>
              <ref id="B44">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Teixeira</surname><given-names>J. P.</given-names></name><name><surname>Ferreira</surname><given-names>D.</given-names></name><name><surname>Carneiro</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). “<article-title>Análise acústica vocal - determinação do Jitter e Shimmer para diagnóstico de patalogias da fala</article-title>,” in <source><italic>6° Congresso Luso-Moçambicano de Engenharia</italic></source> (<publisher-loc>Maputo</publisher-loc>).</mixed-citation>
              </ref>
              <ref id="B45">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomilovskaya</surname><given-names>E.</given-names></name><name><surname>Amirova</surname><given-names>L.</given-names></name><name><surname>Nosikova</surname><given-names>I.</given-names></name><name><surname>Rukavishnikov</surname><given-names>I.</given-names></name><name><surname>Chernogorov</surname><given-names>R.</given-names></name><name><surname>Lebedeva</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>The First Female Dry Immersion (NAIAD-2020): Design and Specifics of a 3-Day Study.</article-title>
<source><italic>Front. Physiol.</italic></source>
<volume>12</volume>:<fpage>284</fpage>. <pub-id pub-id-type="doi">10.3389/fphys.2021.661959</pub-id>
<?supplied-pmid 34194336?><pub-id pub-id-type="pmid">34194336</pub-id></mixed-citation>
              </ref>
              <ref id="B46">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomilovskaya</surname><given-names>E.</given-names></name><name><surname>Shigueva</surname><given-names>T.</given-names></name><name><surname>Sayenko</surname><given-names>D.</given-names></name><name><surname>Rukavishnikov</surname><given-names>I.</given-names></name><name><surname>Kozlovskaya</surname><given-names>I.</given-names></name></person-group> (<year>2019</year>). <article-title>Dry Immersion as a Ground-Based Model of Microgravity Physiological Effects.</article-title>
<source><italic>Front. Physiol.</italic></source>
<volume>10</volume>:<fpage>284</fpage>. <pub-id pub-id-type="doi">10.3389/fphys.2019.00284</pub-id>
<?supplied-pmid 30971938?><pub-id pub-id-type="pmid">30971938</pub-id></mixed-citation>
              </ref>
              <ref id="B47">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tullett</surname><given-names>A. M.</given-names></name><name><surname>Inzlicht</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>The voice of self-control: Blocking the inner voice increases impulsive responding.</article-title>
<source><italic>Acta Psychol.</italic></source>
<volume>135</volume>
<fpage>252</fpage>–<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1016/j.actpsy.2010.07.008</pub-id>
<?supplied-pmid 20692639?><pub-id pub-id-type="pmid">20692639</pub-id></mixed-citation>
              </ref>
              <ref id="B48">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ushakov</surname><given-names>I. B.</given-names></name><name><surname>Ivanov</surname><given-names>A. V.</given-names></name><name><surname>Kvasovets</surname><given-names>S. V.</given-names></name><name><surname>Bubeev Yu</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>Neurosemantic and psychophysiological correlates of rhythm-suggestive correction of stress conditions.</article-title>
<source><italic>Aviakosmicheskaya i ekologicheskaya meditsina</italic></source>
<volume>49</volume>
<fpage>55</fpage>–<lpage>60</lpage>.</mixed-citation>
              </ref>
              <ref id="B49">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wollseiffen</surname><given-names>P.</given-names></name><name><surname>Vogt</surname><given-names>T.</given-names></name><name><surname>Abeln</surname><given-names>V.</given-names></name><name><surname>Strüder</surname><given-names>H. K.</given-names></name><name><surname>Askew</surname><given-names>C. D.</given-names></name><name><surname>Schneider</surname><given-names>S.</given-names></name></person-group> (<year>2016</year>). <article-title>Neuro-cognitive performance is enhanced during short-periods of microgravity.</article-title>
<source><italic>Physiol. Behav.</italic></source>
<volume>155</volume>
<fpage>9</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1016/j.physbeh.2015.11.036</pub-id>
<?supplied-pmid 26657021?><pub-id pub-id-type="pmid">26657021</pub-id></mixed-citation>
              </ref>
              <ref id="B50">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name></person-group> (<year>2016</year>). <article-title>Mechanics of human voice production and control.</article-title>
<source><italic>J. Acoust. Soc. Am.</italic></source>
<volume>140</volume>:<fpage>2614</fpage>. <pub-id pub-id-type="doi">10.1121/1.4964509</pub-id>
<?supplied-pmid 27794319?><pub-id pub-id-type="pmid">27794319</pub-id></mixed-citation>
              </ref>
              <ref id="B51">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zwetsch</surname><given-names>I.</given-names></name><name><surname>Fagundes</surname><given-names>R.</given-names></name><name><surname>Russomano</surname><given-names>T.</given-names></name><name><surname>Scolari</surname><given-names>D.</given-names></name></person-group> (<year>2006</year>). <source><italic>Digital signal processing in the differential diagnosis of beningn larynx diseases.</italic></source>
<publisher-loc>Porto Alegre</publisher-loc>: <publisher-name>Directory of Open Access Journals</publisher-name>.</mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
