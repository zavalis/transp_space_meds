<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2023-02-23T14:52:09Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:8420811" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:8420811</identifier>
        <datestamp>2021-09-07</datestamp>
        <setSpec>fronthumneuro</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article" dtd-version="1.3">
          <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
            <restricted-by>pmc</restricted-by>
          </processing-meta>
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">Front Hum Neurosci</journal-id>
              <journal-id journal-id-type="iso-abbrev">Front Hum Neurosci</journal-id>
              <journal-id journal-id-type="publisher-id">Front. Hum. Neurosci.</journal-id>
              <journal-title-group>
                <journal-title>Frontiers in Human Neuroscience</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1662-5161</issn>
              <publisher>
                <publisher-name>Frontiers Media S.A.</publisher-name>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC8420811</article-id>
              <article-id pub-id-type="pmcid">PMC8420811</article-id>
              <article-id pub-id-type="pmc-uid">8420811</article-id>
              <article-id pub-id-type="pmid">34497497</article-id>
              <article-id pub-id-type="doi">10.3389/fnhum.2021.642025</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Human Neuroscience</subject>
                  <subj-group>
                    <subject>Hypothesis and Theory</subject>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Gravity and Known Size Calibrate Visual Information to Time Parabolic Trajectories</article-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Aguado</surname>
                    <given-names>Borja</given-names>
                  </name>
                  <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1169293/overview"/>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>López-Moliner</surname>
                    <given-names>Joan</given-names>
                  </name>
                  <xref ref-type="corresp" rid="c001">
                    <sup>*</sup>
                  </xref>
                  <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/34332/overview"/>
                </contrib>
              </contrib-group>
              <aff><institution>Vision and Control of Action (VISCA) Group, Department of Cognition, Development and Psychology of Education, Institut de Neurociències, Universitat de Barcelona</institution>, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff>
              <author-notes>
                <fn fn-type="edited-by">
                  <p>Edited by: Paul Michael Corballis, The University of Auckland, New Zealand</p>
                </fn>
                <fn fn-type="edited-by">
                  <p>Reviewed by: Frank T. J. M. Zaal, University of Groningen, Netherlands; Dennis Shaffer, Ohio State University at Mansfield, United States</p>
                </fn>
                <corresp id="c001">*Correspondence: Joan López-Moliner <email>j.lopezmoliner@ub.edu</email></corresp>
                <fn fn-type="other" id="fn001">
                  <p><bold>Specialty section:</bold> This article was submitted to Sensory Neuroscience, a section of the journal Frontiers in Human Neuroscience</p>
                </fn>
              </author-notes>
              <pub-date pub-type="epub">
                <day>23</day>
                <month>8</month>
                <year>2021</year>
              </pub-date>
              <pub-date pub-type="collection">
                <year>2021</year>
              </pub-date>
              <volume>15</volume>
              <elocation-id>642025</elocation-id>
              <history>
                <date date-type="received">
                  <day>15</day>
                  <month>12</month>
                  <year>2020</year>
                </date>
                <date date-type="accepted">
                  <day>28</day>
                  <month>7</month>
                  <year>2021</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>Copyright © 2021 Aguado and López-Moliner.</copyright-statement>
                <copyright-year>2021</copyright-year>
                <copyright-holder>Aguado and López-Moliner</copyright-holder>
                <license>
                  <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
                </license>
              </permissions>
              <abstract>
                <p>Catching a ball in a parabolic flight is a complex task in which the time and area of interception are strongly coupled, making interception possible for a short period. Although this makes the estimation of time-to-contact (TTC) from visual information in parabolic trajectories very useful, previous attempts to explain our precision in interceptive tasks circumvent the need to estimate TTC to guide our action. Obtaining TTC from optical variables alone in parabolic trajectories would imply very complex transformations from 2D retinal images to a 3D layout. We propose based on previous work and show by using simulations that exploiting prior distributions of gravity and known physical size makes these transformations much simpler, enabling predictive capacities from minimal early visual information. Optical information is inherently ambiguous, and therefore, it is necessary to explain how these prior distributions generate predictions. Here is where the role of prior information comes into play: it could help to interpret and calibrate visual information to yield meaningful predictions of the remaining TTC. The objective of this work is: (1) to describe the primary sources of information available to the observer in parabolic trajectories; (2) unveil how prior information can be used to disambiguate the sources of visual information within a Bayesian encoding-decoding framework; (3) show that such predictions might be robust against complex dynamic environments; and (4) indicate future lines of research to scrutinize the role of prior knowledge calibrating visual information and prediction for action control.</p>
              </abstract>
              <kwd-group>
                <kwd>3D perception</kwd>
                <kwd>calibration</kwd>
                <kwd>internal models</kwd>
                <kwd>optic flow</kwd>
                <kwd>prior knowledge</kwd>
                <kwd>TTC</kwd>
              </kwd-group>
              <funding-group>
                <award-group>
                  <funding-source id="cn001">Agència de Gestió d’Ajuts Universitaris i de Recerca<named-content content-type="fundref-id">10.13039/501100003030</named-content></funding-source>
                </award-group>
                <award-group>
                  <funding-source id="cn002">Agencia Estatal de Investigación<named-content content-type="fundref-id">10.13039/501100011033</named-content></funding-source>
                </award-group>
              </funding-group>
              <counts>
                <fig-count count="9"/>
                <table-count count="0"/>
                <equation-count count="39"/>
                <ref-count count="167"/>
                <page-count count="19"/>
                <word-count count="16071"/>
              </counts>
            </article-meta>
          </front>
          <body>
            <sec sec-type="introduction" id="s1">
              <title>Introduction</title>
              <p>Intercepting a ball in a parabolic trajectory before reaching ground level is a fundamental task in different sports: batting a baseball, hitting a high lob in tennis, or heading a football. In those situations, the time at which the interception is possible is very tight, yet our performance is astonishing. Time-to-contact (from now on TTC), that is, the time until an object reaches a location of interest, can provide very useful information that would help anticipate motor programs to solve those tasks.</p>
              <p>In principle, to intercept a target, it would be enough to estimate its position and predict its future position based on speed estimates. Solutions based on this idea have been put forward for 2D motion (Kwon et al., <xref rid="B87" ref-type="bibr">2015</xref>; Aguilar-Lleyda et al., <xref rid="B4" ref-type="bibr">2018</xref>) but the generalization to 3D parabolic trajectories faces complex problems deeply rooted in the inverse-projection problem of Perception. The inverse problem of Perception refers to the ambiguous mapping between distal stimuli and final percept (Pizlo, <xref rid="B119" ref-type="bibr">2001</xref>; Kersten et al., <xref rid="B82" ref-type="bibr">2004</xref>). Unlike previous attempts where TTC is obtained from optical variables, in this article, we propose that some constants in the environment like gravity and size are considered and ease the otherwise complex transformation of optical variables to a 3D world to obtain relevant variables like TTC. The stance taken in this work will assume that we make implicit inferences (Von Helmholtz, <xref rid="B149" ref-type="bibr">1867</xref>) about the present and future states of the world to act. However, the nature of the information guiding the control of action is an ongoing source of debate within the study of Perception.</p>
            </sec>
            <sec id="s2">
              <title>Two Theories for Interceptive Control</title>
              <sec id="s2-1">
                <title>Information-Based Control</title>
                <p>The information-based control perspective, rooted in the Ecological or Gibsonian framework of Psychology (Gibson, <xref rid="B55" ref-type="bibr">1966</xref>, <xref rid="B56" ref-type="bibr">1979</xref>; <xref ref-type="fig" rid="F1">Figure 1A</xref>), assumes that perceptual information is governed by certain physical regularities (Turvey et al., <xref rid="B148" ref-type="bibr">1981</xref>) that can be captured and exploited to control our action. Under ecologically valid conditions (i.e., full-cue conditions), our perceptual system would be attuned to perceptual invariants directly specifying the characteristics of an event without the need to perform internal computations according to which humans act (Gibson, <xref rid="B56" ref-type="bibr">1979</xref>). Thus, the information to solve a given task is directly specified in the optic flow (direct perception) explaining why only identifying task-relevant visual variables will determine an actor’s successful action from a perceptual perspective.</p>
                <fig id="F1" orientation="portrait" position="float">
                  <label>Figure 1</label>
                  <caption>
                    <p><bold>(A)</bold> Optic flow conforms to invariants that specify properties of the environment (direct perception), indicating the adequacy and availability of action within the task. <bold>(B)</bold> Sensory stimulation is combined with prior information to infer current or future states in the environment (read-out), providing the grounds to plan and adapt action.</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0001"/>
                </fig>
                <p>Under this framework, mainstream interpretations argue that the role of the observer is to actively seek out invariants within certain task-relevant pieces of optic information and unfold a coupled action based on instantaneous information. Following this line, detecting and maintaining invariant stimulation requires reducing the difference or the error with an “ideal value.” Because of that, these strategies are also called error-nulling strategies (Fajen, <xref rid="B50" ref-type="bibr">2005b</xref>). Based on this idea, different control laws have been proposed for visually guided actions such as intercepting a moving object (Warren et al., <xref rid="B151" ref-type="bibr">2001</xref>; Wilkie and Wann, <xref rid="B158" ref-type="bibr">2003</xref>; Bruggeman et al., <xref rid="B28" ref-type="bibr">2007</xref>; Zhao et al., <xref rid="B168" ref-type="bibr">2019</xref>), braking (Lee, <xref rid="B89" ref-type="bibr">1976</xref>) or catching a ball on the fly (Chapman, <xref rid="B32" ref-type="bibr">1968</xref>; Michaels and Oudejans, <xref rid="B109" ref-type="bibr">1992</xref>; McLeod and Dienes, <xref rid="B106" ref-type="bibr">1993</xref>; McBeath et al., <xref rid="B102" ref-type="bibr">1995</xref>).</p>
                <p>Among the previous examples, catching a ball in a parabolic flight is a paradigmatic interception case including locomotion and manual interceptive phases. The study of the underlying mechanisms regarding the locomotive phase is usually referred to as the outfielder problem (Todd, <xref rid="B146" ref-type="bibr">1981</xref>). The outfielder problem studies a case of interception in which baseball players known as outfielders must move to catch a high-flying ball in a parabolic trajectory before it hits the ground (Chapman, <xref rid="B32" ref-type="bibr">1968</xref>; Todd, <xref rid="B146" ref-type="bibr">1981</xref>; Michaels and Oudejans, <xref rid="B109" ref-type="bibr">1992</xref>).</p>
                <p>The first catching error-nulling strategy put forward to explain action control within the outfielder problem was Chapman’s strategy (Chapman, <xref rid="B32" ref-type="bibr">1968</xref>). S. Chapman noticed that when a ball follows a parabolic trajectory on a collision course with the observer, the elevation angle (γ; see <xref ref-type="fig" rid="F2">Figure 2</xref>), that is, the vertical angle between the ball’s position and an observer’s eye level, increases during the whole trajectory. Therefore, all an observer would need to do to navigate towards the interception location is keeping the elevation angle increasing during the whole trajectory at a constant rate. However, others suggested it should increase at a decreasing rate (McLeod and Dienes, <xref rid="B106" ref-type="bibr">1993</xref>, <xref rid="B107" ref-type="bibr">1996</xref>).</p>
                <fig id="F2" orientation="portrait" position="float">
                  <label>Figure 2</label>
                  <caption>
                    <p>Lateral view of a parabolic trajectory depicting the primary primitive monocular cues, that is, retinal size (green projection; θ) and elevation angle (orange projection; γ).</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0002"/>
                </fig>
                <p>Later, Michaels and Oudejans (<xref rid="B109" ref-type="bibr">1992</xref>) described Chapman’s strategy in terms of the projected image in the vertical plane at launch distance. If the ball is in a collision course with the viewer, the vertical projection of the ball increases linearly through the trajectory. In any other case, the image of the ball would displace non-linearly, that is, accelerated. Therefore, to catch a ball in a parabolic trajectory, one needs to actively maintain the acceleration of the projected vertical position of the ball at zero. Motivated by that, this strategy was named Optic Acceleration Cancellation (from now on, OAC) in McBeath et al. (<xref rid="B102" ref-type="bibr">1995</xref>).</p>
                <p>Although the error-nulling strategies emerged within the ecological framework, they conflict with a key concept at the core of the Ecological theory, the theory of affordances (Gibson, <xref rid="B56" ref-type="bibr">1979</xref>). The affordance-based theory emphasizes the idea that observers are tuned to the availability of an action given a sensory array. This tuning would be a by-product of a gauging process that maps optic into movement information and even into optic correlates in object size units (Peper et al., <xref rid="B117" ref-type="bibr">1994</xref>; Jacobs and Michaels, <xref rid="B71" ref-type="bibr">2006</xref>). Hence, if a fielder is correctly calibrated, acting to keep certain variables of interest into a “safe region” would ensure interception. This notion provides the grounds for an affordance-based control strategy theory (Fajen, <xref rid="B51" ref-type="bibr">2007</xref>).</p>
                <p>Reformulating the OAC under the scope of the affordance-based control, either canceling out vertical acceleration or running at maximum speed without being able to cancel out vertical acceleration, would be required to perceive catchability. However, a series of studies (Postma et al., <xref rid="B122" ref-type="bibr">2017</xref>, <xref rid="B123" ref-type="bibr">2018</xref>) found that actual catchers did not need to cancel out acceleration nor run at their maximum speed to judge catchability. These results cast doubts on the informational nature of a catchability affordance.</p>
                <p>Despite a lesser dependence on immediate visual information, an affordance-based control strategy is still dependent on instantaneous visual information. In this respect, simulations of the locomotion based on error-nulling strategies were irreconcilable with actual catches when accounting for human neuromotor acceleration and sensorimotor integration delays (McLeod and Dienes, <xref rid="B107" ref-type="bibr">1996</xref>; Kistemaker et al., <xref rid="B84" ref-type="bibr">2006</xref>, <xref rid="B83" ref-type="bibr">2009</xref>). Consequently, a minimal prediction seems necessary to account for sensorimotor delays in the central nervous system (Nijhawan, <xref rid="B113" ref-type="bibr">1994</xref>). Furthermore, the occlusion of visual information would result in a considerable impairment of the action. A possible solution to provide adequate responses would be to continue to do what has been done so far (Bootsma, <xref rid="B16" ref-type="bibr">2009</xref>). Nevertheless, in temporally constrained tasks, another question arises: for how long? In the outfielder problem, catching the ball in-flight imposes tight temporal restrictions constraining the interception area. Hence, predicting parameters such as TTC or the interception area in dynamic contexts is key to planning our actions while looking around for a teammate, finding a safe path towards the goal, or modulating speed to reach the interception location in time. Following this reasoning, some alternatives have been proposed in the literature as solutions based on predictions about future states of the world.</p>
              </sec>
              <sec id="s2-2">
                <title>Model-Based Control</title>
                <p>The model-based control is framed within the constructivist framework (Von Helmholtz, <xref rid="B149" ref-type="bibr">1867</xref>). It assumes that the information picked up by our senses is inherently ambiguous, to some degree corrupted by noise in the neural system and delayed at higher-order brain areas. Craik (<xref rid="B35" ref-type="bibr">1967</xref>) proposed that the brain tries to infer and replicate an external world model given the available sensory information. This replica results in an internal model of the environment, including an agent’s state that allows one to predict future states of the world and act accordingly avoiding sensorimotor delays.</p>
                <p>Relying on predictions would allow us to divert our gaze from the immediate region of interest and consequently interrupt the sensory flow. For example, Hayhoe et al. (<xref rid="B65" ref-type="bibr">2005</xref>) and Diaz et al. (<xref rid="B45" ref-type="bibr">2013</xref>) showed anticipatory saccades towards future interest points to plan future goal states. The same applies to catching a ball in a parabolic trajectory for manual interception tasks. Despite distractors, parallel tasks, occlusions or head-turns that might divert our attention, we still manage to intercept a ball in flight (Dessing et al., <xref rid="B44" ref-type="bibr">2009</xref>; López-Moliner et al., <xref rid="B95" ref-type="bibr">2010</xref>; López-Moliner and Brenner, <xref rid="B93" ref-type="bibr">2016</xref>; Binaee and Diaz, <xref rid="B13" ref-type="bibr">2019</xref>) In fact, we can hit it even when the ball was visible for just a short time (Sharp and Whiting, <xref rid="B137" ref-type="bibr">1974</xref>; Whiting and Sharp, <xref rid="B157" ref-type="bibr">1974</xref>; Amazeen et al., <xref rid="B6" ref-type="bibr">1999</xref>), revealing that actually, the major constraint for the use of a predictive strategy would be to obtain predictions early enough to overcome sensory-motor delays.</p>
                <p>The trajectory prediction strategy (Saxberg, <xref rid="B133" ref-type="bibr">1987a</xref>,<xref rid="B134" ref-type="bibr">b</xref>), framed within the model-based theory, assumes that an observer predicts where and when the ball will be within reach in Cartesian units, allowing to pre-program a minimal action plan since motion onset. However, the available optic information is egocentric and therefore ambiguous with respect to its source. Therefore, an observer must perform an inferential process to interpret optic information accurately.</p>
                <p>In this line, Perception has been proposed as a Bayesian inferential process in which visual information is interpreted as a function of the most probable state of the world given prior knowledge. This inferential process has been formulated in terms of “encoding” and “decoding” (Knill and Pouget, <xref rid="B86" ref-type="bibr">2004</xref>; Friston, <xref rid="B54" ref-type="bibr">2010</xref>; Wei and Stocker, <xref rid="B153" ref-type="bibr">2015</xref>). Encoding corresponds to the activity resulting from the transduction of external energy onto the sensory receptors. The encoded sensory information is then combined with prior knowledge through an inferential process called decoding (<xref ref-type="fig" rid="F1">Figure 1B</xref>). The product of the decoding is an interpretation (read-out) of the currently available data resulting in a belief of the state of the world that provides the grounds to draw predictions.</p>
                <p>In real life, we generally do not judge the parameters of a task for ambiguous targets in the environment. Instead, we have some prior knowledge of the elements to be judged that are stable and might help disambiguate optic information providing the grounds to extract valuable information for the task. In this line, a significant number of works highlighted the role of prior knowledge about contextual variables such as gravitational acceleration (McIntyre et al., <xref rid="B103" ref-type="bibr">2001</xref>; Jörges and López-Moliner, <xref rid="B73" ref-type="bibr">2017</xref>) or known/familiar size (López-Moliner et al., <xref rid="B96" ref-type="bibr">2007</xref>; Hosking and Crassini, <xref rid="B68" ref-type="bibr">2010</xref>), framing the interpretation of visual information for the control of timed actions.</p>
                <p>Note that using <italic>a priori</italic> knowledge does not imply the availability of accurate Cartesian metrics or Newtonian laws within an internal model. A fully-featured 3D internal model replicating the external world has been repeatedly dismissed. For example, Shaffer and McBeath (<xref rid="B135" ref-type="bibr">2005</xref>) showed that even expert baseball players could not judge the apex of a ballistic trajectory on a collision course with the observer. In this situation, the apex was estimated to be 0.33 s before collision for flight durations of 4 s, that is, 1.66 s after the actual apex. These results indicate a tendency to judge the apex of the elevation angle as the physical apex of the trajectory. Also, Reed et al. (<xref rid="B124" ref-type="bibr">2010</xref>) showed that neither expert nor novel baseball players could reconstruct the visual trajectory of a parabolic trajectory in a head-on approach mixing up the ball’s movement in space with the visual trajectory it follows.</p>
                <p>Unlike Craik (<xref rid="B35" ref-type="bibr">1967</xref>), however, we propose that the prior knowledge can be kept to a minimal number of components that help exploit the optic flow’s complexity. Thus, in line with a Bayesian framework, under our view, the use of prior knowledge just suggests the existence of a probabilistic and implicit knowledge acquired by repeated experience that helps infer the most probable sources of visual information in the external world (Zago et al., <xref rid="B166" ref-type="bibr">2008</xref>; Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>). In this sense, an accurate representation of <italic>a priori</italic> parameters would suffice to obtain reliable estimates of the task’s parameters.</p>
                <p>Here we propose using priors as internalized knowledge to translate optic variables into temporal estimates in a process we name calibration. Calibration would be the process by which optical or angular information is mapped into Cartesian ones with the assistance of different pieces of prior knowledge providing actionable predictions (López-Moliner et al., <xref rid="B96" ref-type="bibr">2007</xref>, <xref rid="B97" ref-type="bibr">2013</xref>). Calibrating optic cues into Cartesian allows us to test the correspondence between the prediction of a model and our actions in terms of accuracy. Furthermore, it may allow us to formulate a hypothesis based on known psychophysical precision levels for the different pieces of information in the sensory array and even check if integration rules apply (Wolpert et al., <xref rid="B159" ref-type="bibr">1995</xref>; de la Malla and López-Moliner, <xref rid="B40" ref-type="bibr">2015</xref>).</p>
                <p>As an example, the GS model (Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>) is an algorithm that predicts the TTC for parabolic trajectories based on a combination of optic variables and prior knowledge information. Its predictions have been partially validated based on predictions about the accuracy and the precision of temporal estimations (de la Malla and López-Moliner, <xref rid="B40" ref-type="bibr">2015</xref>; Aguado and López-Moliner, <xref rid="B3" ref-type="bibr">2021</xref>). However, there is a lack of mathematical formulation to predict the interception location. This makes it harder to test experimentally predictive control strategies within the outfielder problem. Hence, in this work, we will limit ourselves to indicate the role of TTC estimates guiding the interceptive action.</p>
                <p>It is essential to mention here that our definition of calibration is different from the definition of calibration made within the Ecologic framework (Fajen, <xref rid="B49" ref-type="bibr">2005a</xref>; Jacobs and Michaels, <xref rid="B72" ref-type="bibr">2007</xref>). Under our perspective, calibration is a process by which otherwise ambiguous optical information is directly mapped into kinematic and temporal estimates such as motion vectors or TTC highlighting the relevance of prior knowledge to provide predictions that may assist visually guided actions. In contrast, within the Ecological framework, calibration would be a by-product of a gauging process that maps visual information into movement information and even into optic correlates in object size units (Peper et al., <xref rid="B117" ref-type="bibr">1994</xref>; Jacobs and Michaels, <xref rid="B71" ref-type="bibr">2006</xref>).</p>
                <p>Nevertheless, producing predictions does not necessarily mean that those predictions will be accurate or that the new visual information would be disregarded. Take the case of Fink et al. (<xref rid="B52" ref-type="bibr">2009</xref>) study. Participants had to catch a ball in a parabolic trajectory that suddenly would alter its motion towards the ground. As a reaction, the catchers changed their trajectory towards the ball as well which was taken as support for the information-based control perspective. Under Fink et al. (<xref rid="B52" ref-type="bibr">2009</xref>) rationale, a model-based control strategy would result in a consistent path towards the interception point despite mid-flight disturbances. This rationale assumes that new information would be dismissed or might be irrelevant because the prediction would remain invariant. However, predictions would also be subject to continuous evaluations to avoid errors or perceptually driven biases. In a similar line, Postma et al. (<xref rid="B121" ref-type="bibr">2014</xref>) reasoned that continuously gazing the ball through the trajectory would support the information-based control perspective. However, following the ball with our gaze does not necessarily imply that action guidance must be driven by instantaneous optic information. Periodically sampling visual input to correct the prediction made would be an alternative strategy to guide action with reasonable levels of accuracy in a more general framework (Brenner and Smeets, <xref rid="B25" ref-type="bibr">2018</xref>). In fact, a simulation study conducted by Belousov et al. (<xref rid="B11" ref-type="bibr">2016</xref>) showed that predictive behavior would be indistinguishable from using error-nulling strategies if the ball is continuously monitored.</p>
                <p>In the following sections, we will unveil how the interaction between perceptual information and prior knowledge contributes to interpreting and reliably predict TTC for gravitationally accelerated objects under parabolic trajectories. To do so, we will first analyze the available sources of visual information within the optic flow to judge TTC or time an interceptive action. Then, we will stress the role of prior information in calibrating visual information. After that, we will show the accuracy and reliability of the GS model which includes known gravity and size in complex environments. Finally, we will indicate future lines of research to address the role of predictions of TTC guiding interceptive behavior.</p>
              </sec>
            </sec>
            <sec id="s3">
              <title>Available Visual Information</title>
              <p>When an observer faces a ball in a parabolic trajectory, the projectile describes the following sequence of events (see <xref ref-type="fig" rid="F2">Figure 2</xref>). The ball initially goes up at a decreasing speed until it reaches the peak of its trajectory. Then, it accelerates during the descent towards the ground. However, an observer cannot access the underlying dynamics of projectile motion using Cartesian metrics. Instead, they only have access to information based on egocentric angular variables that depend on their position and the kinematics of the ball (Shaffer and McBeath, <xref rid="B135" ref-type="bibr">2005</xref>; McBeath et al., <xref rid="B101" ref-type="bibr">2018</xref>). Hence, the ball’s kinematics and an observer’s movement influence the visual information being exposed throughout the trajectory. <xref ref-type="fig" rid="F2">Figure 2</xref> depicts the main primitive optic variables that we will consider and how both unfold over time (<italic>t</italic>) depending on the observer’s position and total flight time (<italic>T</italic>), which is unknown to the observer.</p>
              <p>While interpreting sensory information is a central part of this work, we also need to consider the limitations of our sensory system to gather that visual information. Because of that, in the following subsections, we will elaborate on the conditions that render different visual cues helpful regarding detectability or discriminability, describing their precision as Weber fractions. To do so, we will assume that the observers keep their gaze on the projectile, which is usually the case in free viewing situations (Oudejans et al., <xref rid="B116" ref-type="bibr">1999</xref>; Postma et al., <xref rid="B121" ref-type="bibr">2014</xref>) and laboratory-controlled tasks when the position to hit a target is not pre-specified (Brenner and Smeets, <xref rid="B21" ref-type="bibr">2007</xref>; Soechting et al., <xref rid="B139" ref-type="bibr">2009</xref>; Cámara et al., <xref rid="B31" ref-type="bibr">2018</xref>).</p>
              <sec id="s3-1">
                <title>Retinal Size (<italic>θ</italic>)</title>
                <p>The visual angle or retinal size is the angular size projected by an object on the retina (<italic>θ</italic>; see green projections in <xref ref-type="fig" rid="F2">Figure 2</xref>). Retinal size (<italic>θ</italic>) is proportional to both object size and distance, being the prototypical example of an ambiguous optic variable. Previous studies have shown that human performance in discrimination tasks for angular size judgments is about a 3–6% Weber fraction (WF; <italic>k</italic><sub>θ</sub>) for objects yielding &gt;0.0009 radians, increasing steeply up to a 20–30% (WF) for smaller objects (Westheimer and McKee, <xref rid="B155" ref-type="bibr">1977</xref>; Klein and Levi, <xref rid="B85" ref-type="bibr">1987</xref>; McKee and Welch, <xref rid="B105" ref-type="bibr">1992</xref>).</p>
                <p>Retinal size is a zero-order variable; that is, it does not carry temporal information and thus, cannot be employed alone to estimate motion components or TTC. To do so, one needs to have access to the rate of expansion (<inline-formula><mml:math id="M1"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>), which is the speed at which the retinal image changes. The absolute detection threshold for <inline-formula><mml:math id="M2"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> has been reported to be about 0.0003 rad/s (McKee, <xref rid="B104" ref-type="bibr">1981</xref>), while the discrimination threshold associated with this parameter is about an 8.5–14% of change (WF; <italic>k</italic><sub><inline-formula><mml:math id="M3"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula></sub>; Regan and Hamstra, <xref rid="B126" ref-type="bibr">1993</xref>).</p>
                <p>In some cases, such as baseball games, the players meet scenarios where the ball is at a considerable distance. In those cases, although mediated by physical size and ball’s horizontal speed, discriminability of the rate of expansion (<inline-formula><mml:math id="M4"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) is generally poor (20% of change (WF) for objects expanding at a rate of less than 0.004 rad/s (Regan and Beverley, <xref rid="B125" ref-type="bibr">1978</xref>; Harris and Watamaniuk, <xref rid="B64" ref-type="bibr">1995</xref>).</p>
                <p>To show the effect of ball size on an observer’s ability to discriminate differences in the rate of expansion (<inline-formula><mml:math id="M5"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>), we computed the rate of expansion for two different balls (baseball and soccer balls) moving in a parabolic trajectory towards an observer from different initial distances. <xref ref-type="fig" rid="F3">Figure 3</xref> shows how retinal expansion unfolds as a function of time. Values below 0.004 rad/s (red dashed line) would fall below the optimal discriminability range, indicating that the observer’s ability to discriminate differences is inferior. As depicted in <xref ref-type="fig" rid="F3">Figure 3</xref>, a player facing a baseball will not discriminate retinal expansion during more than half of the trajectory. Instead, differences in retinal expansion can be discriminated during most of the trajectory of the Soccer ball. This example aims to point out that even when visual cues are present in the optic flow, the resolution of our visual system might not allow us to use them to guide our actions. Therefore, initial estimates of TTC might be computed using alternative routes.</p>
                <fig id="F3" orientation="portrait" position="float">
                  <label>Figure 3</label>
                  <caption>
                    <p>Rate of expansion (<inline-formula><mml:math id="M6"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) for two different ball sizes at five different initial distances. The total flight time is 2 s. Values under the red dashed line (0.004 rad/s) indicate that an observer cannot discriminate differences.</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0003"/>
                </fig>
              </sec>
              <sec id="s3-2">
                <title>Tau (τ)</title>
                <p>Lee’s seminal work (Lee, <xref rid="B89" ref-type="bibr">1976</xref>) described Tau (from now on, <italic>τ</italic>) as the ratio between the visual angle (<italic>θ</italic>) and its rate of expansion (<inline-formula><mml:math id="M7"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>; for a review, see Hecht and Savelsbergh, <xref rid="B66" ref-type="bibr">2004</xref>). Tau signals TTC and is directly accessible within the optic flow without prior knowledge or previous estimates of distance, size, or approaching speed.</p>
                <p>Although <italic>τ</italic> can not be conceptualized as a primitive variable in the study of visual cues, it has shown different features that could allow us to consider it as such. Regan and Hamstra (<xref rid="B126" ref-type="bibr">1993</xref>) found that differences in <italic>τ</italic> could be distinguished independently of differences in <italic>θ</italic> or <inline-formula><mml:math id="M8"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> (<italic>k</italic><sub>τ</sub> ≈ 0.07:0.13; WF). Because of this, Regan and Hamstra (<xref rid="B126" ref-type="bibr">1993</xref>) concluded that there might exist a mechanism sensitive to <italic>τ</italic> independently of <italic>θ</italic> or <inline-formula><mml:math id="M9"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>. Indeed, other studies have shown the existence of a neural mechanism tuned to <italic>τ</italic> (independently of retinal size and rate of expansion) or some of its modifications [such as the <italic>η</italic>-function (Judge and Rind, <xref rid="B77" ref-type="bibr">1997</xref>) or <italic>τ</italic>_m-function (Keil and López-Moliner, <xref rid="B81" ref-type="bibr">2012</xref>)] in various species such as pigeons and humans (Yonas et al., <xref rid="B160" ref-type="bibr">1977</xref>; Sun and Frost, <xref rid="B143" ref-type="bibr">1998</xref>; Rind and Simmons, <xref rid="B128" ref-type="bibr">1999</xref>).</p>
                <p>Tau (<italic>τ</italic>) has been indicated as a source of prospective information that might be used as a threshold (as a criterion) to perform different tasks such as hitting (Lee et al., <xref rid="B90" ref-type="bibr">1983</xref>; Bootsma and van Wieringen, <xref rid="B17" ref-type="bibr">1990</xref>) or catching (Savelsbergh et al., <xref rid="B132" ref-type="bibr">1991</xref>). This threshold is usually referred to as Tau-margin (Wann, <xref rid="B150" ref-type="bibr">1996</xref>). However, its applicability to time parabolic trajectories might be compromised due to several limitations.</p>
                <p>First, <italic>τ</italic> would only generate accurate TTC predictions at launch when the ball travels in a collision course with the observer.</p>
                <p>Second, the object should approach the observer at a constant speed. In a parabolic trajectory, from an allocentric viewpoint, <italic>V</italic><sub>x</sub> and <italic>V</italic><sub>z</sub> are constant (assuming no air resistance). Nevertheless, the approaching speed for the observer corresponds to radial velocity (<italic>V</italic><sub>r</sub>), which would carry the isotropic expansion of the retinal expansion. However, <italic>V</italic><sub>r</sub> is not constant through the trajectory and cannot be directly estimated from the optic flow (Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>). For instance, consider a trajectory launched 2 m far from an observer in a trajectory 10 m of height. In this situation, during the first half of the trajectory, <italic>V</italic><sub>r</sub> and retinal expansion <inline-formula><mml:math id="M10"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> would be negative; that is, the object moves further away from the observer, rendering meaningless estimates of TTC using Tau.</p>
                <p>Third, even though Tau could be discriminated independently of the rate of expansion (<inline-formula><mml:math id="M11"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>), it is likely constrained to the same detection thresholds (Keil and López-Moliner, <xref rid="B81" ref-type="bibr">2012</xref>). Therefore, rates of expansion (<inline-formula><mml:math id="M12"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) lower than 0.004 rad/s could result in a non-informative source to guide temporal estimations during an important section of parabolic trajectories. As reported above, the WF for Tau ranges between 7% and 13%. Therefore, we will be using a mean WF of 10% referring to Tau in the following sections.</p>
                <p>Finally, it might not be directly implemented as a general-purpose mechanism because the object must be spherical and rigid, which is not the case for an interception in some sports such as Rugby or Frisbee.</p>
              </sec>
              <sec id="s3-3">
                <title>Elevation Angle (γ)</title>
                <p>The elevation angle (γ) is the position of an object in the vertical meridian of the retina (see orange projection in <xref ref-type="fig" rid="F2">Figure 2</xref>. We conceptualize the elevation angle (γ) using a spherical projection because angular variables are assumed to be directly accessible to an observer (McBeath et al., <xref rid="B101" ref-type="bibr">2018</xref>).</p>
                <p>Even though it is often referred to as the vertical position of an object in the retina, when a projectile is visible, we tend to perform continuous visual follow-ups foveating the object, which might prevent perceptual biases (de la Malla et al., <xref rid="B41" ref-type="bibr">2017</xref>). In those cases, the retinal angle of the elevation angle (<italic>γ</italic>) would tend to zero. Because of that, it has been suggested that this visual angle can be estimated as a combination of the displacement of the environment in the retina (Oudejans et al., <xref rid="B116" ref-type="bibr">1999</xref>; Brenner and Smeets, <xref rid="B24" ref-type="bibr">2015b</xref>), the movement of the eyes with respect to the observation axis (Crowell and Banks, <xref rid="B36" ref-type="bibr">1996</xref>) and estimates of the heading angle generated at the otoliths of the vestibular system (Berthoz, <xref rid="B12" ref-type="bibr">2000</xref>; Roy and Cullen, <xref rid="B129" ref-type="bibr">2003</xref>) produced by the movement of the head and trunk (Crowell et al., <xref rid="B37" ref-type="bibr">1998</xref>; Lewis et al., <xref rid="B91" ref-type="bibr">1998</xref>). Previous literature has found that foveated objects require a difference of up to a 3–5% of change (WF) to be effectively discriminated (Regan and Kaushal, <xref rid="B127" ref-type="bibr">1994</xref>; Crowell and Banks, <xref rid="B36" ref-type="bibr">1996</xref>).</p>
                <p>The first derivative with the time of the rate of change of the elevation angle (<inline-formula><mml:math id="M13"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) is the vertical rate of displacement of a target in the retina (see <xref ref-type="fig" rid="F2">Figure 2</xref>). According to several studies (McKee, <xref rid="B104" ref-type="bibr">1981</xref>; Orban et al., <xref rid="B115" ref-type="bibr">1984</xref>; de Bruyn and Orban, <xref rid="B29" ref-type="bibr">1988</xref>), the ability to judge differences in <inline-formula><mml:math id="M14"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> is about 5% (WF) for angular velocities between 0.03 rad/s (1.71 deg/s) and 1.2 rad/s (69 deg/s). Interestingly, Portfors-Yeomans and Regan (<xref rid="B120" ref-type="bibr">1996</xref>) suggest channels that process position and cardinal motion independently, which indicates that the noise for both estimates is independent.</p>
                <p>Given that parabolic trajectories move accelerated by terrestrial gravity, it is reasonable to consider humans’ ability to detect acceleration. Calderone and Kaiser (<xref rid="B30" ref-type="bibr">1989</xref>) proposed that acceleration in the visual system can be studied as the rate of change in speed divided by the average object speed in a two-stage process carried out in about 200 ms (Werkhoven et al., <xref rid="B154" ref-type="bibr">1992</xref>; Zaal et al., <xref rid="B162" ref-type="bibr">2012</xref>). This delay would mean that the observer would not continuously monitor the adequacy of their actions. Furthermore, some studies found that it is necessary at least ~20% of the change in speed to detect acceleration (Gottsdanker et al., <xref rid="B59" ref-type="bibr">1961</xref>; Werkhoven et al., <xref rid="B154" ref-type="bibr">1992</xref>; Babler and Dannemiller, <xref rid="B7" ref-type="bibr">1993</xref>; Brouwer et al., <xref rid="B27" ref-type="bibr">2006</xref>; Zaal et al., <xref rid="B162" ref-type="bibr">2012</xref>) indicating that humans are quite insensitive to changes in speed.</p>
              </sec>
              <sec id="s3-4">
                <title>Disparity (δ)</title>
                <p>Disparity (δ) is the vertical/horizontal difference between the position of an object in the retinal image of both eyes. An algorithm like Tau (τ) for the estimation of TTC has been proposed as a combination of the knowledge of interocular distance (I), the distance with the ball (D) and the rate of change of horizontal disparity) (<inline-formula><mml:math id="M15"><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) (TTC ≈ I/(D*<inline-formula><mml:math id="M16"><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>)). Furthermore, it can be used to estimate the lateral distance at which an object would pass an observer position.</p>
                <p>A combination of Tau and the information contained in the above expression would assist the estimation of TTC to achieve our exceptional temporal precision batting fastballs (Gray and Regan, <xref rid="B62" ref-type="bibr">1998</xref>). This solution may account for systematic underestimations of TTC by weighting the visual cue that indicates a shorter TTC to guide the final interceptive phase (Savelsbergh and Whiting, <xref rid="B131" ref-type="bibr">1992</xref>; Gray and Regan, <xref rid="B62" ref-type="bibr">1998</xref>; Rushton and Wann, <xref rid="B130" ref-type="bibr">1999</xref>). However, Brenner et al. (<xref rid="B26" ref-type="bibr">2014</xref>) found no evidence that hitting a free fall ball uses the rate of change in disparity (<inline-formula><mml:math id="M17"><mml:mover><mml:mi>θ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) to estimate TTC. In this sense, Brenner and Smeets (<xref rid="B25" ref-type="bibr">2018</xref>) argue that some studies that compare the performance between monocular and binocular conditions “ignore the benefit of having two estimates of the relevant monocular cues” instead of one.</p>
              </sec>
            </sec>
            <sec id="s4">
              <title>Evidence of Prior Knowledge Calibrating Visual Information</title>
              <p>Humans quickly acquire knowledge about regularities in their interaction with the environment. Regularities such as the light coming from above (Adams et al., <xref rid="B2" ref-type="bibr">2004</xref>), that bigger means heavier (Peters et al., <xref rid="B118" ref-type="bibr">2016</xref>) or the fact that object size is generally constant (López-Moliner and Keil, <xref rid="B94" ref-type="bibr">2012</xref>) enhance predictability and reduce uncertainty about future states of the world. Indeed, the assumption of a stable world is at the heart of essential findings in different areas of vision science, such as speed perception (Stocker and Simoncelli, <xref rid="B142" ref-type="bibr">2006</xref>), depth estimation (Glennerster et al., <xref rid="B57" ref-type="bibr">2006</xref>), and manual interception (Brenner and Smeets, <xref rid="B23" ref-type="bibr">2015a</xref>).</p>
              <p>Such known regularities may also be referred to here as contextual information stressing the role of acquired knowledge by repeated experience within a specific context. In this work, we will focus on two pieces of internalized knowledge that usually remain stable in our world and might frame the interpretation of visual information for parabolic trajectories: known size and gravity.</p>
              <sec id="s4-1">
                <title>Size</title>
                <p>The assumption of constant size is likely one of the most critical assumptions about action because, in general, the objects around us do not change size unexpectedly. Under this assumption, known size calibrates visual information into distance estimations with an object as the ratio between known size and the retinal size projected (Ittelson, <xref rid="B70" ref-type="bibr">1951</xref>; Hecht et al., <xref rid="B67" ref-type="bibr">1996</xref>; Sousa et al., <xref rid="B140" ref-type="bibr">2011</xref>) even though irregular objects such as rugby balls and frisbees can be problematic.</p>
                <disp-formula id="E1">
                  <label>(1)</label>
                  <mml:math id="M18">
                    <mml:mrow>
                      <mml:mi>d</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mi>s</mml:mi>
                        <mml:mi>θ</mml:mi>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <p>The previous expression provides a mechanism to scale the optic space into ball size units (Peper et al., <xref rid="B117" ref-type="bibr">1994</xref>; Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>) for a broad range of contexts. Calibrating the optic space with known size provides estimates of relative distances in paintings, pictures, video games, and environments with low or incongruent pictorial detail (Todd, <xref rid="B146" ref-type="bibr">1981</xref>; Saxberg, <xref rid="B134" ref-type="bibr">1987b</xref>), sometimes at the cost of leading to systematic misperceptions (Battaglia et al., <xref rid="B9" ref-type="bibr">2005</xref>; Tcheang et al., <xref rid="B144" ref-type="bibr">2005</xref>; Battaglia et al., <xref rid="B8" ref-type="bibr">2011</xref>).</p>
                <p>In line with the use of known size calibrating visual information, López-Moliner et al. (<xref rid="B96" ref-type="bibr">2007</xref>) showed that when an object approaches at a constant speed and physical size is known; an observer can exploit the lawful relations between physical size and optic variables in the equation above to estimate approaching speed (<italic>V</italic><sub>z</sub>) as its first derivative:</p>
                <disp-formula id="E2">
                  <label>(2)</label>
                  <mml:math id="M19">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>V</mml:mi>
                        <mml:mi>z</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>s</mml:mi>
                          <mml:mover>
                            <mml:mi>θ</mml:mi>
                            <mml:mo>˙</mml:mo>
                          </mml:mover>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:msup>
                            <mml:mi>θ</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:msup>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <p>In the above expression, known size (<italic>s</italic>) allows calibrating retinal size (<italic>θ</italic>) and rate of expansion (<inline-formula><mml:math id="M20"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) into an estimate of approaching speed (<italic>V</italic><sub>z</sub>) from otherwise spatiotemporally ambiguous optic variables. Then, an observer could use single optic variables (e.g., retinal size or expansion rate) to time the initiation of interceptive actions (Smith et al., <xref rid="B138" ref-type="bibr">2001</xref>; López-Moliner et al., <xref rid="B96" ref-type="bibr">2007</xref>; López-Moliner and Keil, <xref rid="B94" ref-type="bibr">2012</xref>) depending on noise levels (Aguilar-Lleyda et al., <xref rid="B4" ref-type="bibr">2018</xref>). However, what happens when it comes to obtaining parameters of more complex tasks such as parabolic trajectories?</p>
                <p>In Todd (<xref rid="B146" ref-type="bibr">1981</xref>), the participants had to judge if a ball on a parabolic trajectory would fall in front or behind an observer in different experimental conditions. Todd’s work showed that, even though there might be enough information to estimate the final position qualitatively for parabolic trajectories only based on sensory information, prior knowledge of an object’s size helped the participants to judge the final position in depth accurately. In each block, the absolute size was either fixed, selected at random, or fixed to a single dot during the whole trajectory. Accuracy was significantly better when the absolute size was fixed than the condition in which size was selected randomly. Those results indicate that prior knowledge of the ball’s size aids the estimation of motion-in-depth.</p>
                <p>Interestingly, the third condition yielded the worst performance of all three conditions, yet performance was slightly over chance level. In this condition, only the vertical movement was available to the observers to judge approaching speed. Participants judged landing position based on “the amount of vertical speed.” In line with these results, Jörges and López-Moliner (<xref rid="B73" ref-type="bibr">2017</xref>) showed that prior knowledge of gravity might be essential to calibrate estimates of the rate of change (<inline-formula><mml:math id="M21"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) into estimates of approaching speed (<italic>V</italic><sub>z</sub>) in parabolic motion.</p>
              </sec>
              <sec id="s4-2">
                <title>Gravity</title>
                <p>Since Lacquaniti and Maioli (<xref rid="B88" ref-type="bibr">1989</xref>) work, showing an anticipatory activity for gravitationally accelerated objects, there is evidence that an internal representation of gravity may play a key role in controlling interceptive actions and judging TTC. For example, McIntyre et al. (<xref rid="B103" ref-type="bibr">2001</xref>) found that astronauts react to moving objects as if they were accelerated by Earth gravity under micro-gravity conditions. That study showed that although the astronauts were immersed in an environment where visual and bodily cues indicated microgravity conditions, they could not adapt their interceptive actions completely. After 15 days, the astronauts were still anticipating their interceptive actions mimicking the conditions under terrestrial gravity. Subsequent work using virtual reality setups showed that participants could adapt to arbitrary gravities in a few trials. However, the performance is still lower than that under terrestrial gravity conditions (Zago and Lacquaniti, <xref rid="B163" ref-type="bibr">2005</xref>; Zago et al., <xref rid="B164" ref-type="bibr">2005</xref>).</p>
                <p>Since then, an implicit representation of gravity has been found at a neurobiological level (Indovina et al., <xref rid="B69" ref-type="bibr">2005</xref>; Miller et al., <xref rid="B110" ref-type="bibr">2008</xref>) and in a broad range of tasks such as eye behavior (Bosco et al., <xref rid="B18" ref-type="bibr">2012</xref>; Diaz et al., <xref rid="B45" ref-type="bibr">2013</xref>; Jörges and López-Moliner, <xref rid="B74" ref-type="bibr">2019</xref>) or the estimation of the duration of events (Hosking and Crassini, <xref rid="B68" ref-type="bibr">2010</xref>; Moscatelli and Lacquaniti, <xref rid="B112" ref-type="bibr">2011</xref>; Jörges and López-Moliner, <xref rid="B75" ref-type="bibr">2020</xref>) despite our general insensibility to accelerations (Werkhoven et al., <xref rid="B154" ref-type="bibr">1992</xref>).</p>
                <p>However, the best example of a representation of gravity for sensorimotor control is that an observer does not need to see an ascending ball falling to intercept it (de la Malla and López-Moliner, <xref rid="B40" ref-type="bibr">2015</xref>). In general, humans have an implicit expectation that upwards moving objects will eventually fall (López-Moliner et al., <xref rid="B95" ref-type="bibr">2010</xref>; Reed et al., <xref rid="B124" ref-type="bibr">2010</xref>). Nevertheless, this representation may not be available for every kind of task. For example, timing tasks for gravitationally accelerated objects in imagination show a bias towards the last visible motion speed (Gravano et al., <xref rid="B60" ref-type="bibr">2017</xref>; Bratzke and Ulrich, <xref rid="B20" ref-type="bibr">2021</xref>). In this line, some authors dismiss an internal model-based explanation favoring a prediction-free explanation (Baurès et al., <xref rid="B10" ref-type="bibr">2007</xref>; Katsumata and Russell, <xref rid="B80" ref-type="bibr">2012</xref>). However, the lack of adaptation under microgravity conditions and the need to account for sensorimotor delays pinpoint the relevance of gravity prior guiding predictive control (Zago et al., <xref rid="B166" ref-type="bibr">2008</xref>).</p>
                <p>A recent study (Jörges and López-Moliner, <xref rid="B75" ref-type="bibr">2020</xref>) tried to derive the mean and standard deviation of the Gravity prior in a Bayesian framework. Their results found a prior with a standard deviation of 14% (WF). According to the authors, these results might correspond with an upper bound, as there seem to be theoretical reasons such as the lack of adaptation to arbitrary gravity values suggesting a relatively inflexible and robust gravity prior (Jörges and López-Moliner, <xref rid="B73" ref-type="bibr">2017</xref>).</p>
                <p>To test the use of different pieces of prior information for calibration, it is first necessary to put forward algorithms that require pieces of internalized knowledge. In the temporal domain, Gómez and López-Moliner (<xref rid="B58" ref-type="bibr">2013</xref>) showed that by using both prior knowledge of gravity and size, visual information could be calibrated, resulting in actionable estimates of TTC. The model was named GS model about the assumption of <italic>a priori</italic> known gravity and size.</p>
              </sec>
            </sec>
            <sec id="s5">
              <title>Time-To-Contact Estimation</title>
              <sec id="s5-1">
                <title>GS Model</title>
                <p>The GS model (Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>) is an algorithm that relies on calibrated optic information using prior knowledge to obtain estimates of TTC for parabolic trajectories. It relies on a combination of contextual variables such as known ball size (<italic>s</italic>) and gravitational acceleration (<italic>g</italic>) along with monocular cues such as retinal size (<italic>θ</italic>), elevation angle (<italic>γ</italic>) and its first derivative (<inline-formula><mml:math id="M22"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>), providing accurate estimates of TTC.</p>
                <disp-formula id="E3">
                  <label>(3)</label>
                  <mml:math id="M23">
                    <mml:mrow>
                      <mml:mi>T</mml:mi>
                      <mml:mi>T</mml:mi>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mrow>
                          <mml:mi>G</mml:mi>
                          <mml:mi>S</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mo>≈</mml:mo>
                      <mml:mfrac>
                        <mml:mn>2</mml:mn>
                        <mml:mi>g</mml:mi>
                      </mml:mfrac>
                      <mml:mfrac>
                        <mml:mi>s</mml:mi>
                        <mml:mi>θ</mml:mi>
                      </mml:mfrac>
                      <mml:mfrac>
                        <mml:mover>
                          <mml:mi>γ</mml:mi>
                          <mml:mo>˙</mml:mo>
                        </mml:mover>
                        <mml:mrow>
                          <mml:mi>cos</mml:mi>
                          <mml:mtext> </mml:mtext>
                          <mml:mo>(</mml:mo>
                          <mml:mi>γ</mml:mi>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <p>Known ball size (<italic>s</italic>) and retinal size (<italic>θ</italic>) provide a mapping from retinal to Cartesian metrics. On its part, gravitational acceleration (<italic>g</italic>) calibrates and normalizes the rate of change of the elevation angle (<inline-formula><mml:math id="M24"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) to be interpreted into meaningful predictions of TTC under arbitrary gravitational accelerations. In addition, cos(γ) would act as a non-declarative internalized parameter linked to action expecting that the elevation angle (<italic>γ</italic>) would increase over time (Reed et al., <xref rid="B124" ref-type="bibr">2010</xref>; Shaffer et al., <xref rid="B136" ref-type="bibr">2013</xref>). Removing the internalized variables from the GS model, one can still obtain a correlate of TTC based on retinal size (<italic>θ</italic>), the elevation angle (<italic>γ</italic>) and the rate of change of the elevation angle (<inline-formula><mml:math id="M25"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>). However, its value is meaningless in signaling an actionable TTC and, therefore, not directly applicable. The following section will illustrate that envisioning those pieces of prior knowledge as priors within an encoding-decoding framework could calibrate ambiguous visual cues into accurate estimates of TTC for parabolic trajectories.</p>
                <sec id="s5-1-1">
                  <title>Simulating the Benefits of Using Gravity and Size Priors for the Decoding</title>
                  <p>Under the constructivist framework, visual information is underspecified, and many trajectories can originate the same stimulation. This simulation shows how entering the correct gravity and size values increases the chances of inferring the actual trajectory exposed to the system from a subset of the possible ones.</p>
                  <p>In the case of this simulation, the possible inferred parabolas are a combination of the nine different TTC (ranging from 1.8 to 2.2 s in steps of 0.05 s), five different conditions of gravity (8.826, 9.316, 9.807, 10.297, 10.787 m/s<sup>2</sup>) and five different sizes (0.0703, 0.07215, 0.074, 0.07585, 0.0777 m) launched at eye-level 30 meters away from the observer in a head-on approach. We chose those values of gravitational acceleration and size using differences of 5% the standard of Earth gravity and 2.5% of the standard size of a baseball to envision reliable values of prior knowledge of gravity and size (however, see Jörges and López-Moliner, <xref rid="B75" ref-type="bibr">2020</xref>).</p>
                  <p><xref ref-type="fig" rid="F4">Figure 4</xref> represents nine test trajectories exposed to the system (panel A), whereas panels B, C and D represent the range of possible values for each variable available for the observer: retinal size (<italic>θ</italic>), the elevation angle (<italic>γ</italic>) and the rate of change of the elevation angle (<inline-formula><mml:math id="M26"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) respectively.</p>
                  <fig id="F4" orientation="portrait" position="float">
                    <label>Figure 4</label>
                    <caption>
                      <p>Test parabolas used in the simulation. <bold>(A)</bold> Ball’s vertical vs. depth position. Panels <bold>(B–D)</bold> indicate retinal size (<italic>θ</italic>), elevation angle (<italic>γ</italic>) and rate of change of the elevation angle (<inline-formula><mml:math id="M27"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) as a function of time for the first 200 ms of the trajectory. Panels <bold>(E,F)</bold> depict the output of the GS model using visual information only and combined with prior information, respectively.</p>
                    </caption>
                    <graphic xlink:href="fnhum-15-642025-g0004"/>
                  </fig>
                  <p>To reproduce the encoding process of a sensory stimulus, we simulated a set of tuning curves covering the range of possible stimulus strengths (stimulus values) for each optic variable 200 ms. after motion onset. In <xref ref-type="fig" rid="F5">Figure 5</xref>, the reader can see an illustration of the tuning curves (black curves), the stimulus strength presented to the system (blue vertical line), and an example of the average response by a detector (red curve) for the average TTC under standard conditions of gravity and size (light blue trajectory in <xref ref-type="fig" rid="F4">Figure 4</xref>). The detectors simulated for retinal size (<italic>θ</italic>) covered a range from 0.0024 to 0.0031 rad (SD = 0.00014; representing a 5% WF). The stimulus range covered for the elevation angle (<italic>γ</italic>) and its rate of change (<inline-formula><mml:math id="M28"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) was from 0.045 to 0.085 rad (SD = 0.00325 rad; 5% WF) and from 0.2 to 0.45 rad/s (SD = 0.01625 rad/s; 5% WF) respectively.</p>
                  <fig id="F5" orientation="portrait" position="float">
                    <label>Figure 5</label>
                    <caption>
                      <p>Simulated tuning curves of neurons specialized for different values of <bold>(A)</bold> retinal size (<italic>θ</italic>), <bold>(B)</bold> elevation angle (<italic>γ</italic>) and <bold>(C)</bold> rate of change of the elevation angle (<inline-formula><mml:math id="M29"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>). The blue vertical line indicates the true stimulus strength exposed to the system. The stimulus strength was selected from the standard condition 200 ms after motion onset (see main text). The red curve indicates the average activation per neuron in a single trial (Poisson noise added). The red dashed lines indicate the stimulus strength inferred by the encoding process.</p>
                    </caption>
                    <graphic xlink:href="fnhum-15-642025-g0005"/>
                  </fig>
                  <p>After the detectors were exposed to the stimulus, we obtained the average response probability (r; solid red line in <xref ref-type="fig" rid="F5">Figure 5</xref>) for corresponding neural detectors (Dayan and Abbott, <xref rid="B39" ref-type="bibr">2001</xref>) as:</p>
                  <disp-formula id="E4">
                    <label>(4)</label>
                    <mml:math id="M30">
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                        <mml:mtext> </mml:mtext>
                        <mml:mo>(</mml:mo>
                        <mml:mi>r</mml:mi>
                        <mml:mo>)</mml:mo>
                        <mml:mo>=</mml:mo>
                        <mml:mi>f</mml:mi>
                        <mml:msup>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mi>θ</mml:mi>
                            <mml:mo>,</mml:mo>
                            <mml:mi>γ</mml:mi>
                            <mml:mo>,</mml:mo>
                            <mml:mover>
                              <mml:mi>γ</mml:mi>
                              <mml:mo>˙</mml:mo>
                            </mml:mover>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                          <mml:mi>r</mml:mi>
                        </mml:msup>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:msup>
                              <mml:mi>e</mml:mi>
                              <mml:mrow>
                                <mml:mo>−</mml:mo>
                                <mml:mi>f</mml:mi>
                                <mml:mo>(</mml:mo>
                                <mml:mi>θ</mml:mi>
                                <mml:mo>,</mml:mo>
                                <mml:mi>γ</mml:mi>
                                <mml:mo>,</mml:mo>
                                <mml:mover>
                                  <mml:mi>γ</mml:mi>
                                  <mml:mo>˙</mml:mo>
                                </mml:mover>
                                <mml:mo>)</mml:mo>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>r</mml:mi>
                            <mml:mo>!</mml:mo>
                          </mml:mrow>
                        </mml:mfrac>
                      </mml:mrow>
                    </mml:math>
                  </disp-formula>
                  <p>In this expression, (<italic>f</italic>) indicates the mean activity per detector, whereas (<italic>r</italic>!) corresponds to the factorial response for each detector. In our simulation, the resulting activation varies on each iteration by adding Poisson noise, representing random variability in neural activation.</p>
                  <p>We simulated 1,000 trials per TTC in which the size was the standard of a baseball (0.074 m), and gravity was the standard on Earth (9.807 m/s<sup>2</sup>). Once the optic variables were encoded by the detectors simulated, we recovered the most likely stimulus strength presented to the system for each optic variable using a Maximum Likelihood estimate (MLE) procedure. Then, we obtained a value corresponding to the GS model based only on the optic variables retrieved by the encoding procedure.</p>
                  <p>We compared that output to the GS model’s ideal (noiseless) output based only on optic variables for all the simulated trajectories. We obtained two possible sets of decoding responses to select all the potential trajectories that matched the model’s output. For the first set of responses, we only used sensory information without resorting to size or gravity priors to decode the correct TTC; that is, we used a Maximum Likelihood Estimation procedure. We assumed the correct size and gravity priors to decode the correct TTC for the second set of responses. Then, we selected all potential trajectories that would fall into a relatively low error margin of ± 5%.</p>
                  <p><xref ref-type="fig" rid="F6">Figure 6</xref> depicts the average accuracy per procedure. Here, the performance of a system using only sensory information (MLE; red dashed line) is slightly over the chance level (blue dashed line). On the contrary, using the correct priors (central dots in panels A and B of <xref ref-type="fig" rid="F6">Figure 6</xref>) improves the proportion of correctly estimated TTC’s substantially. Note that since the relative difference between the different simulated gravity values is higher than those of size, the procedure benefits more from an accurate representation of internalized knowledge of gravity. This example highlights that, despite the inherent ambiguity of sensory information in the optic flow, the use of prior information is a powerful calibration tool to interpret otherwise ambiguous visual information.</p>
                  <fig id="F6" orientation="portrait" position="float">
                    <label>Figure 6</label>
                    <caption>
                      <p>Average accuracy per procedure. The blue dashed line indicates chance level (11.1%), red dashed line indicates the performance of an maximum likelihood estimate (MLE) procedure. The black points indicate the performance assuming different size priors in panel <bold>(A)</bold> (<italic>g</italic> = 9.807 <italic>m/s</italic><sup>2</sup> assumed) and assuming different gravity priors in panel <bold>(B)</bold> (baseball size assumed).</p>
                    </caption>
                    <graphic xlink:href="fnhum-15-642025-g0006"/>
                  </fig>
                </sec>
              </sec>
              <sec id="s5-1-2">
                <title>Accuracy and Precision of Using Gravity and Known Size</title>
                <p>So far, we have shown that calibrating visual information in the light of prior knowledge allows us to draw accurate predictions using the GS model. However, it could still be the case that even if the output is accurate, the visual information in the optic flow is so noisy that an estimation of TTC might not be available.</p>
                <p>To evaluate an observer’s ability to estimate TTC accurately and precisely from the GS model, we simulated a series of typical spatio-temporal parameters for parabolic trajectories. We simulated parabolic trajectories launching at eye-level at five initial distances (<italic>Z</italic><sub>init</sub> = 15, 20, 30, 40, 50 m), one contact time (<italic>TTC</italic> = 2 s; Δ<sub>t</sub> = 0.01 s) and a single radius corresponding to a baseball (0.037 m). In each case, the endpoint is the origin, that is, the position of the simulated observer.</p>
                <p>To evaluate the precision of the output, we introduced independent Gaussian noise to <italic>θ</italic>, <italic>γ</italic> and <inline-formula><mml:math id="M31"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> according to their respective WFs (identified with the letter <italic>k</italic>).</p>
                <disp-formula id="E5">
                  <label>(5)</label>
                  <mml:math id="M32">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>θ</mml:mi>
                        <mml:mi>χ</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mi>θ</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:msub>
                        <mml:mi>N</mml:mi>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:mi>μ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>0</mml:mn>
                              <mml:mo>;</mml:mo>
                              <mml:mtext> </mml:mtext>
                              <mml:mi>σ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mi>θ</mml:mi>
                              <mml:mo>∗</mml:mo>
                              <mml:msub>
                                <mml:mi>θ</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mtext>  </mml:mtext>
                      <mml:msub>
                        <mml:mi>θ</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mn>0.05</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <disp-formula id="E6">
                  <label>(6)</label>
                  <mml:math id="M33">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>γ</mml:mi>
                        <mml:mi>χ</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mi>γ</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:msub>
                        <mml:mi>N</mml:mi>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:mi>μ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>0</mml:mn>
                              <mml:mo>;</mml:mo>
                              <mml:mtext> </mml:mtext>
                              <mml:mi>σ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mi>γ</mml:mi>
                              <mml:mo>∗</mml:mo>
                              <mml:msub>
                                <mml:mi>γ</mml:mi>
                                <mml:mi>k</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mtext>  </mml:mtext>
                      <mml:msub>
                        <mml:mi>γ</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mn>0.05</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <disp-formula id="E7">
                  <label>(7)</label>
                  <mml:math id="M34">
                    <mml:mrow>
                      <mml:msub>
                        <mml:mover>
                          <mml:mi>γ</mml:mi>
                          <mml:mo>˙</mml:mo>
                        </mml:mover>
                        <mml:mi>χ</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mover>
                        <mml:mi>γ</mml:mi>
                        <mml:mo>˙</mml:mo>
                      </mml:mover>
                      <mml:mo>+</mml:mo>
                      <mml:msub>
                        <mml:mi>N</mml:mi>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:mi>μ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mn>0</mml:mn>
                              <mml:mo>;</mml:mo>
                              <mml:mtext> </mml:mtext>
                              <mml:mi>σ</mml:mi>
                              <mml:mo>=</mml:mo>
                              <mml:mover>
                                <mml:mi>γ</mml:mi>
                                <mml:mo>˙</mml:mo>
                              </mml:mover>
                              <mml:mo>∗</mml:mo>
                              <mml:msub>
                                <mml:mover>
                                  <mml:mi>γ</mml:mi>
                                  <mml:mo>˙</mml:mo>
                                </mml:mover>
                                <mml:mi>k</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:msub>
                      <mml:mtext>  </mml:mtext>
                      <mml:msub>
                        <mml:mover>
                          <mml:mi>γ</mml:mi>
                          <mml:mo>˙</mml:mo>
                        </mml:mover>
                        <mml:mi>k</mml:mi>
                      </mml:msub>
                      <mml:mo>=</mml:mo>
                      <mml:mn>0.05</mml:mn>
                    </mml:mrow>
                  </mml:math>
                </disp-formula>
                <p>To test the noise-suppression performance for the GS model, we ran 10,000 simulations for each condition using Equations (5)–(7). Then, we obtained a WF timewise as the ratio between the standard deviation of the signal and the mean predicted TTC. Note that the χ version of a variable denotes its noisified version.</p>
                <p><xref ref-type="fig" rid="F7">Figure 7A</xref> depicts the output of the GS model for each initial distance (color code), whereas the inset indicates the predicted temporal error for the ideal (noise-free) output of the model. The GS model provides very accurate estimates for which the maximum error is lower than 10 ms. On its part, <xref ref-type="fig" rid="F7">Figure 7B</xref> represents the WF estimated timewise for the GS model. As a comparison, the WF for Tau was envisioned as constant at 10% as reviewed above. The GS model presents a precise output during most of the trajectory (WF is always lower than 10%), resulting in an accurate and robust solution to the estimation of TTC in parabolic trajectories comparable to previous WFs found in the literature (Moscatelli and Lacquaniti, <xref rid="B112" ref-type="bibr">2011</xref>; Jörges and López-Moliner, <xref rid="B75" ref-type="bibr">2020</xref>).</p>
                <fig id="F7" orientation="portrait" position="float">
                  <label>Figure 7</label>
                  <caption>
                    <p><bold>(A)</bold> Noisified estimates of TTC using the GS model for different trajectories. The inset represents the temporal error for the noiseless output of the GS model. <bold>(B)</bold> Weber fraction (WF) computed as the ratio between standard deviation and mean of the GS model each temporal frame. The red dashed line indicates the mean WF of Tau (see main text). The translucid output indicates the WF of a combination of the GS model and Tau using an MLE procedure.</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0007"/>
                </fig>
                <p>It is essential to mention here that just as others have already described in the literature, the sources of information to estimate TTC may vary depending on the segments of an approach visible (DeLucia, <xref rid="B42" ref-type="bibr">2004</xref>; López-Moliner et al., <xref rid="B97" ref-type="bibr">2013</xref>; DeLucia et al., <xref rid="B43" ref-type="bibr">2016</xref>). While an initial temporal estimate would be available using the GS model, final interceptive actions would take advantage of more straightforward strategies such as a distance criterion (Wann, <xref rid="B150" ref-type="bibr">1996</xref>; López-Moliner and Keil, <xref rid="B94" ref-type="bibr">2012</xref>; Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>), Tau (Lee, <xref rid="B89" ref-type="bibr">1976</xref>; Zago et al., <xref rid="B165" ref-type="bibr">2004</xref>; Shaffer and McBeath, <xref rid="B135" ref-type="bibr">2005</xref>) or correlates of binocular disparity (Rushton and Wann, <xref rid="B130" ref-type="bibr">1999</xref>).</p>
                <p>Following this reasoning, de la Malla and López-Moliner (<xref rid="B40" ref-type="bibr">2015</xref>) partially validated the use of the GS model, showing that early estimates of TTC based on the GS model could be integrated with the latest estimates derived from correlates of the rate of expansion resulting in an accurate and precise timing mechanism. Mimicking that context, we combined the predictions of Tau and the GS model using a maximum likelihood process (Ernst and Banks, <xref rid="B47" ref-type="bibr">2002</xref>). The output results in a robust solution against sensory noise for the estimation of TTC and timing interceptive actions (see translucid lines in <xref ref-type="fig" rid="F7">Figure 7B</xref>).</p>
              </sec>
              <sec id="s5-1-3">
                <title>Generalization of the GS Model</title>
                <p>The formalization of the GS model assumes that the ball moves in a collision course with the observer (Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>). However, this is not usually the case. Commonly an observer must move to intercept the ball. Therefore, the following question is to what extent the output of the GS model deviates from perfect accuracy for trajectories ending in locations other than the observer’s position?</p>
                <p>To investigate those cases, we estimated the output of the GS model for trajectories ending at different interception locations. We simulated one initial distance (<italic>Z</italic><sub>init</sub> = 50 m) and eight interception points around the observer (see <xref ref-type="fig" rid="F8">Figure 8A</xref>). Initially, the GS model provides accurate estimates of the TTC regardless of the position of the observer. Then, in contrast with trajectories on a collision course, the simulation reflects systematic errors in TTC estimation shortly after motion onset if the observer remains stationary (see <xref ref-type="fig" rid="F8">Figure 8B</xref>). If the ball falls behind the observer, the rate of change of the predicted TTC decreases. Thus, the model’s output overestimates the remaining TTC and <italic>vice versa</italic> for balls falling ahead (see <xref ref-type="fig" rid="F8">Figure 8B</xref>), pointing out that the errors depend on the interception location. In this context, a navigational strategy predicting where and when the ball would be within reach would initially guide the observer towards the wrong position.</p>
                <fig id="F8" orientation="portrait" position="float">
                  <label>Figure 8</label>
                  <caption>
                    <p><bold>(A)</bold> Ending positions for simulated trajectories around the observer. The lines represent the trajectories followed by the moving observer. Panels <bold>(B,C)</bold> depict the output of the GS model for a stationary and a moving observer. The line code indicates lateral ending position [<italic>X</italic><sub>End</sub> = 0, 5 (m)]. The color code indicates the ending position in depth [<italic>Z</italic><sub>End</sub> = −5, 0, 5 (m)] . Note that the GS model predicts an underestimation of TTC for balls falling ahead and an overestimation of TTC for those falling behind the observer.</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0008"/>
                </fig>
                <p>Nevertheless, the simulations described so far result in predictions of TTC for an unlikely situation in which the observer is not at the interception location and remains stationary. Usually, an observer would control the ball moving towards the interception area. As a result, an observer’s movement would prompt changes in the optic flow. As we will show, simulating the observer’s movement, we found interesting properties in the output of the GS model that might indicate the availability of a navigational strategy.</p>
                <p>To perform the following simulations, we replicated the previous trajectories. However, in this case, the observer started moving towards the interception location at a constant speed 500 ms after the ball’s launch. We chose this moment because catchers generally start running in the right direction 500 ms after the ball’s flight has started (Michaels and Oudejans, <xref rid="B109" ref-type="bibr">1992</xref>; McLeod and Dienes, <xref rid="B106" ref-type="bibr">1993</xref>, <xref rid="B107" ref-type="bibr">1996</xref>; Hecht et al., <xref rid="B67" ref-type="bibr">1996</xref>; Brouwer et al., <xref rid="B27" ref-type="bibr">2006</xref>). The displacement speed of the observer was computed to reach the interception point just in time to catch the ball (see inset in <xref ref-type="fig" rid="F8">Figure 8C</xref>). Although this pattern of displacement and speed does not correspond precisely to the found in real life (McLeod and Dienes, <xref rid="B106" ref-type="bibr">1993</xref>; McLeod et al., <xref rid="B108" ref-type="bibr">2006</xref>), it is essential to point out that it will be useful for an illustrative purpose.</p>
                <p>In <xref ref-type="fig" rid="F8">Figure 8B</xref>, the reader can see that when the observer remains stationary for some time in a position other than the interception location, the rate of change of the predicted TTC changes (<xref ref-type="fig" rid="F8">Figure 8B</xref>). When the rate of change in TTC decreases, the ball will fall behind the observer and <italic>vice versa</italic>. This would signal the need to move and also provide information of the correct direction of movement in depth. Therefore, departures from the initial rate of change in TTC (slopes different from −1) could be used as a navigational strategy indicating if the observer must move forward or backwards. Instead, the movement of an observer in the correct direction provides the necessary change in the optic flow to linearize the predictions of the remaining TTC (see <xref ref-type="fig" rid="F8">Figure 8C</xref>). Thus, keeping the prediction linear will ensure that the observer would end up at the interception position in time.</p>
                <p>In sum, the above simulations indicate that the model’s output is accurate when the observer moves in the correct direction and speed providing the basis for a mechanism to navigate towards the interception location. However, these simulations were performed in a context in which the ball is only affected by the gravitational acceleration. Would a simulation of trajectories under air drag provide equally accurate temporal estimates?</p>
              </sec>
              <sec id="s5-1-4">
                <title>Dynamic Effects: Air Drag</title>
                <p>In real life, the ball is affected by external forces other than gravity, such as air drag, Magnus force or wind currents. These forces deviate the trajectory from a perfect parabola compared to motion in a vacuum in astonishing ways (McBeath et al., <xref rid="B100" ref-type="bibr">2008</xref>). For instance, previous works indicate that air drag can reduce flight time and distance traveled by a flying ball up to 50% (Brancazio, <xref rid="B19" ref-type="bibr">1985</xref>; Adair, <xref rid="B1" ref-type="bibr">2002</xref>). Therefore, trajectories initially on a collision course with the observer are no longer so after a short period. This pattern would potentially preclude the use of different algorithms for estimating the TTC, such as the Tau or GS model.</p>
                <p>It has been argued that the self-regulatory nature of information-based strategies can efficiently deal with dynamic effects in a parabolic trajectory, provided that continuous visual information is available. In contrast, it is commonly argued that an internal model assuming a constant gravitational acceleration would be insufficient to account for dynamic forces such as air drag (Fink et al., <xref rid="B52" ref-type="bibr">2009</xref>). To account for air drag, an internal model would have to gain access to a drag coefficient, mass and size for every single object and environment dynamically, which limits a massive application (Craig et al., <xref rid="B34" ref-type="bibr">2006</xref>). Furthermore, it seems at odds with the fact that most people think that objects fall at the same rate despite their mass or volume (Oberle et al., <xref rid="B114" ref-type="bibr">2005</xref>). However, explicit knowledge of physics may not affect performance in action-related tasks (Reed et al., <xref rid="B124" ref-type="bibr">2010</xref>; Flavell, <xref rid="B53" ref-type="bibr">2014</xref>). Following this reasoning, in our view, predictions using priors would only include variables facilitating the interpretation of the most generic case of natural law or parameters for a given task. In the following, we will show how the GS model, which relies only on gravity and size priors, can predict the remaining TTC reliably for the general case of trajectories under gravity and air drag conditions.</p>
                <p>Unlike the gravitational force, which exerts the same force for different projectiles, air resistance depends on several factors: <italic>ρ</italic>, cosity of the environment surrounding the object; <italic>C</italic><sub>d</sub>, a drag coefficient relative to the texture and shape of the projectile essentially; r object’s radius and v, the tangential speed of the object estimated dynamically. To simulate the effects of air drag on a parabolic trajectory, we followed the procedure described in Timmerman and van der Weele (<xref rid="B145" ref-type="bibr">1999</xref>) and Gómez and López-Moliner (<xref rid="B58" ref-type="bibr">2013</xref>). We simulated different trajectories under two different conditions: gravity only and gravity + air drag. Air viscosity around the ball (<italic>ρ</italic>) was set to 1.225 <italic>kg/m</italic><sup>3</sup> (value at sea level), and <italic>C</italic><sub>d</sub> was set to 0.346 or 0.4 for baseball and soccer balls, respectively (Alam et al., <xref rid="B5" ref-type="bibr">2010</xref>; Kagan and Nathan, <xref rid="B78" ref-type="bibr">2014</xref>). We introduced one initial vertical speed <italic>V<sub>y0</sub></italic> = 9.807 m/s (2 s of flight time under gravity only conditions) for each trajectory and corresponding approaching speeds (<italic>V<sub>y0</sub></italic> = 7.5,15,25 m/s) different balls launched at the origin. In this simulation, we did not include horizontal displacements.</p>
                <p>In <xref ref-type="fig" rid="F9">Figure 9A</xref>, the reader can see how air drag influences the trajectory described by the ball in both: the spatial and the temporal domain. In <xref ref-type="fig" rid="F9">Figure 9A</xref>, the gray trajectory represents the trajectory followed by a ball under gravity-only conditions, whereas the blue and red trajectories indicate the trajectories followed by baseball and soccer balls including air drag in the simulation. For soccer balls, the effect of air drag is more pronounced mainly due to a larger cross-sectional area against the air. Note that since the initial vertical speed was the same for all the trajectories, the differences in flight time and distance traveled can be attributed to the different approaching speeds.</p>
                <fig id="F9" orientation="portrait" position="float">
                  <label>Figure 9</label>
                  <caption>
                    <p><bold>(A)</bold> Lateral view of different parabolic trajectories under gravity (gray lines) and gravity + air drag conditions for two different balls (red: soccer ball; blue: baseballs) and three initial approaching speeds (different panels). The figure annotates the difference in distance traveled (<italic>Z</italic><sub>Δ</sub>) and flight duration (<italic>t</italic><sub>Δ</sub>) compared to a trajectory only considering gravity. The black and orange dots in the third panel indicate the position of the corresponding simulated observer in panels <bold>(B)</bold> or <bold>(C,D)</bold>, respectively. The green arrow indicates the displacement simulated in panel <bold>(D)</bold>. Panels <bold>(B–D)</bold> indicate the predicted TTC using the GS model for different simulated observers in the worst-case scenario simulated. Insets depict the corresponding temporal errors using the predictions of the GS model.</p>
                  </caption>
                  <graphic xlink:href="fnhum-15-642025-g0009"/>
                </fig>
                <p>Thus, how well can the GS model estimate the remaining TTC in trajectories, including air drag? To answer this question, we simulated the output of the GS model for the worst-case scenario previously simulated. In that case, the GS model will yield the least accurate predictions. As shown in <xref ref-type="fig" rid="F9">Figure 9A</xref>, the trajectory most affected by air drag is when a Soccer ball moves at the highest horizontal speed (<italic>V<sub>z0</sub></italic> = 25 m/s).</p>
                <p>To test the model’s accuracy, we used three different situations. In the first one, the observer is stationary at the interception position under gravity + air drag conditions (black dot in <xref ref-type="fig" rid="F9">Figure 9A</xref>). In the second, the observer is stationary at a midpoint between the fall point under gravity-only and gravity + air drag conditions (black dot in <xref ref-type="fig" rid="F9">Figure 9B</xref>). Finally, we simulated a situation in which the observer is at the same “mid-point.” However, in this case, the observer moves towards the intercept point at a constant speed (8.13 m/s), 500 ms after motion onset (green arrow in <xref ref-type="fig" rid="F9">Figure 9A</xref>).</p>
                <p>The output of the model for corresponding situations is depicted in <xref ref-type="fig" rid="F9">Figures 9B–D</xref>. In all cases, the GS model reflects initial temporal errors corresponding to the difference in flight time between trajectories under gravity-only and gravity + air drag conditions (see annotations within <xref ref-type="fig" rid="F9">Figure 9A</xref>). When the observer stands still in the interception location (<xref ref-type="fig" rid="F9">Figure 9B</xref>), the GS model presents a high degree of accuracy during most of the trajectory. For instance, 0.5 s before the collision, the output converges to temporal errors of about 10–20 ms. However, if the observer stands still at the midpoint (<xref ref-type="fig" rid="F9">Figure 9C</xref>), the model’s output deviates severely. In this case, the rate of change in the predicted TTC remains consistently lower than −1. In principle, this pattern could inform the observer that the interception point would be ahead of their position. In contrast, when the observer heads towards the interception location (<xref ref-type="fig" rid="F9">Figure 9D</xref>), the model yield accurate predictions.</p>
                <p>These simulations provide evidence that the output of the information included within the GS model provides accurate and actionable predictions of the remaining TTC when the observer remains stationary in the interception location or displaces towards the interception location. Therefore, it could be used as a navigational strategy or to plan the final interceptive action even when air drag is present.</p>
              </sec>
              <sec id="s5-1-5">
                <title>Benefits and Limitations of the Generalization of the GS Model</title>
                <p>The GS model, like Tau, provides temporal information that may involve certain predictive benefits compared to the error-nulling strategies within the outfielder problem. Nevertheless, it also has some limitations that will be addressed in this section.</p>
                <p>First, the GS model is much more robust to sensory noise than Tau (Gómez and López-Moliner, <xref rid="B58" ref-type="bibr">2013</xref>). It uses the rate of change of the elevation angle (<inline-formula><mml:math id="M35"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) to estimate the TTC instead of a much noisier variable, the rate of expansion (<inline-formula><mml:math id="M36"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) upon which Tau relies.</p>
                <p>Second, Tau only provides accurate estimates when the ball is moving at constant speed towards the observer. In contrast, the GS provides accurate estimates at launch independently of the observer’s position, which would provide an initial accurate temporal information useful for planning the action.</p>
                <p>Third, the GS model overestimates the TTC for trajectories under air drag as a function of the difference in flight time between trajectories under gravity-only and gravity + air drag conditions. However, our simulations show that in combination with the observer movement, temporal errors of less than 50 ms are possible 1 s before collision (<xref ref-type="fig" rid="F9">Figure 9D</xref>).</p>
                <p>Fourth, in contrast with previous error-nulling strategies, the GS model provides temporal information and can help compensate for the temporal delays and occlusions due to its predictive nature. The TTC can be used to adjust locomotion speed, inform of the remaining TTC under restricted visibility conditions or plan the final manual interception. On its part, the rate of change of TTC could be used to adjust the direction of movement. In this sense, both signals are complementary. However, the viability of the latter requires being able to detect changes in the rate of change of the predicted TTC, which needs further research. Furthermore, the detection of variations in the rate of change of TTC will likely incur delays. Therefore, future studies should study to which extent the simultaneous TTC signal can compensate for these delays.</p>
                <p>Finally, the prediction from the GS model shares some limitations with Tau; that is, dealing with non-spherical objects such as Rugby balls or Frisbees would need further elaboration. However, some studies found that those errors can be canceled out by adding binocular information at the latter stages of catching (Gray and Regan, <xref rid="B62" ref-type="bibr">1998</xref>).</p>
              </sec>
            </sec>
            <sec id="s6">
              <title>Evidence of Prediction in Eye Behavior and Manual Interception</title>
              <p>The main problem to find support for model-based controlled behavior is that, when possible, the observer would keep track of the trajectory continuously (Oudejans et al., <xref rid="B116" ref-type="bibr">1999</xref>; Postma et al., <xref rid="B121" ref-type="bibr">2014</xref>). Indeed, this is the case of the outfielder problem, for which there is only anecdotal evidence of successful catchers directing away the gaze from the ball (Chodosh et al., <xref rid="B33" ref-type="bibr">1995</xref>). In this context, accurate actions would not allow us to discriminate between information-based and model-based control directly (Belousov et al., <xref rid="B11" ref-type="bibr">2016</xref>). Because of that, we need to scrutinize scenarios in which simple solutions such as heuristics or mappings between sensory information and temporal correlates for temporal estimation or action initiation are not available (Zhao and Warren, <xref rid="B167" ref-type="bibr">2015</xref>).</p>
              <p>One possibility to unveil the need for prediction in action control is to manipulate the target’s visibility. It is the most widely used experimental manipulation to study the predictive nature of behavior in interception (Sharp and Whiting, <xref rid="B137" ref-type="bibr">1974</xref>; Whiting and Sharp, <xref rid="B157" ref-type="bibr">1974</xref>; López-Moliner et al., <xref rid="B95" ref-type="bibr">2010</xref>; Brenner and Smeets, <xref rid="B22" ref-type="bibr">2011</xref>; Spering et al., <xref rid="B141" ref-type="bibr">2011</xref>; de la Malla and López-Moliner, <xref rid="B40" ref-type="bibr">2015</xref>). Nevertheless, more natural conditions are essential to understand how an observer could use temporal estimates to guide their action. In natural conditions, our gaze is often shifted to different locations to gather the information that may be relevant shortly (Hayhoe et al., <xref rid="B65" ref-type="bibr">2005</xref>). In other contexts, a player would divert her gaze to check for deviations caused by balls’ bouncing (Diaz et al., <xref rid="B45" ref-type="bibr">2013</xref>) or confirm whether the ball was appropriately hit (Mann et al., <xref rid="B98" ref-type="bibr">2013</xref>). Some studies in manual interception and temporal estimations gave the observer complete freedom to decide which part of a trajectory they wanted to exploit visually while dealing with alternative tasks (Faisal and Wolpert, <xref rid="B48" ref-type="bibr">2009</xref>; López-Moliner and Brenner, <xref rid="B93" ref-type="bibr">2016</xref>; Aguado and López-Moliner, <xref rid="B3" ref-type="bibr">2021</xref>). In those cases, where and when the observer averts the gaze from the target may provide valuable clues about the most relevant pieces of information according to task demands. Therefore, future studies might investigate when people prefer to divert the gaze from the ball while moving towards the interception location.</p>
              <p>In some cases, it has been suggested the existence of privileged portions of the trajectory available for an observer to judge TTC. For example, in juggling or catching a ball, looking at the apex would provide the most relevant information (Whiting, <xref rid="B156" ref-type="bibr">1968</xref>; Todd, <xref rid="B146" ref-type="bibr">1981</xref>; Watson et al., <xref rid="B152" ref-type="bibr">1992</xref>). However, a closer look at experimental data indicates that an observer does not actively search for a particular position in the parabola. Instead, prefers to use fixed temporal viewing windows generating priors during the task. These priors could then be used to weight visual information or estimate TTC when sensory information is unavailable (Amazeen et al., <xref rid="B6" ref-type="bibr">1999</xref>; López-Moliner and Keil, <xref rid="B94" ref-type="bibr">2012</xref>; Aguado and López-Moliner, <xref rid="B3" ref-type="bibr">2021</xref>).</p>
              <p>For example, most studies show acceptable catching performance in manual interception tasks for short flight durations no matter the section of the trajectory viewed. However, visual information had to be captured at least 200 ms before the catch to avoid sensorimotor delays (Sharp and Whiting, <xref rid="B137" ref-type="bibr">1974</xref>; López-Moliner et al., <xref rid="B95" ref-type="bibr">2010</xref>; López-Moliner and Brenner, <xref rid="B93" ref-type="bibr">2016</xref>). For longer flight durations (up to 2 s), catching performance describes an inverted U shape with respect to flight duration (Sharp and Whiting, <xref rid="B137" ref-type="bibr">1974</xref>; Amazeen et al., <xref rid="B6" ref-type="bibr">1999</xref>). If the observer can only see the ball well in advance, performance would be low because the predictions decay rapidly (Binsted et al., <xref rid="B15" ref-type="bibr">2006</xref>; Aguado and López-Moliner, <xref rid="B3" ref-type="bibr">2021</xref>).</p>
              <p>Zhao and Warren (<xref rid="B167" ref-type="bibr">2015</xref>) reasoned that in the case of short flight durations, part of an observer’s performance could be explained by the observer having learnt some of the regularities of a predictable trajectory mapping optic variables with a temporal correlate. Still, this would indicate the usefulness of developing priors during the task, which would be exploited when online visual information is not available. However, the fact that an observer exploits visual information when optic mappings are available indicates that they prefer to update their predictions based on the latest available visual information and combine it with evidence from previous knowledge (Mazyn et al., <xref rid="B99" ref-type="bibr">2007</xref>; Binaee and Diaz, <xref rid="B13" ref-type="bibr">2019</xref>). In the end, having a rough prediction is better than none (Brenner and Smeets, <xref rid="B25" ref-type="bibr">2018</xref>).</p>
              <p>In this line, de la Malla and López-Moliner (<xref rid="B40" ref-type="bibr">2015</xref>) proved that general rules of integration apply to the estimation of the TTC, which means: the observer integrates past and concurrent information to optimize the precision of temporal responses in a continuous fashion (Todorov, <xref rid="B147" ref-type="bibr">2004</xref>; Liu and Todorov, <xref rid="B92" ref-type="bibr">2007</xref>; Dimitriou et al., <xref rid="B46" ref-type="bibr">2013</xref>). Assuming this is true, we can use Kalman filters to predict an observer’s estimation of TTC and response variability. A Kalman filter (Kalman, <xref rid="B79" ref-type="bibr">1960</xref>) is a Bayesian tool that estimates the state of a system combining new noisy estimates, a prediction from prior measurements and a prior knowledge of how the system behaves. Using this technique, we could estimate both the accuracy and precision of online measurements for temporal judgments, manual interceptive tasks, and more general interceptive tasks such as the locomotion within the outfielder problem.</p>
            </sec>
            <sec id="s7">
              <title>Future Research</title>
              <p>One of the main objectives of this work is to highlight the potential role of prior knowledge in calibrating visual information in terms of actionable predictions such as TTC. In our view, drawing predictions based on prior knowledge is not just a reliable and accurate way to predict future states of the environment but also helps us override the need to use unreliable optic cues (Cutting and Vishton, <xref rid="B38" ref-type="bibr">1995</xref>). For instance: expansion rate (<inline-formula><mml:math id="M37"><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>) and thus Tau (<italic>τ</italic>) might not be available at large distances, optic acceleration (<inline-formula><mml:math id="M38"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙˙</mml:mo></mml:mover></mml:math></inline-formula>) is hardly discriminable by humans and would not allow for the continuous control of action (Werkhoven et al., <xref rid="B154" ref-type="bibr">1992</xref>) even though some studies claim that the values of optical acceleration available are large enough to be detected (Babler and Dannemiller, <xref rid="B7" ref-type="bibr">1993</xref>; Zaal et al., <xref rid="B162" ref-type="bibr">2012</xref>); lastly, the literature is mixed with regards to the benefits of providing binocular disparity. Because of these reasons, here we advocate using the rate of change in the elevation angle (<inline-formula><mml:math id="M39"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula>), which is very precise, in combination with an internalized knowledge of gravity and physical size for the estimation of TTC in the GS model.</p>
              <p>Here, the GS model provides different contexts to test the information included. For example, within the GS model, each contextual piece of information, gravity or size, is either in the denominator or the numerator. Hence, introducing proportional changes in the parameters governing the trajectory would result in proportional errors in the estimates of the remaining TTC. In a similar line, Jörges and López-Moliner (<xref rid="B73" ref-type="bibr">2017</xref>) showed that an observer might be able to extract information about the approaching speed of a ball through estimations of the rate of change of the elevation angle prior knowledge of gravity. Therefore, different values of gravity governing a trajectory should influence the prediction of the interception location.</p>
              <p>Moreover, using TTC discrimination tasks, it could be possible to study if an observer can detect differences between trajectories under gravity-only conditions and gravity + air drag conditions. Our simulations indicated a WF of about 7% for the GS output (see <xref ref-type="fig" rid="F7">Figure 7</xref>). Therefore, the difference in TTC should be above the discrimination threshold in some cases, as depicted in <xref ref-type="fig" rid="F9">Figure 9A</xref>. Furthermore, decision tasks based on an observer’s ability to decide if there is enough time to perform alternate tasks (e.g., looking for teammates or running towards the interception area) from early visual information might be essential to test the availability of temporal estimates as a parameter to plan action for a broader range of interceptive actions.</p>
              <p>On another note, it might be interesting to investigate the use of the GS model as a navigational mechanism. Since the GS model does not specify the interception location to plan interception in advance, we discovered a continuous coupling to keep a constant rate of change of the predicted TTC. To test if an observer would adapt locomotion to a constant rate of change, we should introduce players into contexts in which the value of gravitational acceleration or ball size do not correspond with the parameters assumed <italic>a priori</italic>. As introduced above, changes in the parameters would result in estimation errors of the remaining TTC. Thus, these manipulations would lead to predictions of the path followed by the observer. Nevertheless, to be able to use such a strategy, an observer might be able to detect deviations from different rates of change in TTC. To our knowledge, there is no previous work providing figures about how well people detect changes in TTC. Thus, our ability to detect differences in the rate of change and the time required to do so will need to be studied in future works.</p>
              <p>To generate the suggested experiments, we need immersive and realistic spaces. Virtual scenarios will provide ecologically valid contexts to evaluate to what extent predictions influence interception. To do so, the use of wireless head-mounted displays (HMD) and portable eye-trackers will be essential. HMD insert the participants into rich and controlled environments already being used to train professional sports players (Zaal and Bootsma, <xref rid="B161" ref-type="bibr">2011</xref>; Gray, <xref rid="B61" ref-type="bibr">2017</xref>; Harris et al., <xref rid="B63" ref-type="bibr">2020</xref>). Combining this technique with built-in eye-tracking systems provides access to how players interact with the environment to gather relevant visual information (Binaee et al., <xref rid="B14" ref-type="bibr">2016</xref>; Moran et al., <xref rid="B111" ref-type="bibr">2018</xref>). Those findings would still need to be replicated in real life under full-cue conditions. However, augmented reality devices are becoming more and more accessible and are likely to become more widespread. Those results may not be fully transferable to real life. However, it still would provide us information about human performance interacting with increasingly in-demand devices with potential applicability in a growing industry, eSports.</p>
            </sec>
            <sec id="s8">
              <title>Code Availability</title>
              <p>The code to reproduce all the simulations included in this work can be found in the following link: <ext-link ext-link-type="uri" xlink:href="https://osf.io/sa3cm/">https://osf.io/sa3cm/</ext-link>.</p>
            </sec>
            <sec sec-type="data-availability" id="s9">
              <title>Data Availability Statement</title>
              <p>The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found in the article.</p>
            </sec>
            <sec id="s10">
              <title>Author Contributions</title>
              <p>JL-M initially conceptualized the manuscript. BA performed the literature review based on JL-M’s suggestions and initial guidance. BA and JL-M programmed the simulations. BA wrote the manuscript with input from JL-M. All authors contributed to the article and approved the submitted version.</p>
            </sec>
            <sec sec-type="COI-statement" id="s11">
              <title>Conflict of Interest</title>
              <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
            </sec>
            <sec sec-type="disclaimer" id="s12">
              <title>Publisher’s Note</title>
              <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
            </sec>
          </body>
          <back>
            <fn-group>
              <fn fn-type="financial-disclosure">
                <p><bold>Funding.</bold> The research group was funded by the Catalan government (2017SGR-48) and grant ref. PSI2017-83493-R (AEI/FEDER, UE). BA was supported by the fellowship FPU17/01248 from Ministerio de Educación y Formación Profesional of the Spanish government.</p>
              </fn>
            </fn-group>
            <ack>
              <p>We thank Cristina de la Malla and Björn Jörges for their comments and proof reading. We also thank the reviewers for their insightful and constructive criticism during peer review.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="B1">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Adair</surname><given-names>R. K.</given-names></name></person-group> (<year>2002</year>). <source>The Physics of Baseball.</source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>HarperCollins</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B2">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>W. J.</given-names></name><name><surname>Graf</surname><given-names>E. W.</given-names></name><name><surname>Ernst</surname><given-names>M. O.</given-names></name></person-group> (<year>2004</year>). <article-title>Experience can change the’light-from-above’prior</article-title>. <source>Nat. Neurosci.</source>
<volume>7</volume>, <fpage>1057</fpage>–<lpage>1058</lpage>. <pub-id pub-id-type="doi">10.1038/nn1312</pub-id><?supplied-pmid 15361877?><pub-id pub-id-type="pmid">15361877</pub-id></mixed-citation>
              </ref>
              <ref id="B3">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguado</surname><given-names>B.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>Flexible viewing time when estimating time-to-contact in 3D parabolic trajectories</article-title>. <source>J. Vis.</source>
<volume>21</volume>:<fpage>9</fpage>. <pub-id pub-id-type="doi">10.1167/jov.21.4.9</pub-id><?supplied-pmid 33900365?><pub-id pub-id-type="pmid">33900365</pub-id></mixed-citation>
              </ref>
              <ref id="B4">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguilar-Lleyda</surname><given-names>D.</given-names></name><name><surname>Tubau</surname><given-names>E.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>An object-tracking model that combines position and speed explains spatial and temporal responses in a timing task</article-title>. <source>J. Vis.</source>
<volume>18</volume>:<fpage>12</fpage>. <pub-id pub-id-type="doi">10.1167/18.12.12</pub-id><?supplied-pmid 30458517?><pub-id pub-id-type="pmid">30458517</pub-id></mixed-citation>
              </ref>
              <ref id="B5">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alam</surname><given-names>F.</given-names></name><name><surname>Chowdhury</surname><given-names>H.</given-names></name><name><surname>Moria</surname><given-names>H.</given-names></name><name><surname>Fuss</surname><given-names>F. K.</given-names></name></person-group> (<year>2010</year>). <article-title>A comparative study of football aerodynamics</article-title>. <source>Procedia Eng.</source>
<volume>2</volume>, <fpage>2443</fpage>–<lpage>2448</lpage>. <pub-id pub-id-type="doi">10.1016/j.proeng.2010.04.013</pub-id></mixed-citation>
              </ref>
              <ref id="B6">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amazeen</surname><given-names>E. L.</given-names></name><name><surname>Amazeen</surname><given-names>P. G.</given-names></name><name><surname>Post</surname><given-names>A. A.</given-names></name><name><surname>Beek</surname><given-names>P. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Timing the selection of information during rhythmic catching</article-title>. <source>J. Mot. Behav.</source>
<volume>31</volume>, <fpage>279</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1080/00222899909600994</pub-id><?supplied-pmid 11177637?><pub-id pub-id-type="pmid">11177637</pub-id></mixed-citation>
              </ref>
              <ref id="B7">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babler</surname><given-names>T. G.</given-names></name><name><surname>Dannemiller</surname><given-names>J. L.</given-names></name></person-group> (<year>1993</year>). <article-title>Role of image acceleration in judging landing location of free-falling projectiles</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>19</volume>, <fpage>15</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1037//0096-1523.19.1.15</pub-id><?supplied-pmid 8440982?><pub-id pub-id-type="pmid">8440982</pub-id></mixed-citation>
              </ref>
              <ref id="B8">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battaglia</surname><given-names>P. W.</given-names></name><name><surname>Kersten</surname><given-names>D.</given-names></name><name><surname>Schrater</surname><given-names>P. R.</given-names></name></person-group> (<year>2011</year>). <article-title>How haptic size sensations improve distance perception</article-title>. <source>PLoS Comput. Biol.</source>
<volume>7</volume>:<fpage>e1002080</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1002080</pub-id><?supplied-pmid 21738457?><pub-id pub-id-type="pmid">21738457</pub-id></mixed-citation>
              </ref>
              <ref id="B9">
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Battaglia</surname><given-names>P. W.</given-names></name><name><surname>Schrater</surname><given-names>P. R.</given-names></name><name><surname>Kersten</surname><given-names>D. J.</given-names></name></person-group> (<year>2005</year>). “<article-title>Auxiliary object knowledge influences visually-guided interception behavior</article-title>,” in <source>Proceedings of the 2nd Symposium on Applied Perception in Graphics and Visualization</source> (<conf-loc>A Coruña, Spain</conf-loc>), <fpage>145</fpage>–<lpage>152</lpage>.</mixed-citation>
              </ref>
              <ref id="B10">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baurès</surname><given-names>R.</given-names></name><name><surname>Benguigui</surname><given-names>N.</given-names></name><name><surname>Amorim</surname><given-names>M.-A.</given-names></name><name><surname>Siegler</surname><given-names>I. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Intercepting free falling objects: better use occam’s razor than internalize newton’s law</article-title>. <source>Vis. Res.</source>
<volume>47</volume>, <fpage>2982</fpage>–<lpage>2991</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2007.07.024</pub-id><?supplied-pmid 17884129?><pub-id pub-id-type="pmid">17884129</pub-id></mixed-citation>
              </ref>
              <ref id="B11">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Belousov</surname><given-names>B.</given-names></name><name><surname>Neumann</surname><given-names>G.</given-names></name><name><surname>Rothkopf</surname><given-names>C. A.</given-names></name><name><surname>Peters</surname><given-names>J. R.</given-names></name></person-group> (<year>2016</year>). “<article-title>Catching heuristics are optimal control policies</article-title>,” in <source>Advances in Neural Information Processing Systems</source>, eds <person-group person-group-type="editor"><name><surname>Lee</surname><given-names>D. D.</given-names></name><name><surname>Sugiyama</surname><given-names>M.</given-names></name><name><surname>Luxburg</surname><given-names>U. V.</given-names></name><name><surname>Guyon</surname><given-names>I.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-name>Curran Associates, Inc.</publisher-name>), <fpage>1426</fpage>–<lpage>1434</lpage>.</mixed-citation>
              </ref>
              <ref id="B12">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Berthoz</surname><given-names>A.</given-names></name></person-group> (<year>2000</year>). <source>The Brain’s Sense of Movement.</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Harvard University Press</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B13">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binaee</surname><given-names>K.</given-names></name><name><surname>Diaz</surname><given-names>G.</given-names></name></person-group> (<year>2019</year>). <article-title>Movements of the eyes and hands are coordinated by a common predictive strategy</article-title>. <source>J. Vis.</source>
<volume>19</volume>, <fpage>3</fpage>–<lpage>3</lpage>. <pub-id pub-id-type="doi">10.1167/19.12.3</pub-id><?supplied-pmid 31585462?><pub-id pub-id-type="pmid">31585462</pub-id></mixed-citation>
              </ref>
              <ref id="B14">
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Binaee</surname><given-names>K.</given-names></name><name><surname>Diaz</surname><given-names>G.</given-names></name><name><surname>Pelz</surname><given-names>J.</given-names></name><name><surname>Phillips</surname><given-names>F.</given-names></name></person-group> (<year>2016</year>). “<article-title>Binocular eye tracking calibration during a virtual ball catching task using head mounted display</article-title>,” in <source>Proceedings of the ACM Symposium on Applied Perception</source>, (Anaheim: CA), <fpage>15</fpage>–<lpage>18</lpage>.</mixed-citation>
              </ref>
              <ref id="B15">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binsted</surname><given-names>G.</given-names></name><name><surname>Rolheiser</surname><given-names>T. M.</given-names></name><name><surname>Chua</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Decay in visuomotor representations during manual aiming</article-title>. <source>J. Mot. Behav.</source>
<volume>38</volume>, <fpage>82</fpage>–<lpage>87</lpage>. <pub-id pub-id-type="doi">10.3200/JMBR.38.2.82-87</pub-id><?supplied-pmid 16531391?><pub-id pub-id-type="pmid">16531391</pub-id></mixed-citation>
              </ref>
              <ref id="B16">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bootsma</surname><given-names>R. J.</given-names></name></person-group> (<year>2009</year>). <article-title>The (current) future is here!</article-title>. <source>Perception</source>
<volume>38</volume>, <fpage>851</fpage>–<lpage>858</lpage>. <?supplied-pmid 19806968?><pub-id pub-id-type="pmid">19806968</pub-id></mixed-citation>
              </ref>
              <ref id="B17">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bootsma</surname><given-names>R. J.</given-names></name><name><surname>van Wieringen</surname><given-names>P. C.</given-names></name></person-group> (<year>1990</year>). <article-title>Timing an attacking forehand drive in table tennis</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>16</volume>, <fpage>21</fpage>–<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.16.1.21</pub-id></mixed-citation>
              </ref>
              <ref id="B18">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosco</surname><given-names>G.</given-names></name><name><surname>Delle Monache</surname><given-names>S.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2012</year>). <article-title>Catching what we can’t see: manual interception of occluded fly-ball trajectories</article-title>. <source>PLoS One</source>
<volume>7</volume>:<fpage>e49381</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0049381</pub-id><?supplied-pmid 23166653?><pub-id pub-id-type="pmid">23166653</pub-id></mixed-citation>
              </ref>
              <ref id="B19">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brancazio</surname><given-names>P. J.</given-names></name></person-group> (<year>1985</year>). <article-title>Looking into chapman’s homer: the physics of judging a fly ball</article-title>. <source>Am. J. Phys.</source>
<volume>53</volume>, <fpage>849</fpage>–<lpage>855</lpage>. <pub-id pub-id-type="doi">10.1119/1.14350</pub-id></mixed-citation>
              </ref>
              <ref id="B20">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bratzke</surname><given-names>D.</given-names></name><name><surname>Ulrich</surname><given-names>R.</given-names></name></person-group> (<year>2021</year>). <article-title>Mental imagery of free fall: does a falling apple accelerate in our minds?</article-title>
<source>Timing Time Percept.</source>
<volume>9</volume>, <fpage>150</fpage>–<lpage>160</lpage>. <pub-id pub-id-type="doi">10.1163/22134468-bja10022</pub-id></mixed-citation>
              </ref>
              <ref id="B26">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Driesen</surname><given-names>B.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2014</year>). <article-title>Precise timing when hitting falling balls</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>8</volume>:<fpage>342</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2014.00342</pub-id><?supplied-pmid 24904380?><pub-id pub-id-type="pmid">24904380</pub-id></mixed-citation>
              </ref>
              <ref id="B21">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2007</year>). <article-title>Flexibility in intercepting moving objects</article-title>. <source>J. Vis.</source>
<volume>7</volume>, <fpage>14.1</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1167/7.5.14</pub-id><?supplied-pmid 18217854?><pub-id pub-id-type="pmid">18217854</pub-id></mixed-citation>
              </ref>
              <ref id="B22">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Continuous visual control of interception</article-title>. <source>Hum. Mov. Sci.</source>
<volume>30</volume>, <fpage>475</fpage>–<lpage>494</lpage>. <pub-id pub-id-type="doi">10.1016/j.humov.2010.12.007</pub-id><?supplied-pmid 21353717?><pub-id pub-id-type="pmid">21353717</pub-id></mixed-citation>
              </ref>
              <ref id="B23">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2015a</year>). <article-title>How moving backgrounds influence interception</article-title>. <source>PLoS One</source>
<volume>10</volume>:<fpage>e0119903</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0119903</pub-id><?supplied-pmid 25767873?><pub-id pub-id-type="pmid">25767873</pub-id></mixed-citation>
              </ref>
              <ref id="B24">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2015b</year>). <article-title>How people achieve their amazing temporal precision in interception</article-title>. <source>J. Vis.</source>
<volume>15</volume>:<fpage>8</fpage>. <pub-id pub-id-type="doi">10.1167/15.3.8</pub-id><?supplied-pmid 25767094?><pub-id pub-id-type="pmid">25767094</pub-id></mixed-citation>
              </ref>
              <ref id="B25">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2018</year>). <article-title>Continuously updating one’s predictions underlies successful interception</article-title>. <source>J. Neurophysiol.</source>
<volume>120</volume>, <fpage>3257</fpage>–<lpage>3274</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00517.2018</pub-id><?supplied-pmid 30379633?><pub-id pub-id-type="pmid">30379633</pub-id></mixed-citation>
              </ref>
              <ref id="B27">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>A.-M.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B.</given-names></name></person-group> (<year>2006</year>). <article-title>Determining whether a ball will land behind or in front of you: not just a combination of expansion and angular velocity</article-title>. <source>Vis. Res.</source>
<volume>46</volume>, <fpage>382</fpage>–<lpage>391</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2005.09.002</pub-id><?supplied-pmid 16271742?><pub-id pub-id-type="pmid">16271742</pub-id></mixed-citation>
              </ref>
              <ref id="B28">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruggeman</surname><given-names>H.</given-names></name><name><surname>Zosh</surname><given-names>W.</given-names></name><name><surname>Warren</surname><given-names>W. H.</given-names></name></person-group> (<year>2007</year>). <article-title>Optic flow drives human visuo-locomotor adaptation</article-title>. <source>Curr. Biol.</source>
<volume>17</volume>, <fpage>2035</fpage>–<lpage>2040</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2007.10.059</pub-id><?supplied-pmid 18023350?><pub-id pub-id-type="pmid">18023350</pub-id></mixed-citation>
              </ref>
              <ref id="B30">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calderone</surname><given-names>J. B.</given-names></name><name><surname>Kaiser</surname><given-names>M. K.</given-names></name></person-group> (<year>1989</year>). <article-title>Visual acceleration detection: effect of sign and motion orientation</article-title>. <source>Percept. Psychophys.</source>
<volume>45</volume>, <fpage>391</fpage>–<lpage>394</lpage>. <pub-id pub-id-type="doi">10.3758/bf03210711</pub-id><?supplied-pmid 2726400?><pub-id pub-id-type="pmid">2726400</pub-id></mixed-citation>
              </ref>
              <ref id="B31">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cámara</surname><given-names>C.</given-names></name><name><surname>de la Malla</surname><given-names>C.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name></person-group> (<year>2018</year>). <article-title>Eye movements in interception with delayed visual feedback</article-title>. <source>Exp. Brain Res.</source>
<volume>236</volume>, <fpage>1837</fpage>–<lpage>1847</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-018-5257-8</pub-id><?supplied-pmid 29675715?><pub-id pub-id-type="pmid">29675715</pub-id></mixed-citation>
              </ref>
              <ref id="B32">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chapman</surname><given-names>S.</given-names></name></person-group> (<year>1968</year>). <article-title>Catching a baseball</article-title>. <source>Am. J. Phys.</source>
<volume>36</volume>, <fpage>868</fpage>–<lpage>870</lpage>. <pub-id pub-id-type="doi">10.1119/1.1974297</pub-id></mixed-citation>
              </ref>
              <ref id="B33">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chodosh</surname><given-names>L. A.</given-names></name><name><surname>Lifson</surname><given-names>L. E.</given-names></name><name><surname>Tabin</surname><given-names>C.</given-names></name></person-group> (<year>1995</year>). <article-title>Play ball!</article-title>. <source>Science</source>
<volume>268</volume>, <fpage>1682</fpage>–<lpage>1683</lpage>. <pub-id pub-id-type="doi">10.1126/science.7792585</pub-id><?supplied-pmid 7792585?><pub-id pub-id-type="pmid">7792585</pub-id></mixed-citation>
              </ref>
              <ref id="B34">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craig</surname><given-names>C. M.</given-names></name><name><surname>Berton</surname><given-names>E.</given-names></name><name><surname>Rao</surname><given-names>G.</given-names></name><name><surname>Fernandez</surname><given-names>L.</given-names></name><name><surname>Bootsma</surname><given-names>R. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Judging where a ball will go: the case of curved free kicks in football</article-title>. <source>Naturwissenschaften</source>
<volume>93</volume>, <fpage>97</fpage>–<lpage>101</lpage>. <pub-id pub-id-type="doi">10.1007/s00114-005-0071-0</pub-id><?supplied-pmid 16450083?><pub-id pub-id-type="pmid">16450083</pub-id></mixed-citation>
              </ref>
              <ref id="B35">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Craik</surname><given-names>K. J. W.</given-names></name></person-group> (<year>1967</year>). <source>Nature of Explanation.</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B36">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crowell</surname><given-names>J. A.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name></person-group> (<year>1996</year>). <article-title>Ideal observer for heading judgments</article-title>. <source>Vis. Res.</source>
<volume>36</volume>, <fpage>471</fpage>–<lpage>490</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(95)00121-2</pub-id><?supplied-pmid 8746236?><pub-id pub-id-type="pmid">8746236</pub-id></mixed-citation>
              </ref>
              <ref id="B37">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crowell</surname><given-names>J. A.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name><name><surname>Shenoy</surname><given-names>K. V.</given-names></name><name><surname>Andersen</surname><given-names>R. A.</given-names></name></person-group> (<year>1998</year>). <article-title>Visual self-motion perception during head turns</article-title>. <source>Nat. Neurosci.</source>
<volume>1</volume>, <fpage>732</fpage>–<lpage>737</lpage>. <pub-id pub-id-type="doi">10.1038/3732</pub-id><?supplied-pmid 10196591?><pub-id pub-id-type="pmid">10196591</pub-id></mixed-citation>
              </ref>
              <ref id="B38">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cutting</surname><given-names>J. E.</given-names></name><name><surname>Vishton</surname><given-names>P. M.</given-names></name></person-group> (<year>1995</year>). “<article-title>Perceiving layout and knowing distances: the integration, relative potency, and contextual use of different information about depth</article-title>,” in <source>Perception of Space and Motion</source>, eds <person-group person-group-type="editor"><name><surname>Epstein</surname><given-names>W.</given-names></name><name><surname>Rogers</surname><given-names>S.</given-names></name></person-group> (<publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>), <fpage>69</fpage>–<lpage>117</lpage>.</mixed-citation>
              </ref>
              <ref id="B39">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Abbott</surname><given-names>L.</given-names></name></person-group> (<year>2001</year>). <source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems.</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B29">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Bruyn</surname><given-names>B.</given-names></name><name><surname>Orban</surname><given-names>G. A.</given-names></name></person-group> (<year>1988</year>). <article-title>Human velocity and direction discrimination measured with random dot patterns</article-title>. <source>Vis. Res.</source>
<volume>28</volume>, <fpage>1323</fpage>–<lpage>1335</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(88)90064-8</pub-id><?supplied-pmid 3256150?><pub-id pub-id-type="pmid">3256150</pub-id></mixed-citation>
              </ref>
              <ref id="B40">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Malla</surname><given-names>C.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Predictive plus online visual information optimizes temporal precision in interception</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>41</volume>, <fpage>1271</fpage>–<lpage>1280</lpage>. <pub-id pub-id-type="doi">10.1037/xhp0000075</pub-id><?supplied-pmid 26076178?><pub-id pub-id-type="pmid">26076178</pub-id></mixed-citation>
              </ref>
              <ref id="B41">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Malla</surname><given-names>C.</given-names></name><name><surname>Smeets</surname><given-names>J. B.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name></person-group> (<year>2017</year>). <article-title>Potential systematic interception errors are avoided when tracking the target with one’s eyes</article-title>. <source>Sci. Rep.</source>
<volume>7</volume>:<fpage>10793</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-017-11200-5</pub-id><?supplied-pmid 28883471?><pub-id pub-id-type="pmid">28883471</pub-id></mixed-citation>
              </ref>
              <ref id="B42">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>DeLucia</surname><given-names>P. R.</given-names></name></person-group> (<year>2004</year>). “<article-title>Multiple sources of information influence time-to-contact judgments: do heuristics accommodate limits in sensory and cognitive processes?</article-title>,” in <source>Advances in Psychology, Vol. 135. Time-to-Contact</source>, (<publisher-name>Amsterdam: Elsevier/North-Holland</publisher-name>), <fpage>243</fpage>–<lpage>285</lpage>.</mixed-citation>
              </ref>
              <ref id="B43">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeLucia</surname><given-names>P. R.</given-names></name><name><surname>Meza-Arroyo</surname><given-names>M.</given-names></name><name><surname>Baurès</surname><given-names>R.</given-names></name><name><surname>Ranjit</surname><given-names>M.</given-names></name><name><surname>Hsiang</surname><given-names>S.</given-names></name><name><surname>Gorman</surname><given-names>J. C.</given-names></name></person-group> (<year>2016</year>). <article-title>Continuous response monitoring of relative time-to-contact judgments: does effective information change during an approach event?</article-title>
<source>Ecol. Psychol.</source>
<volume>28</volume>, <fpage>1</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1080/10407413.2016.1121735</pub-id></mixed-citation>
              </ref>
              <ref id="B44">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dessing</surname><given-names>J. C.</given-names></name><name><surname>Wijdenes</surname><given-names>L. O.</given-names></name><name><surname>Peper</surname><given-names>C. E.</given-names></name><name><surname>Beek</surname><given-names>P. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Visuomotor transformation for interception: catching while fixating</article-title>. <source>Exp. Brain Res.</source>
<volume>196</volume>, <fpage>511</fpage>–<lpage>527</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-009-1882-6</pub-id><?supplied-pmid 19543722?><pub-id pub-id-type="pmid">19543722</pub-id></mixed-citation>
              </ref>
              <ref id="B45">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diaz</surname><given-names>G.</given-names></name><name><surname>Cooper</surname><given-names>J.</given-names></name><name><surname>Rothkopf</surname><given-names>C.</given-names></name><name><surname>Hayhoe</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Saccades to future ball location reveal memory-based prediction in a virtual-reality interception task</article-title>. <source>J. Vis.</source>
<volume>13</volume>:<fpage>20</fpage>. <pub-id pub-id-type="doi">10.1167/13.1.20</pub-id><?supplied-pmid 23325347?><pub-id pub-id-type="pmid">23325347</pub-id></mixed-citation>
              </ref>
              <ref id="B46">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitriou</surname><given-names>M.</given-names></name><name><surname>Wolpert</surname><given-names>D. M.</given-names></name><name><surname>Franklin</surname><given-names>D. W.</given-names></name></person-group> (<year>2013</year>). <article-title>The temporal evolution of feedback gains rapidly update to task demands</article-title>. <source>J. Neurosci.</source>
<volume>33</volume>, <fpage>10898</fpage>–<lpage>10909</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5669-12.2013</pub-id><?supplied-pmid 23804109?><pub-id pub-id-type="pmid">23804109</pub-id></mixed-citation>
              </ref>
              <ref id="B47">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ernst</surname><given-names>M. O.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name></person-group> (<year>2002</year>). <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>
<volume>415</volume>, <fpage>429</fpage>–<lpage>433</lpage>. <pub-id pub-id-type="doi">10.1038/415429a</pub-id><?supplied-pmid 11807554?><pub-id pub-id-type="pmid">11807554</pub-id></mixed-citation>
              </ref>
              <ref id="B48">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>A. A.</given-names></name><name><surname>Wolpert</surname><given-names>D. M.</given-names></name></person-group> (<year>2009</year>). <article-title>Near optimal combination of sensory and motor uncertainty in time during a naturalistic perception-action task</article-title>. <source>J. Neurophysiol.</source>
<volume>101</volume>, <fpage>1901</fpage>–<lpage>1912</lpage>. <pub-id pub-id-type="doi">10.1152/jn.90974.2008</pub-id><?supplied-pmid 19109455?><pub-id pub-id-type="pmid">19109455</pub-id></mixed-citation>
              </ref>
              <ref id="B49">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fajen</surname><given-names>B. R.</given-names></name></person-group> (<year>2005a</year>). <article-title>Calibration, information, and control strategies for braking to avoid a collision</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>31</volume>, <fpage>480</fpage>–<lpage>501</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.31.3.480</pub-id><?supplied-pmid 15982127?><pub-id pub-id-type="pmid">15982127</pub-id></mixed-citation>
              </ref>
              <ref id="B50">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fajen</surname><given-names>B. R.</given-names></name></person-group> (<year>2005b</year>). <article-title>Perceiving possibilities for action: on the necessity of calibration and perceptual learning for the visual guidance of action</article-title>. <source>Perception</source>
<volume>34</volume>, <fpage>717</fpage>–<lpage>740</lpage>. <pub-id pub-id-type="doi">10.1068/p5405</pub-id><?supplied-pmid 16042193?><pub-id pub-id-type="pmid">16042193</pub-id></mixed-citation>
              </ref>
              <ref id="B51">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fajen</surname><given-names>B. R.</given-names></name></person-group> (<year>2007</year>). <article-title>Affordance-based control of visually guided action</article-title>. <source>Ecol. Psychol.</source>
<volume>19</volume>, <fpage>383</fpage>–<lpage>410</lpage>. <pub-id pub-id-type="doi">10.1080/10407410701557877</pub-id></mixed-citation>
              </ref>
              <ref id="B52">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fink</surname><given-names>P. W.</given-names></name><name><surname>Foo</surname><given-names>P. S.</given-names></name><name><surname>Warren</surname><given-names>W. H.</given-names></name></person-group> (<year>2009</year>). <article-title>Catching fly balls in virtual reality: a critical test of the outfielder problem</article-title>. <source>J. Vis.</source>
<volume>9</volume>, <fpage>14.1</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1167/9.13.14</pub-id><?supplied-pmid 20055547?><pub-id pub-id-type="pmid">20055547</pub-id></mixed-citation>
              </ref>
              <ref id="B53">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>J. C.</given-names></name></person-group> (<year>2014</year>). <source>An Investigation into the Directional and Amplitude Aspects of An Internal Model of Gravity.</source>
<publisher-name>Thesis. Manchester Metropolitan University</publisher-name></mixed-citation>
              </ref>
              <ref id="B54">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>2010</year>). <article-title>The free-energy principle: a unified brain theory?</article-title>
<source>Nat. Rev. Neurosci.</source>
<volume>11</volume>, <fpage>127</fpage>–<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2787</pub-id><?supplied-pmid 20068583?><pub-id pub-id-type="pmid">20068583</pub-id></mixed-citation>
              </ref>
              <ref id="B55">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>J. J.</given-names></name></person-group> (<year>1966</year>). <source>The Senses Considered As Perceptual Systems.</source>
<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Houghton Mifflin</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B56">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gibson</surname><given-names>J. J.</given-names></name></person-group> (<year>1979</year>). <source>The Ecological Approach to Visual Perception.</source>
<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Houghton Mifflin Company</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B57">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glennerster</surname><given-names>A.</given-names></name><name><surname>Tcheang</surname><given-names>L.</given-names></name><name><surname>Gilson</surname><given-names>S. J.</given-names></name><name><surname>Fitzgibbon</surname><given-names>A. W.</given-names></name><name><surname>Parker</surname><given-names>A. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Humans ignore motion and stereo cues in favor of a fictional stable world</article-title>. <source>Curr. Biol.</source>
<volume>16</volume>, <fpage>428</fpage>–<lpage>432</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2006.01.019</pub-id><?supplied-pmid 16488879?><pub-id pub-id-type="pmid">16488879</pub-id></mixed-citation>
              </ref>
              <ref id="B58">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gómez</surname><given-names>J.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>Synergies between optical and physical variables in intercepting parabolic targets</article-title>. <source>Front. Behav. Neurosci.</source>
<volume>7</volume>:<fpage>46</fpage>. <pub-id pub-id-type="doi">10.3389/fnbeh.2013.00046</pub-id><?supplied-pmid 23720614?><pub-id pub-id-type="pmid">23720614</pub-id></mixed-citation>
              </ref>
              <ref id="B59">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottsdanker</surname><given-names>R.</given-names></name><name><surname>Frick</surname><given-names>J. W.</given-names></name><name><surname>Lockard</surname><given-names>R. B.</given-names></name></person-group> (<year>1961</year>). <article-title>Identifying the acceleration of visual targets</article-title>. <source>Br. J. Psychol.</source>
<volume>52</volume>, <fpage>31</fpage>–<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1111/j.2044-8295.1961.tb00765.x</pub-id><?supplied-pmid 13707460?><pub-id pub-id-type="pmid">13707460</pub-id></mixed-citation>
              </ref>
              <ref id="B60">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gravano</surname><given-names>S.</given-names></name><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2017</year>). <article-title>Mental imagery of gravitational motion</article-title>. <source>Cortex</source>
<volume>95</volume>, <fpage>172</fpage>–<lpage>191</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2017.08.005</pub-id><?supplied-pmid 28910670?><pub-id pub-id-type="pmid">28910670</pub-id></mixed-citation>
              </ref>
              <ref id="B61">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>R.</given-names></name></person-group> (<year>2017</year>). <article-title>Transfer of training from virtual to real baseball batting</article-title>. <source>Front. Psychol.</source>
<volume>8</volume>:<fpage>2183</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2017.02183</pub-id><?supplied-pmid 29326627?><pub-id pub-id-type="pmid">29326627</pub-id></mixed-citation>
              </ref>
              <ref id="B62">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>R.</given-names></name><name><surname>Regan</surname><given-names>D.</given-names></name></person-group> (<year>1998</year>). <article-title>Accuracy of estimating time to collision using binocular and monocular information</article-title>. <source>Vis. Res.</source>
<volume>38</volume>, <fpage>499</fpage>–<lpage>512</lpage>. <pub-id pub-id-type="doi">10.1016/s0042-6989(97)00230-7</pub-id><?supplied-pmid 9536374?><pub-id pub-id-type="pmid">9536374</pub-id></mixed-citation>
              </ref>
              <ref id="B63">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>D. J.</given-names></name><name><surname>Bird</surname><given-names>J. M.</given-names></name><name><surname>Smart</surname><given-names>P. A.</given-names></name><name><surname>Wilson</surname><given-names>M. R.</given-names></name><name><surname>Vine</surname><given-names>S. J.</given-names></name></person-group> (<year>2020</year>). <article-title>A framework for the testing and validation of simulated environments in experimentation and training</article-title>. <source>Front. Psychol.</source>
<volume>11</volume>:<fpage>605</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2020.00605</pub-id><?supplied-pmid 32296379?><pub-id pub-id-type="pmid">32296379</pub-id></mixed-citation>
              </ref>
              <ref id="B64">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>J. M.</given-names></name><name><surname>Watamaniuk</surname><given-names>S. N. J.</given-names></name></person-group> (<year>1995</year>). <article-title>Speed discrimination of motion-in-depth using binocular cues</article-title>. <source>Vis. Res.</source>
<volume>35</volume>, <fpage>885</fpage>–<lpage>896</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(94)00194-q</pub-id><?supplied-pmid 7762146?><pub-id pub-id-type="pmid">7762146</pub-id></mixed-citation>
              </ref>
              <ref id="B65">
                <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hayhoe</surname><given-names>M.</given-names></name><name><surname>Mennie</surname><given-names>N.</given-names></name><name><surname>Sullivan</surname><given-names>B.</given-names></name><name><surname>Gorgos</surname><given-names>K.</given-names></name></person-group> (<year>2005</year>). “<article-title>The role of internal models and prediction in catching balls</article-title>,” in <source>From Reactive to Anticipatory Cognitive Embodied Systems</source>, ed C. Castelfranchi (Menlo Park, CA: American Association for Artificial Intelligence), <fpage>78</fpage>–<lpage>82</lpage>.</mixed-citation>
              </ref>
              <ref id="B67">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hecht</surname><given-names>H.</given-names></name><name><surname>Kaiser</surname><given-names>M. K.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name></person-group> (<year>1996</year>). <article-title>Gravitational acceleration as a cue for absolute size and distance?</article-title>
<source>Percept. Psychophys.</source>
<volume>58</volume>, <fpage>1066</fpage>–<lpage>1075</lpage>. <pub-id pub-id-type="doi">10.3758/bf03206833</pub-id><?supplied-pmid 8920842?><pub-id pub-id-type="pmid">8920842</pub-id></mixed-citation>
              </ref>
              <ref id="B66">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hecht</surname><given-names>H.</given-names></name><name><surname>Savelsbergh</surname><given-names>G.</given-names></name></person-group> (<year>2004</year>). <source>Time-To-Contact.</source>
<publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B68">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hosking</surname><given-names>S. G.</given-names></name><name><surname>Crassini</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>The effects of familiar size and object trajectories on time-to-contact judgements</article-title>. <source>Exp. Brain Res.</source>
<volume>203</volume>, <fpage>541</fpage>–<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-010-2258-7</pub-id><?supplied-pmid 20440609?><pub-id pub-id-type="pmid">20440609</pub-id></mixed-citation>
              </ref>
              <ref id="B69">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Indovina</surname><given-names>I.</given-names></name><name><surname>Maffei</surname><given-names>V.</given-names></name><name><surname>Bosco</surname><given-names>G.</given-names></name><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Macaluso</surname><given-names>E.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2005</year>). <article-title>Representation of visual gravitational motion in the human vestibular cortex</article-title>. <source>Science</source>
<volume>308</volume>, <fpage>416</fpage>–<lpage>419</lpage>. <pub-id pub-id-type="doi">10.1126/science.1107961</pub-id><?supplied-pmid 15831760?><pub-id pub-id-type="pmid">15831760</pub-id></mixed-citation>
              </ref>
              <ref id="B70">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ittelson</surname><given-names>W. H.</given-names></name></person-group> (<year>1951</year>). <article-title>Size as a cue to distance: static localization</article-title>. <source>Am. J. Psychol.</source>
<volume>64</volume>, <fpage>54</fpage>–<lpage>67</lpage>. <pub-id pub-id-type="doi">10.2307/1418595</pub-id><?supplied-pmid 14819380?><pub-id pub-id-type="pmid">14819380</pub-id></mixed-citation>
              </ref>
              <ref id="B71">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>D. M.</given-names></name><name><surname>Michaels</surname><given-names>C. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Lateral interception I: operative optical variables, attunement, and calibration</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>32</volume>, <fpage>443</fpage>–<lpage>458</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.32.2.443</pub-id><?supplied-pmid 16634681?><pub-id pub-id-type="pmid">16634681</pub-id></mixed-citation>
              </ref>
              <ref id="B72">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>D. M.</given-names></name><name><surname>Michaels</surname><given-names>C. F.</given-names></name></person-group> (<year>2007</year>). <article-title>Direct learning</article-title>. <source>Ecol. Psychol.</source>
<volume>19</volume>, <fpage>321</fpage>–<lpage>349</lpage>. <pub-id pub-id-type="doi">10.1080/10407410701432337</pub-id></mixed-citation>
              </ref>
              <ref id="B73">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jörges</surname><given-names>B.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). <article-title>Gravity as a strong prior: implications for perception and action</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>11</volume>:<fpage>203</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2017.00203</pub-id><?supplied-pmid 33015572?><pub-id pub-id-type="pmid">28503140</pub-id></mixed-citation>
              </ref>
              <ref id="B74">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jörges</surname><given-names>B.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Earth-gravity congruent motion facilitates ocular control for pursuit of parabolic trajectories</article-title>. <source>Sci. Rep.</source>
<volume>9</volume>:<fpage>14094</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-019-50512-6</pub-id><?supplied-pmid 31575901?><pub-id pub-id-type="pmid">31575901</pub-id></mixed-citation>
              </ref>
              <ref id="B75">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jörges</surname><given-names>B.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Determining mean and standard deviation of the strong prior through simulations</article-title>. <source>PLoS One</source>
<volume>15</volume>:<fpage>e0236732</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0236732</pub-id><?supplied-pmid 25454700?><pub-id pub-id-type="pmid">32813686</pub-id></mixed-citation>
              </ref>
              <ref id="B77">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Judge</surname><given-names>S.</given-names></name><name><surname>Rind</surname><given-names>F.</given-names></name></person-group> (<year>1997</year>). <article-title>The locust DCMD, a movement-detecting neurone tightly tuned to collision trajectories</article-title>. <source>J. Exp. Biol.</source>
<volume>200</volume>, <fpage>2209</fpage>–<lpage>2216</lpage>. <pub-id pub-id-type="doi">10.1242/jeb.200.16.2209</pub-id><?supplied-pmid 9320123?><pub-id pub-id-type="pmid">9320123</pub-id></mixed-citation>
              </ref>
              <ref id="B78">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kagan</surname><given-names>D.</given-names></name><name><surname>Nathan</surname><given-names>A. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Simplified models for the drag coefficient of a pitched baseball</article-title>. <source>Phys. Teacher</source>
<volume>52</volume>, <fpage>278</fpage>–<lpage>280</lpage>. <pub-id pub-id-type="doi">10.1119/1.4872406</pub-id></mixed-citation>
              </ref>
              <ref id="B79">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalman</surname><given-names>R. E.</given-names></name></person-group> (<year>1960</year>). <article-title>A new approach to linear filtering and prediction problems</article-title>. <source>J. Basic Eng.</source>
<volume>82</volume>, <fpage>35</fpage>–<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1115/1.3662552</pub-id></mixed-citation>
              </ref>
              <ref id="B80">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katsumata</surname><given-names>H.</given-names></name><name><surname>Russell</surname><given-names>D. M.</given-names></name></person-group> (<year>2012</year>). <article-title>Prospective versus predictive control in timing of hitting a falling ball</article-title>. <source>Exp. Brain Res.</source>
<volume>216</volume>, <fpage>499</fpage>–<lpage>514</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-011-2954-y</pub-id><?supplied-pmid 22120106?><pub-id pub-id-type="pmid">22120106</pub-id></mixed-citation>
              </ref>
              <ref id="B81">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keil</surname><given-names>M. S.</given-names></name><name><surname>López-Moliner</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>Unifying time to contact estimation and collision avoidance across species</article-title>. <source>PLoS Comput. Biol.</source>
<volume>8</volume>:<fpage>e1002625</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1002625</pub-id><?supplied-pmid 22915999?><pub-id pub-id-type="pmid">22915999</pub-id></mixed-citation>
              </ref>
              <ref id="B82">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kersten</surname><given-names>D.</given-names></name><name><surname>Mamassian</surname><given-names>P.</given-names></name><name><surname>Yuille</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Object perception as bayesian inference</article-title>. <source>Annu. Rev. Psychol.</source>
<volume>55</volume>, <fpage>271</fpage>–<lpage>304</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.142005</pub-id><?supplied-pmid 14744217?><pub-id pub-id-type="pmid">14744217</pub-id></mixed-citation>
              </ref>
              <ref id="B83">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kistemaker</surname><given-names>D. A.</given-names></name><name><surname>Faber</surname><given-names>H.</given-names></name><name><surname>Beek</surname><given-names>P. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Catching fly balls: a simulation study of the Chapman strategy</article-title>. <source>Hum. Mov. Sci.</source>
<volume>28</volume>, <fpage>236</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1016/j.humov.2008.11.001</pub-id><?supplied-pmid 19110332?><pub-id pub-id-type="pmid">19110332</pub-id></mixed-citation>
              </ref>
              <ref id="B84">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kistemaker</surname><given-names>D. A.</given-names></name><name><surname>Van Soest</surname><given-names>A. J.</given-names></name><name><surname>Bobbert</surname><given-names>M. F.</given-names></name></person-group> (<year>2006</year>). <article-title>Is equilibrium point control feasible for fast goal-directed single-joint movements?</article-title>
<source>J. Neurophysiol.</source>
<volume>95</volume>, <fpage>2898</fpage>–<lpage>2912</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00983.2005</pub-id><?supplied-pmid 16436480?><pub-id pub-id-type="pmid">16436480</pub-id></mixed-citation>
              </ref>
              <ref id="B85">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S. A.</given-names></name><name><surname>Levi</surname><given-names>D. M.</given-names></name></person-group> (<year>1987</year>). <article-title>Position sense of the peripheral retina</article-title>. <source>J. Opt. Soc. Am. A</source>
<volume>4</volume>, <fpage>1543</fpage>–<lpage>1553</lpage>. <pub-id pub-id-type="doi">10.1364/josaa.4.001543</pub-id><?supplied-pmid 3625335?><pub-id pub-id-type="pmid">3625335</pub-id></mixed-citation>
              </ref>
              <ref id="B86">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knill</surname><given-names>D. C.</given-names></name><name><surname>Pouget</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>The Bayesian brain: the role of uncertainty in neural coding and computation</article-title>. <source>Trends Neurosci.</source>
<volume>27</volume>, <fpage>712</fpage>–<lpage>719</lpage>. <pub-id pub-id-type="doi">10.1016/j.tins.2004.10.007</pub-id><?supplied-pmid 15541511?><pub-id pub-id-type="pmid">15541511</pub-id></mixed-citation>
              </ref>
              <ref id="B87">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwon</surname><given-names>O.-S.</given-names></name><name><surname>Tadin</surname><given-names>D.</given-names></name><name><surname>Knill</surname><given-names>D. C.</given-names></name></person-group> (<year>2015</year>). <article-title>Unifying account of visual motion and position perception</article-title>. <source>Proc. Natl. Acad. Sci. U S A</source>
<volume>112</volume>, <fpage>8142</fpage>–<lpage>8147</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1500361112</pub-id><?supplied-pmid 26080410?><pub-id pub-id-type="pmid">26080410</pub-id></mixed-citation>
              </ref>
              <ref id="B88">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lacquaniti</surname><given-names>F.</given-names></name><name><surname>Maioli</surname><given-names>C.</given-names></name></person-group> (<year>1989</year>). <article-title>The role of preparation in tuning anticipatory and reflex responses during catching</article-title>. <source>J. Neurosci.</source>
<volume>9</volume>, <fpage>134</fpage>–<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-01-00134.1989</pub-id><?supplied-pmid 2913200?><pub-id pub-id-type="pmid">2913200</pub-id></mixed-citation>
              </ref>
              <ref id="B89">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D. N.</given-names></name></person-group> (<year>1976</year>). <article-title>A theory of visual control of braking based on information about time-to-collision</article-title>. <source>Perception</source>
<volume>5</volume>, <fpage>437</fpage>–<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1068/p050437</pub-id><?supplied-pmid 1005020?><pub-id pub-id-type="pmid">1005020</pub-id></mixed-citation>
              </ref>
              <ref id="B90">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D.</given-names></name><name><surname>Young</surname><given-names>D.</given-names></name><name><surname>Reddish</surname><given-names>P.</given-names></name><name><surname>Lough</surname><given-names>S.</given-names></name><name><surname>Clayton</surname><given-names>T.</given-names></name></person-group> (<year>1983</year>). <article-title>Visual timing in hitting an accelerating ball</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>35</volume>, <fpage>333</fpage>–<lpage>346</lpage>. <pub-id pub-id-type="doi">10.1080/14640748308402138</pub-id><?supplied-pmid 6571315?><pub-id pub-id-type="pmid">6571315</pub-id></mixed-citation>
              </ref>
              <ref id="B91">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>R. F.</given-names></name><name><surname>Gaymard</surname><given-names>B. M.</given-names></name><name><surname>Tamargo</surname><given-names>R. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Efference copy provides the eye position information required for visually guided reaching</article-title>. <source>J. Neurophysiol.</source>
<volume>80</volume>, <fpage>1605</fpage>–<lpage>1608</lpage>. <pub-id pub-id-type="doi">10.1152/jn.1998.80.3.1605</pub-id><?supplied-pmid 9744968?><pub-id pub-id-type="pmid">9744968</pub-id></mixed-citation>
              </ref>
              <ref id="B92">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D.</given-names></name><name><surname>Todorov</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Evidence for the flexible sensorimotor strategies predicted by optimal feedback control</article-title>. <source>J. Neurosci.</source>
<volume>27</volume>, <fpage>9354</fpage>–<lpage>9368</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1110-06.2007</pub-id><?supplied-pmid 17728449?><pub-id pub-id-type="pmid">17728449</pub-id></mixed-citation>
              </ref>
              <ref id="B93">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name></person-group> (<year>2016</year>). <article-title>Flexible timing of eye movements when catching a ball</article-title>. <source>J. Vis.</source>
<volume>16</volume>:<fpage>13</fpage>. <pub-id pub-id-type="doi">10.1167/16.5.13</pub-id><?supplied-pmid 26982371?><pub-id pub-id-type="pmid">26982371</pub-id></mixed-citation>
              </ref>
              <ref id="B95">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Louw</surname><given-names>S.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Catching a gently thrown ball</article-title>. <source>Exp. Brain Res.</source>
<volume>206</volume>, <fpage>409</fpage>–<lpage>417</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-010-2421-1</pub-id><?supplied-pmid 20862460?><pub-id pub-id-type="pmid">20862460</pub-id></mixed-citation>
              </ref>
              <ref id="B96">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Field</surname><given-names>D. T.</given-names></name><name><surname>Wann</surname><given-names>J. P.</given-names></name></person-group> (<year>2007</year>). <article-title>Interceptive timing: prior knowledge matters</article-title>. <source>J. Vis.</source>
<volume>7</volume>, <fpage>11.1</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1167/7.13.11</pub-id><?supplied-pmid 17997639?><pub-id pub-id-type="pmid">17997639</pub-id></mixed-citation>
              </ref>
              <ref id="B94">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Keil</surname><given-names>M. S.</given-names></name></person-group> (<year>2012</year>). <article-title>People favour imperfect catching by assuming a stable world</article-title>. <source>PLoS One</source>
<volume>7</volume>:<fpage>e35705</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0035705</pub-id><?supplied-pmid 22558205?><pub-id pub-id-type="pmid">22558205</pub-id></mixed-citation>
              </ref>
              <ref id="B97">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>López-Moliner</surname><given-names>J.</given-names></name><name><surname>Supèr</surname><given-names>H.</given-names></name><name><surname>Keil</surname><given-names>M. S.</given-names></name></person-group> (<year>2013</year>). <article-title>The time course of estimating time-to-contact: switching between sources of information</article-title>. <source>Vis. Res.</source>
<volume>92</volume>, <fpage>53</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2013.09.007</pub-id><?supplied-pmid 24075899?><pub-id pub-id-type="pmid">24075899</pub-id></mixed-citation>
              </ref>
              <ref id="B98">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mann</surname><given-names>D. L.</given-names></name><name><surname>Spratford</surname><given-names>W.</given-names></name><name><surname>Abernethy</surname><given-names>B.</given-names></name></person-group> (<year>2013</year>). <article-title>The head tracks and gaze predicts: how the world’s best batters hit a ball</article-title>. <source>PLoS One</source>
<volume>8</volume>:<fpage>e58289</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0058289</pub-id><?supplied-pmid 23516460?><pub-id pub-id-type="pmid">23516460</pub-id></mixed-citation>
              </ref>
              <ref id="B99">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazyn</surname><given-names>L. I. N.</given-names></name><name><surname>Savelsbergh</surname><given-names>G. J. P.</given-names></name><name><surname>Montagne</surname><given-names>G.</given-names></name><name><surname>Lenoir</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Planning and on-line control of catching as a function of perceptual-motor constraints</article-title>. <source>Acta Psychol.</source>
<volume>126</volume>, <fpage>59</fpage>–<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1016/j.actpsy.2006.10.001</pub-id><?supplied-pmid 17239809?><pub-id pub-id-type="pmid">17239809</pub-id></mixed-citation>
              </ref>
              <ref id="B100">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McBeath</surname><given-names>M. K.</given-names></name><name><surname>Nathan</surname><given-names>A. M.</given-names></name><name><surname>Bahill</surname><given-names>A. T.</given-names></name><name><surname>Baldwin</surname><given-names>D. G.</given-names></name></person-group> (<year>2008</year>). <article-title>Paradoxical pop-ups: why are they difficult to catch?</article-title>
<source>Am. J. Phys.</source>
<volume>76</volume>, <fpage>723</fpage>–<lpage>729</lpage>. <pub-id pub-id-type="doi">10.1119/1.2937899</pub-id></mixed-citation>
              </ref>
              <ref id="B101">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McBeath</surname><given-names>M. K.</given-names></name><name><surname>Tang</surname><given-names>T. Y.</given-names></name><name><surname>Shaffer</surname><given-names>D. M.</given-names></name></person-group> (<year>2018</year>). <article-title>The geometry of consciousness</article-title>. <source>Conscious. Cogn.</source>
<volume>64</volume>, <fpage>207</fpage>–<lpage>215</lpage>. <pub-id pub-id-type="doi">10.1016/j.concog.2018.04.015</pub-id><?supplied-pmid 30031669?><pub-id pub-id-type="pmid">30031669</pub-id></mixed-citation>
              </ref>
              <ref id="B102">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McBeath</surname><given-names>M.</given-names></name><name><surname>Shaffer</surname><given-names>D.</given-names></name><name><surname>Kaiser</surname><given-names>M.</given-names></name></person-group> (<year>1995</year>). <article-title>How baseball outfielders determine where to run to catch fly balls</article-title>. <source>Science</source>
<volume>268</volume>, <fpage>569</fpage>–<lpage>573</lpage>. <pub-id pub-id-type="doi">10.1126/science.7725104</pub-id><?supplied-pmid 7725104?><pub-id pub-id-type="pmid">7725104</pub-id></mixed-citation>
              </ref>
              <ref id="B103">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McIntyre</surname><given-names>J.</given-names></name><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Berthoz</surname><given-names>A.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2001</year>). <article-title>Does the brain model newton’s laws?</article-title>
<source>Nat. Neurosci.</source>
<volume>4</volume>, <fpage>693</fpage>–<lpage>694</lpage>. <pub-id pub-id-type="doi">10.1038/89477</pub-id><?supplied-pmid 11426224?><pub-id pub-id-type="pmid">11426224</pub-id></mixed-citation>
              </ref>
              <ref id="B104">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKee</surname><given-names>S. P.</given-names></name></person-group> (<year>1981</year>). <article-title>A local mechanism for differential velocity detection</article-title>. <source>Vis. Res.</source>
<volume>21</volume>, <fpage>491</fpage>–<lpage>500</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(81)90095-x</pub-id><?supplied-pmid 7269327?><pub-id pub-id-type="pmid">7269327</pub-id></mixed-citation>
              </ref>
              <ref id="B105">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKee</surname><given-names>S. P.</given-names></name><name><surname>Welch</surname><given-names>L.</given-names></name></person-group> (<year>1992</year>). <article-title>The precision of size constancy</article-title>. <source>Vis. Res.</source>
<volume>32</volume>, <fpage>1447</fpage>–<lpage>1460</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(92)90201-s</pub-id><?supplied-pmid 1455718?><pub-id pub-id-type="pmid">1455718</pub-id></mixed-citation>
              </ref>
              <ref id="B106">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLeod</surname><given-names>P.</given-names></name><name><surname>Dienes</surname><given-names>Z.</given-names></name></person-group> (<year>1993</year>). <article-title>Running to catch the ball</article-title>. <source>Nature</source>
<volume>362</volume>, <fpage>23</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1038/362023a0</pub-id><?supplied-pmid 8446164?><pub-id pub-id-type="pmid">8446164</pub-id></mixed-citation>
              </ref>
              <ref id="B107">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLeod</surname><given-names>P.</given-names></name><name><surname>Dienes</surname><given-names>Z.</given-names></name></person-group> (<year>1996</year>). <article-title>Do fielders know where to go to catch the ball or only how to get there?</article-title>
<source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>22</volume>, <fpage>531</fpage>–<lpage>543</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.22.3.531</pub-id></mixed-citation>
              </ref>
              <ref id="B108">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLeod</surname><given-names>P.</given-names></name><name><surname>Reed</surname><given-names>N.</given-names></name><name><surname>Dienes</surname><given-names>Z.</given-names></name></person-group> (<year>2006</year>). <article-title>The generalized optic acceleration cancellation theory of catching</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>32</volume>, <fpage>139</fpage>–<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.32.1.139</pub-id><?supplied-pmid 16478332?><pub-id pub-id-type="pmid">16478332</pub-id></mixed-citation>
              </ref>
              <ref id="B109">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname><given-names>C. F.</given-names></name><name><surname>Oudejans</surname><given-names>R. R. D.</given-names></name></person-group> (<year>1992</year>). <article-title>The optics and actions of catching fly balls: zeroing out optical acceleration</article-title>. <source>Ecol. Psychol.</source>
<volume>4</volume>, <fpage>199</fpage>–<lpage>222</lpage>. <pub-id pub-id-type="doi">10.1207/s15326969eco0404_1</pub-id></mixed-citation>
              </ref>
              <ref id="B110">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>W. L.</given-names></name><name><surname>Maffei</surname><given-names>V.</given-names></name><name><surname>Bosco</surname><given-names>G.</given-names></name><name><surname>Iosa</surname><given-names>M.</given-names></name><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Macaluso</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Vestibular nuclei and cerebellum put visual gravitational motion in context</article-title>. <source>J. Neurophysiol.</source><volume>99</volume>, <fpage>1969</fpage>–<lpage>1982</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00889.2007</pub-id><?supplied-pmid 18057110?><pub-id pub-id-type="pmid">18057110</pub-id></mixed-citation>
              </ref>
              <ref id="B111">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>A.</given-names></name><name><surname>Campbell</surname><given-names>M.</given-names></name><name><surname>Ranieri</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>Implications of eye tracking technology for applied sport psychology</article-title>. <source>J. Sport Psychol. Action</source>
<volume>9</volume>, <fpage>249</fpage>–<lpage>259</lpage>. <pub-id pub-id-type="doi">10.1080/21520704.2018.1511660</pub-id></mixed-citation>
              </ref>
              <ref id="B112">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moscatelli</surname><given-names>A.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2011</year>). <article-title>The weight of time: gravitational force enhances discrimination of visual motion duration</article-title>. <source>J. Vis.</source>
<volume>11</volume>:<fpage>5</fpage>. <pub-id pub-id-type="doi">10.1167/11.4.5</pub-id><?supplied-pmid 21478379?><pub-id pub-id-type="pmid">21478379</pub-id></mixed-citation>
              </ref>
              <ref id="B113">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nijhawan</surname><given-names>R.</given-names></name></person-group> (<year>1994</year>). <article-title>Motion extrapolation in catching</article-title>. <source>Nature</source>
<volume>370</volume>, <fpage>256</fpage>–<lpage>257</lpage>. <pub-id pub-id-type="doi">10.1038/370256b0</pub-id><?supplied-pmid 8035873?><pub-id pub-id-type="pmid">8035873</pub-id></mixed-citation>
              </ref>
              <ref id="B114">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberle</surname><given-names>C. D.</given-names></name><name><surname>McBeath</surname><given-names>M. K.</given-names></name><name><surname>Madigan</surname><given-names>S. C.</given-names></name><name><surname>Sugar</surname><given-names>T. G.</given-names></name></person-group> (<year>2005</year>). <article-title>The Galileo bias: a naive conceptual belief that influences people’s perceptions and performance in a ball-dropping task</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>31</volume>, <fpage>643</fpage>–<lpage>653</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.31.4.643</pub-id><?supplied-pmid 16060770?><pub-id pub-id-type="pmid">16060770</pub-id></mixed-citation>
              </ref>
              <ref id="B115">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orban</surname><given-names>G. A.</given-names></name><name><surname>de Wolf</surname><given-names>J.</given-names></name><name><surname>Maes</surname><given-names>H.</given-names></name></person-group> (<year>1984</year>). <article-title>Factors influencing velocity coding in the human visual system</article-title>. <source>Vis. Res.</source>
<volume>24</volume>, <fpage>33</fpage>–<lpage>39</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(84)90141-x</pub-id><?supplied-pmid 6695505?><pub-id pub-id-type="pmid">6695505</pub-id></mixed-citation>
              </ref>
              <ref id="B116">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oudejans</surname><given-names>R. R. D.</given-names></name><name><surname>Michaels</surname><given-names>C. F.</given-names></name><name><surname>Bakker</surname><given-names>F. C.</given-names></name><name><surname>Davids</surname><given-names>K.</given-names></name></person-group> (<year>1999</year>). <article-title>Shedding some light on catching in the dark: perceptual mechanisms for catching fly balls</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>25</volume>, <fpage>531</fpage>–<lpage>542</lpage>. <pub-id pub-id-type="doi">10.1037//0096-1523.25.2.531</pub-id><?supplied-pmid 10205865?><pub-id pub-id-type="pmid">10205865</pub-id></mixed-citation>
              </ref>
              <ref id="B117">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peper</surname><given-names>L.</given-names></name><name><surname>Bootsma</surname><given-names>R. J.</given-names></name><name><surname>Mestre</surname><given-names>D. R.</given-names></name><name><surname>Bakker</surname><given-names>F. C.</given-names></name></person-group> (<year>1994</year>). <article-title>Catching balls: how to get the hand to the right place at the right time</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>20</volume>, <fpage>591</fpage>–<lpage>612</lpage>. <pub-id pub-id-type="doi">10.1037//0096-1523.20.3.591</pub-id><?supplied-pmid 8027714?><pub-id pub-id-type="pmid">8027714</pub-id></mixed-citation>
              </ref>
              <ref id="B118">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>M. A. K.</given-names></name><name><surname>Ma</surname><given-names>W. J.</given-names></name><name><surname>Shams</surname><given-names>L.</given-names></name></person-group> (<year>2016</year>). <article-title>The Size-Weight Illusion is not anti-Bayesian after all: a unifying Bayesian account</article-title>. <source>PeerJ</source>
<volume>4</volume>:<fpage>e2124</fpage>. <pub-id pub-id-type="doi">10.7717/peerj.2124</pub-id><?supplied-pmid 27350899?><pub-id pub-id-type="pmid">27350899</pub-id></mixed-citation>
              </ref>
              <ref id="B119">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizlo</surname><given-names>Z.</given-names></name></person-group> (<year>2001</year>). <article-title>Perception viewed as an inverse problem</article-title>. <source>Vis. Res.</source>
<volume>41</volume>, <fpage>3145</fpage>–<lpage>3161</lpage>. <pub-id pub-id-type="doi">10.1016/s0042-6989(01)00173-0</pub-id><?supplied-pmid 11711140?><pub-id pub-id-type="pmid">11711140</pub-id></mixed-citation>
              </ref>
              <ref id="B120">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Portfors-Yeomans</surname><given-names>C. V.</given-names></name><name><surname>Regan</surname><given-names>D.</given-names></name></person-group> (<year>1996</year>). <article-title>Cyclopean discrimination thresholds for the direction and speed of motion in depth</article-title>. <source>Vis. Res.</source>
<volume>36</volume>, <fpage>3265</fpage>–<lpage>3279</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(96)00065-x</pub-id><?supplied-pmid 8944286?><pub-id pub-id-type="pmid">8944286</pub-id></mixed-citation>
              </ref>
              <ref id="B121">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postma</surname><given-names>D. B. W.</given-names></name><name><surname>Den Otter</surname><given-names>A. R.</given-names></name><name><surname>Zaal</surname><given-names>F. T. J. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Keeping your eyes continuously on the ball while running for catchable and uncatchable fly balls</article-title>. <source>PLoS One</source>
<volume>9</volume>:<fpage>e92392</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0092392</pub-id><?supplied-pmid 24670972?><pub-id pub-id-type="pmid">24670972</pub-id></mixed-citation>
              </ref>
              <ref id="B123">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postma</surname><given-names>D. B.</given-names></name><name><surname>Lemmink</surname><given-names>K. A.</given-names></name><name><surname>Zaal</surname><given-names>F. T.</given-names></name></person-group> (<year>2018</year>). <article-title>The affordance of catchability in running to intercept fly balls</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>44</volume>, <fpage>1336</fpage>–<lpage>1347</lpage>. <pub-id pub-id-type="doi">10.1037/xhp0000531</pub-id><?supplied-pmid 29708378?><pub-id pub-id-type="pmid">29708378</pub-id></mixed-citation>
              </ref>
              <ref id="B122">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postma</surname><given-names>D. B. W.</given-names></name><name><surname>Smith</surname><given-names>J.</given-names></name><name><surname>Pepping</surname><given-names>G.-J.</given-names></name><name><surname>van Andel</surname><given-names>S.</given-names></name><name><surname>Zaal</surname><given-names>F. T. J. M.</given-names></name></person-group> (<year>2017</year>). <article-title>When a fly ball is out of reach: catchability judgments are not based on optical acceleration cancelation</article-title>. <source>Front. Psychol.</source>
<volume>8</volume>:<fpage>535</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2017.00535</pub-id><?supplied-pmid 28439251?><pub-id pub-id-type="pmid">28439251</pub-id></mixed-citation>
              </ref>
              <ref id="B124">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reed</surname><given-names>N.</given-names></name><name><surname>McLeod</surname><given-names>P.</given-names></name><name><surname>Dienes</surname><given-names>Z.</given-names></name></person-group> (<year>2010</year>). <article-title>Implicit knowledge and motor skill: what people who know how to catch don’t know</article-title>. <source>Conscious. Cogn.</source>
<volume>19</volume>, <fpage>63</fpage>–<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1016/j.concog.2009.07.006</pub-id><?supplied-pmid 19703779?><pub-id pub-id-type="pmid">19703779</pub-id></mixed-citation>
              </ref>
              <ref id="B125">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D.</given-names></name><name><surname>Beverley</surname><given-names>K.</given-names></name></person-group> (<year>1978</year>). <article-title>Looming detectors in the human visual pathway</article-title>. <source>Vis. Res.</source>
<volume>18</volume>, <fpage>415</fpage>–<lpage>421</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(78)90051-2</pub-id><?supplied-pmid 664320?><pub-id pub-id-type="pmid">664320</pub-id></mixed-citation>
              </ref>
              <ref id="B126">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D.</given-names></name><name><surname>Hamstra</surname><given-names>S. J.</given-names></name></person-group> (<year>1993</year>). <article-title>Dissociation of discrimination thresholds for time to contact and for rate of angular expansion</article-title>. <source>Vis. Res.</source>
<volume>33</volume>, <fpage>447</fpage>–<lpage>462</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(93)90252-r</pub-id><?supplied-pmid 8503195?><pub-id pub-id-type="pmid">8503195</pub-id></mixed-citation>
              </ref>
              <ref id="B127">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname><given-names>D.</given-names></name><name><surname>Kaushal</surname><given-names>S.</given-names></name></person-group> (<year>1994</year>). <article-title>Monocular discrimination of the direction of motion in depth</article-title>. <source>Vis. Res.</source>
<volume>34</volume>, <fpage>163</fpage>–<lpage>177</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(94)90329-8</pub-id><?supplied-pmid 8116276?><pub-id pub-id-type="pmid">8116276</pub-id></mixed-citation>
              </ref>
              <ref id="B128">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rind</surname><given-names>F. C.</given-names></name><name><surname>Simmons</surname><given-names>P. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Seeing what is coming: building collision-sensitive neurones</article-title>. <source>Trends Neurosci.</source>
<volume>22</volume>, <fpage>215</fpage>–<lpage>220</lpage>. <pub-id pub-id-type="doi">10.1016/s0166-2236(98)01332-0</pub-id><?supplied-pmid 10322494?><pub-id pub-id-type="pmid">10322494</pub-id></mixed-citation>
              </ref>
              <ref id="B129">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>J. E.</given-names></name><name><surname>Cullen</surname><given-names>K. E.</given-names></name></person-group> (<year>2003</year>). <article-title>Brain stem pursuit pathways: dissociating visual, vestibular, and proprioceptive inputs during combined eye-head gaze tracking</article-title>. <source>J. Neurophysiol.</source>
<volume>90</volume>, <fpage>271</fpage>–<lpage>290</lpage>. <pub-id pub-id-type="doi">10.1152/jn.01074.2002</pub-id><?supplied-pmid 12843311?><pub-id pub-id-type="pmid">12843311</pub-id></mixed-citation>
              </ref>
              <ref id="B130">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushton</surname><given-names>S. K.</given-names></name><name><surname>Wann</surname><given-names>J. P.</given-names></name></person-group> (<year>1999</year>). <article-title>Weighted combination of size and disparity: a computational model for timing a ball catch</article-title>. <source>Nat. Neurosci.</source>
<volume>2</volume>, <fpage>186</fpage>–<lpage>190</lpage>. <pub-id pub-id-type="doi">10.1038/5750</pub-id><?supplied-pmid 10195204?><pub-id pub-id-type="pmid">10195204</pub-id></mixed-citation>
              </ref>
              <ref id="B131">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savelsbergh</surname><given-names>G. J. P.</given-names></name><name><surname>Whiting</surname><given-names>H. T. A.</given-names></name></person-group> (<year>1992</year>). <article-title>The acquisition of catching under monocular and binocular conditions</article-title>. <source>J. Mot. Behav.</source>
<volume>24</volume>, <fpage>320</fpage>–<lpage>328</lpage>. <pub-id pub-id-type="doi">10.1080/00222895.1992.9941628</pub-id><?supplied-pmid 14769561?><pub-id pub-id-type="pmid">14769561</pub-id></mixed-citation>
              </ref>
              <ref id="B132">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savelsbergh</surname><given-names>G.</given-names></name><name><surname>Whiting</surname><given-names>H.</given-names></name><name><surname>Bootsma</surname><given-names>R. J.</given-names></name></person-group> (<year>1991</year>). <article-title>Grasping tau</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>17</volume>, <fpage>315</fpage>–<lpage>322</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.17.2.315</pub-id><?supplied-pmid 1830077?><pub-id pub-id-type="pmid">1830077</pub-id></mixed-citation>
              </ref>
              <ref id="B133">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxberg</surname><given-names>B.</given-names></name></person-group> (<year>1987a</year>). <article-title>Projected free fall trajectories. I. Theory and simulation</article-title>. <source>Biol. Cybern.</source>
<volume>56</volume>, <fpage>159</fpage>–<lpage>176</lpage>. <pub-id pub-id-type="doi">10.1007/BF00317991</pub-id><?supplied-pmid 3593785?><pub-id pub-id-type="pmid">3593785</pub-id></mixed-citation>
              </ref>
              <ref id="B134">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxberg</surname><given-names>B.</given-names></name></person-group> (<year>1987b</year>). <article-title>Projected free fall trajectories. II. Human experiments</article-title>. <source>Biol. Cybern.</source>
<volume>56</volume>, <fpage>177</fpage>–<lpage>184</lpage>. <pub-id pub-id-type="doi">10.1007/BF00317992</pub-id><?supplied-pmid 3593786?><pub-id pub-id-type="pmid">3593786</pub-id></mixed-citation>
              </ref>
              <ref id="B136">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaffer</surname><given-names>D. M.</given-names></name><name><surname>Marken</surname><given-names>R. S.</given-names></name><name><surname>Dolgov</surname><given-names>I.</given-names></name><name><surname>Maynor</surname><given-names>A. B.</given-names></name></person-group> (<year>2013</year>). <article-title>Chasin’choppers: using unpredictable trajectories to test theories of object interception</article-title>. <source>Atten. Percept. Psychophys.</source>
<volume>75</volume>, <fpage>1496</fpage>–<lpage>1506</lpage>. <pub-id pub-id-type="doi">10.3758/s13414-013-0500-7</pub-id><?supplied-pmid 23864264?><pub-id pub-id-type="pmid">23864264</pub-id></mixed-citation>
              </ref>
              <ref id="B135">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaffer</surname><given-names>D. M.</given-names></name><name><surname>McBeath</surname><given-names>M. K.</given-names></name></person-group> (<year>2005</year>). <article-title>Naive beliefs in baseball: systematic distortion in perceived time of apex for fly balls</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>31</volume>, <fpage>1492</fpage>–<lpage>1501</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.31.6.1492</pub-id><?supplied-pmid 16393059?><pub-id pub-id-type="pmid">16393059</pub-id></mixed-citation>
              </ref>
              <ref id="B137">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharp</surname><given-names>R. H.</given-names></name><name><surname>Whiting</surname><given-names>H. T. A.</given-names></name></person-group> (<year>1974</year>). <article-title>Exposure and occluded duration effects in a ball-catching skill</article-title>. <source>J. Mot. Behav.</source>
<volume>6</volume>, <fpage>139</fpage>–<lpage>147</lpage>. <pub-id pub-id-type="doi">10.1080/00222895.1974.10734990</pub-id><?supplied-pmid 23952726?><pub-id pub-id-type="pmid">23952726</pub-id></mixed-citation>
              </ref>
              <ref id="B138">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>M. R. H.</given-names></name><name><surname>Flach</surname><given-names>J. M.</given-names></name><name><surname>Dittman</surname><given-names>S. M.</given-names></name><name><surname>Stanard</surname><given-names>T.</given-names></name></person-group> (<year>2001</year>). <article-title>Monocular optical constraints on collision control</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>27</volume>, <fpage>395</fpage>–<lpage>410</lpage>. <pub-id pub-id-type="doi">10.1037//0096-1523.27.2.395</pub-id><?supplied-pmid 11318055?><pub-id pub-id-type="pmid">11318055</pub-id></mixed-citation>
              </ref>
              <ref id="B139">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soechting</surname><given-names>J. F.</given-names></name><name><surname>Juveli</surname><given-names>J. Z.</given-names></name><name><surname>Rao</surname><given-names>H. M.</given-names></name></person-group> (<year>2009</year>). <article-title>Models for the extrapolation of target motion for manual interception</article-title>. <source>J. Neurophysiol.</source>
<volume>102</volume>, <fpage>1491</fpage>–<lpage>1502</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00398.2009</pub-id><?supplied-pmid 19571194?><pub-id pub-id-type="pmid">19571194</pub-id></mixed-citation>
              </ref>
              <ref id="B140">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sousa</surname><given-names>R.</given-names></name><name><surname>Brenner</surname><given-names>E.</given-names></name><name><surname>Smeets</surname><given-names>J. B. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Judging an unfamiliar object’s distance from its retinal image size</article-title>. <source>J. Vis.</source>
<volume>11</volume>:<fpage>10</fpage>. <pub-id pub-id-type="doi">10.1167/11.9.10</pub-id><?supplied-pmid 21859822?><pub-id pub-id-type="pmid">21859822</pub-id></mixed-citation>
              </ref>
              <ref id="B141">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spering</surname><given-names>M.</given-names></name><name><surname>Schütz</surname><given-names>A. C.</given-names></name><name><surname>Braun</surname><given-names>D. I.</given-names></name><name><surname>Gegenfurtner</surname><given-names>K. R.</given-names></name></person-group> (<year>2011</year>). <article-title>Keep your eyes on the ball: smooth pursuit eye movements enhance prediction of visual motion</article-title>. <source>J. Neurophysiol.</source>
<volume>105</volume>, <fpage>1756</fpage>–<lpage>1767</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00344.2010</pub-id><?supplied-pmid 21289135?><pub-id pub-id-type="pmid">21289135</pub-id></mixed-citation>
              </ref>
              <ref id="B142">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>A. A.</given-names></name><name><surname>Simoncelli</surname><given-names>E. P.</given-names></name></person-group> (<year>2006</year>). <article-title>Noise characteristics and prior expectations in human visual speed perception</article-title>. <source>Nat. Neurosci.</source>
<volume>9</volume>, <fpage>578</fpage>–<lpage>585</lpage>. <pub-id pub-id-type="doi">10.1038/nn1669</pub-id><?supplied-pmid 16547513?><pub-id pub-id-type="pmid">16547513</pub-id></mixed-citation>
              </ref>
              <ref id="B143">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H.</given-names></name><name><surname>Frost</surname><given-names>B. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Computation of different optical variables of looming objects in pigeon nucleus rotundus neurons</article-title>. <source>Nat. Neurosci.</source>
<volume>1</volume>, <fpage>296</fpage>–<lpage>303</lpage>. <pub-id pub-id-type="doi">10.1038/1110</pub-id><?supplied-pmid 10195163?><pub-id pub-id-type="pmid">10195163</pub-id></mixed-citation>
              </ref>
              <ref id="B144">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tcheang</surname><given-names>L.</given-names></name><name><surname>Gilson</surname><given-names>S. J.</given-names></name><name><surname>Glennerster</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Systematic distortions of perceptual stability investigated using immersive virtual reality</article-title>. <source>Vis. Res.</source>
<volume>45</volume>, <fpage>2177</fpage>–<lpage>2189</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2005.02.006</pub-id><?supplied-pmid 15845248?><pub-id pub-id-type="pmid">15845248</pub-id></mixed-citation>
              </ref>
              <ref id="B145">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmerman</surname><given-names>P.</given-names></name><name><surname>van der Weele</surname><given-names>J. P.</given-names></name></person-group> (<year>1999</year>). <article-title>On the rise and fall of a ball with linear or quadratic drag</article-title>. <source>Am. J. Phys.</source>
<volume>67</volume>, <fpage>538</fpage>–<lpage>546</lpage>. <pub-id pub-id-type="doi">10.1119/1.19320</pub-id></mixed-citation>
              </ref>
              <ref id="B146">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todd</surname><given-names>J. T.</given-names></name></person-group> (<year>1981</year>). <article-title>Visual information about moving objects</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>7</volume>, <fpage>795</fpage>–<lpage>810</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.7.4.795</pub-id><?supplied-pmid 6457104?><pub-id pub-id-type="pmid">6457104</pub-id></mixed-citation>
              </ref>
              <ref id="B147">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E.</given-names></name></person-group> (<year>2004</year>). <article-title>Optimality principles in sensorimotor control</article-title>. <source>Nat. Neurosci.</source>
<volume>7</volume>, <fpage>907</fpage>–<lpage>915</lpage>. <pub-id pub-id-type="doi">10.1038/nn1309</pub-id><?supplied-pmid 15332089?><pub-id pub-id-type="pmid">15332089</pub-id></mixed-citation>
              </ref>
              <ref id="B148">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turvey</surname><given-names>M. T.</given-names></name><name><surname>Shaw</surname><given-names>R. E.</given-names></name><name><surname>Reed</surname><given-names>E. S.</given-names></name><name><surname>Mace</surname><given-names>W. M.</given-names></name></person-group> (<year>1981</year>). <article-title>Ecological laws of perceiving and acting: in reply to Fodor and Pylyshyn (1981)</article-title>. <source>Cognition</source>
<volume>9</volume>, <fpage>237</fpage>–<lpage>304</lpage>. <pub-id pub-id-type="doi">10.1016/0010-0277(81)90002-0</pub-id><?supplied-pmid 7197604?><pub-id pub-id-type="pmid">7197604</pub-id></mixed-citation>
              </ref>
              <ref id="B149">
                <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Von Helmholtz</surname><given-names>H.</given-names></name></person-group> (<year>1867</year>). <source>Treatise on Physiological Optics Vol. III.</source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Dover Publications</publisher-name>.</mixed-citation>
              </ref>
              <ref id="B150">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wann</surname><given-names>J. P.</given-names></name></person-group> (<year>1996</year>). <article-title>Anticipating arrival: is the tau margin a specious theory?</article-title>
<source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>22</volume>, <fpage>1031</fpage>–<lpage>1048</lpage>. <pub-id pub-id-type="doi">10.1037//0096-1523.22.4.1031</pub-id><?supplied-pmid 8830110?><pub-id pub-id-type="pmid">8830110</pub-id></mixed-citation>
              </ref>
              <ref id="B151">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname><given-names>W. H.</given-names><suffix>Jr.</suffix></name><name><surname>Kay</surname><given-names>B. A.</given-names></name><name><surname>Zosh</surname><given-names>W. D.</given-names></name><name><surname>Duchon</surname><given-names>A. P.</given-names></name><name><surname>Sahuc</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>). <article-title>Optic flow is used to control human walking</article-title>. <source>Nat. Neurosci.</source>
<volume>4</volume>, <fpage>213</fpage>–<lpage>216</lpage>. <pub-id pub-id-type="doi">10.1038/84054</pub-id><?supplied-pmid 11175884?><pub-id pub-id-type="pmid">11175884</pub-id></mixed-citation>
              </ref>
              <ref id="B152">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>J. S.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name><name><surname>von Hofsten</surname><given-names>C.</given-names></name><name><surname>Royden</surname><given-names>C. S.</given-names></name></person-group> (<year>1992</year>). <article-title>Gravity as a monocular cue for perception of absolute distance and/or absolute size</article-title>. <source>Perception</source>
<volume>21</volume>, <fpage>69</fpage>–<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1068/p210069</pub-id><?supplied-pmid 1528705?><pub-id pub-id-type="pmid">1528705</pub-id></mixed-citation>
              </ref>
              <ref id="B153">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X.-X.</given-names></name><name><surname>Stocker</surname><given-names>A. A.</given-names></name></person-group> (<year>2015</year>). <article-title>A Bayesian observer model constrained by efficient coding can explain ‘anti-Bayesian’ percepts</article-title>. <source>Nat. Neurosci.</source>
<volume>18</volume>, <fpage>1509</fpage>–<lpage>1517</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4105</pub-id><?supplied-pmid 26343249?><pub-id pub-id-type="pmid">26343249</pub-id></mixed-citation>
              </ref>
              <ref id="B154">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werkhoven</surname><given-names>P.</given-names></name><name><surname>Snippe</surname><given-names>H. P.</given-names></name><name><surname>Alexander</surname><given-names>T.</given-names></name></person-group> (<year>1992</year>). <article-title>Visual processing of optic acceleration</article-title>. <source>Vis. Res.</source>
<volume>32</volume>, <fpage>2313</fpage>–<lpage>2329</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(92)90095-z</pub-id><?supplied-pmid 1288008?><pub-id pub-id-type="pmid">1288008</pub-id></mixed-citation>
              </ref>
              <ref id="B155">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westheimer</surname><given-names>G.</given-names></name><name><surname>McKee</surname><given-names>S. P.</given-names></name></person-group> (<year>1977</year>). <article-title>Spatial configurations for visual hyperacuity</article-title>. <source>Vis. Res.</source>
<volume>17</volume>, <fpage>941</fpage>–<lpage>947</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(77)90069-4</pub-id><?supplied-pmid 595400?><pub-id pub-id-type="pmid">595400</pub-id></mixed-citation>
              </ref>
              <ref id="B156">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiting</surname><given-names>H. T. A.</given-names></name></person-group> (<year>1968</year>). <article-title>Training in a continuous ball throwing and catching task</article-title>. <source>Ergonomics</source>
<volume>11</volume>, <fpage>375</fpage>–<lpage>382</lpage>. <pub-id pub-id-type="doi">10.1080/00140136808930985</pub-id><?supplied-pmid 5678381?><pub-id pub-id-type="pmid">5678381</pub-id></mixed-citation>
              </ref>
              <ref id="B157">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiting</surname><given-names>H. T. A.</given-names></name><name><surname>Sharp</surname><given-names>R. H.</given-names></name></person-group> (<year>1974</year>). <article-title>Visual occlusion factors in a discrete ball-catching task</article-title>. <source>J. Mot. Behav.</source>
<volume>6</volume>, <fpage>11</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1080/00222895.1974.10734974</pub-id><?supplied-pmid 23947405?><pub-id pub-id-type="pmid">23947405</pub-id></mixed-citation>
              </ref>
              <ref id="B158">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilkie</surname><given-names>R.</given-names></name><name><surname>Wann</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>Controlling steering and judging heading: retinal flow, visual direction, and extraretinal information</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>29</volume>, <fpage>363</fpage>–<lpage>378</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.29.2.363</pub-id><?supplied-pmid 12760621?><pub-id pub-id-type="pmid">12760621</pub-id></mixed-citation>
              </ref>
              <ref id="B159">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>D. M.</given-names></name><name><surname>Ghahramani</surname><given-names>Z.</given-names></name><name><surname>Jordan</surname><given-names>M. I.</given-names></name></person-group> (<year>1995</year>). <article-title>An internal model for sensorimotor integration</article-title>. <source>Science</source>
<volume>269</volume>, <fpage>1880</fpage>–<lpage>1882</lpage>. <pub-id pub-id-type="doi">10.1126/science.7569931</pub-id><?supplied-pmid 7569931?><pub-id pub-id-type="pmid">7569931</pub-id></mixed-citation>
              </ref>
              <ref id="B160">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonas</surname><given-names>A.</given-names></name><name><surname>Bechtold</surname><given-names>A. G.</given-names></name><name><surname>Frankel</surname><given-names>D.</given-names></name><name><surname>Gordon</surname><given-names>F. R.</given-names></name><name><surname>McRoberts</surname><given-names>G.</given-names></name><name><surname>Norcia</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>1977</year>). <article-title>Development of sensitivity to information for impending collision</article-title>. <source>Percept. Psychophys.</source><volume>21</volume>, <fpage>97</fpage>–<lpage>104</lpage>. <pub-id pub-id-type="doi">10.3758/bf03198713</pub-id></mixed-citation>
              </ref>
              <ref id="B162">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaal</surname><given-names>F. T. J. M.</given-names></name><name><surname>Bongers</surname><given-names>R. M.</given-names></name><name><surname>Pepping</surname><given-names>G.-J.</given-names></name><name><surname>Bootsma</surname><given-names>R. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Base on balls for the Chapman strategy: reassessing Brouwer, Brenner, and Smeets (2002)</article-title>. <source>Atten. Percept. Psychophys.</source>
<volume>74</volume>, <fpage>1488</fpage>–<lpage>1498</lpage>. <pub-id pub-id-type="doi">10.3758/s13414-012-0328-6</pub-id><?supplied-pmid 22723014?><pub-id pub-id-type="pmid">22723014</pub-id></mixed-citation>
              </ref>
              <ref id="B161">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaal</surname><given-names>F. T. J. M.</given-names></name><name><surname>Bootsma</surname><given-names>R. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Virtual reality as a tool for the study of perception-action: the case of running to catch fly balls</article-title>. <source>Presence: Teleoperators and Virtual Environ.</source>
<volume>20</volume>, <fpage>93</fpage>–<lpage>103</lpage>. <pub-id pub-id-type="doi">10.1162/pres_a_00037</pub-id></mixed-citation>
              </ref>
              <ref id="B165">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Bosco</surname><given-names>G.</given-names></name><name><surname>Maffei</surname><given-names>V.</given-names></name><name><surname>Iosa</surname><given-names>M.</given-names></name><name><surname>Ivanenko</surname><given-names>Y. P.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2004</year>). <article-title>Internal models of target motion: expected dynamics overrides measured kinematics in timing manual interceptions</article-title>. <source>J. Neurophysiol.</source>
<volume>91</volume>, <fpage>1620</fpage>–<lpage>1634</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00862.2003</pub-id><?supplied-pmid 14627663?><pub-id pub-id-type="pmid">14627663</pub-id></mixed-citation>
              </ref>
              <ref id="B164">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Bosco</surname><given-names>G.</given-names></name><name><surname>Maffei</surname><given-names>V.</given-names></name><name><surname>Iosa</surname><given-names>M.</given-names></name><name><surname>Ivanenko</surname><given-names>Y. P.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2005</year>). <article-title>Fast adaptation of the internal model of gravity for manual interceptions: evidence for event-dependent learning</article-title>. <source>J. Neurophysiol.</source>
<volume>93</volume>, <fpage>1055</fpage>–<lpage>1068</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00833.2004</pub-id><?supplied-pmid 15456796?><pub-id pub-id-type="pmid">15456796</pub-id></mixed-citation>
              </ref>
              <ref id="B163">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2005</year>). <article-title>Internal model of gravity for hand interception: parametric adaptation to zero-gravity visual targets on earth</article-title>. <source>J. Neurophysiol.</source>
<volume>94</volume>, <fpage>1346</fpage>–<lpage>1357</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00215.2005</pub-id><?supplied-pmid 15817649?><pub-id pub-id-type="pmid">15817649</pub-id></mixed-citation>
              </ref>
              <ref id="B166">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zago</surname><given-names>M.</given-names></name><name><surname>McIntyre</surname><given-names>J.</given-names></name><name><surname>Senot</surname><given-names>P.</given-names></name><name><surname>Lacquaniti</surname><given-names>F.</given-names></name></person-group> (<year>2008</year>). <article-title>Internal models and prediction of visual gravitational motion</article-title>. <source>Vis. Res.</source>
<volume>48</volume>, <fpage>1532</fpage>–<lpage>1538</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2008.04.005</pub-id><?supplied-pmid 18499213?><pub-id pub-id-type="pmid">18499213</pub-id></mixed-citation>
              </ref>
              <ref id="B168">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Straub</surname><given-names>D.</given-names></name><name><surname>Rothkopf</surname><given-names>C. A.</given-names></name></person-group> (<year>2019</year>). <article-title>The visual control of interceptive steering: how do people steer a car to intercept a moving target?</article-title>
<source>J. Vis.</source>
<volume>19</volume>:<fpage>11</fpage>. <pub-id pub-id-type="doi">10.1167/19.14.11</pub-id><?supplied-pmid 31830240?><pub-id pub-id-type="pmid">31830240</pub-id></mixed-citation>
              </ref>
              <ref id="B167">
                <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Warren</surname><given-names>W. H.</given-names></name></person-group> (<year>2015</year>). <article-title>On-line and model-based approaches to the visual control of action</article-title>. <source>Vis. Res.</source>
<volume>110</volume>, <fpage>190</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2014.10.008</pub-id><?supplied-pmid 25454700?><pub-id pub-id-type="pmid">25454700</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
